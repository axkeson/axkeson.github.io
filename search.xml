<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[正则表达式速查表]]></title>
    <url>%2F2019%2F07%2F17%2Fdocs%2F09-pc-base%2Fregexsc%2F</url>
    <content type="text"><![CDATA[正则表达式速查表 字符 描述 \ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符。例如，“n”匹配字符”n”。”\n”匹配一个换行符。串行”\“匹配”&quot;而”(“则匹配”(“。 ^ 匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配“\n”或”\r”之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配“\n”或”\r”之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo能匹配“z”以及”zoo”。等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，“zo+”能匹配”zo”以及”zoo”，但不能匹配”z”。+等价于{1,}。 ? 匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配”does”或”does”中的”do”。?等价于{0,1}。 {n} n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配”Bob”中的”o”，但是能匹配”food”中的两个o。 {n,} n是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配”Bob”中的”o”，但能匹配”foooood”中的所有o。”o{1,}”等价于”o+”。”o{0,}”则等价于”o*”。 {n,m} m和n均为非负整数，其中n&lt;=m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配”fooooood”中的前三个o。”o{0,1}”等价于”o?”。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串“oooo”，”o+?”将匹配单个”o”，而”o+”将匹配所有”o”。 . 匹配除“\n”之外的任何单个字符。要匹配包括”\n”在内的任何字符，请使用像”(.|\n)”的模式。 (pattern) 匹配pattern并获取这一匹配。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“(“或”)“。 (?:pattern) 匹配pattern但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用或字符“( (?=pattern) 正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，“Windows(?=95 (?!pattern) 正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如“Windows(?!95 (?&lt;=pattern) 反向肯定预查，与正向肯定预查类拟，只是方向相反。例如，“(?&lt;=95 (?&lt;!pattern) 反向否定预查，与正向否定预查类拟，只是方向相反。例如“(?&lt;!95 x|y 匹配x或y。例如，“z [xyz] 字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配”plain”中的”a”。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，“[^abc]”可以匹配”plain”中的”p”。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配”a”到”z”范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]”可以匹配任何不在”a”到”z”范围内的任意字符。 \b 匹配一个单词边界，也就是指单词和空格间的位置。例如，“er\b”可以匹配”never”中的”er”，但不能匹配”verb”中的”er”。 \B 匹配非单词边界。“er\B”能匹配”verb”中的”er”，但不能匹配”never”中的”er”。 \cx 匹配由x指明的控制字符。例如，\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的“c”字符。 \d 匹配一个数字字符。等价于[0-9]。 \D 匹配一个非数字字符。等价于[^0-9]。 \f 匹配一个换页符。等价于\x0c和\cL。 \n 匹配一个换行符。等价于\x0a和\cJ。 \r 匹配一个回车符。等价于\x0d和\cM。 \s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。 \S 匹配任何非空白字符。等价于[^ \f\n\r\t\v]。 \t 匹配一个制表符。等价于\x09和\cI。 \v 匹配一个垂直制表符。等价于\x0b和\cK。 \w 匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9_]”。 \W 匹配任何非单词字符。等价于“[^A-Za-z0-9_]”。 \xn 匹配n，其中n为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，“\x41”匹配”A”。”\x041”则等价于”\x04&amp;1”。正则表达式中可以使用ASCII编码。. \num 匹配num，其中num是一个正整数。对所获取的匹配的引用。例如，“(.)\1”匹配两个连续的相同字符。 \n 标识一个八进制转义值或一个向后引用。如果\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。 \nm 标识一个八进制转义值或一个向后引用。如果\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\nm将匹配八进制转义值nm。 \nml 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。 \un 匹配n，其中n是一个用四个十六进制数字表示的Unicode字符。例如，\u00A9匹配版权符号（©）。 常用正则表达式校验数字的表达式12345678910111213141516171819 1 数字：^[0-9]*$ 2 n位的数字：^\d&#123;n&#125;$ 3 至少n位的数字：^\d&#123;n,&#125;$ 4 m-n位的数字：^\d&#123;m,n&#125;$ 5 零和非零开头的数字：^(0|[1-9][0-9]*)$ 6 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]&#123;1,2&#125;)?$ 7 带1-2位小数的正数或负数：^(\-)?\d+(\.\d&#123;1,2&#125;)?$ 8 正数、负数、和小数：^(\-|\+)?\d+(\.\d+)?$ 9 有两位小数的正实数：^[0-9]+(.[0-9]&#123;2&#125;)?$10 有1~3位小数的正实数：^[0-9]+(.[0-9]&#123;1,3&#125;)?$11 非零的正整数：^[1-9]\d*$ 或 ^([1-9][0-9]*)&#123;1,3&#125;$ 或 ^\+?[1-9][0-9]*$12 非零的负整数：^\-[1-9][]0-9&quot;*$ 或 ^-[1-9]\d*$13 非负整数：^\d+$ 或 ^[1-9]\d*|0$14 非正整数：^-[1-9]\d*|0$ 或 ^((-\d+)|(0+))$15 非负浮点数：^\d+(\.\d+)?$ 或 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$16 非正浮点数：^((-\d+(\.\d+)?)|(0+(\.0+)?))$ 或 ^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$17 正浮点数：^[1-9]\d*\.\d*|0\.\d*[1-9]\d*$ 或 ^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$18 负浮点数：^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$ 或 ^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$19 浮点数：^(-?\d+)(\.\d+)?$ 或 ^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ 校验字符的表达式123456789101112 1 汉字：^[\u4e00-\u9fa5]&#123;0,&#125;$ 2 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]&#123;4,40&#125;$ 3 长度为3-20的所有字符：^.&#123;3,20&#125;$ 4 由26个英文字母组成的字符串：^[A-Za-z]+$ 5 由26个大写英文字母组成的字符串：^[A-Z]+$ 6 由26个小写英文字母组成的字符串：^[a-z]+$ 7 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 8 由数字、26个英文字母或者下划线组成的字符串：^\w+$ 或 ^\w&#123;3,20&#125;$ 9 中文、英文、数字包括下划线：^[\u4E00-\u9FA5A-Za-z0-9_]+$10 中文、英文、数字但不包括下划线等符号：^[\u4E00-\u9FA5A-Za-z0-9]+$ 或 ^[\u4E00-\u9FA5A-Za-z0-9]&#123;2,20&#125;$11 可以输入含有^%&amp;&apos;,;=?$\&quot;等字符：[^%&amp;&apos;,;=?$\x22]+12 禁止输入含有~的字符：[^~\x22]+ 特殊需求表达式123456789101112131415161718192021222324252627282930313233 1 Email地址：^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$ 2 域名：[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;(/.[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;)+/.? 3 InternetURL：[a-zA-z]+://[^\s]* 或 ^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=]*)?$ 4 手机号码：^(13[0-9]|14[0-9]|15[0-9]|16[0-9]|17[0-9]|18[0-9]|19[0-9])\d&#123;8&#125;$ (由于工信部放号段不定时，所以建议使用泛解析 ^([1][3,4,5,6,7,8,9])\d&#123;9&#125;$) 5 电话号码(&quot;XXX-XXXXXXX&quot;、&quot;XXXX-XXXXXXXX&quot;、&quot;XXX-XXXXXXX&quot;、&quot;XXX-XXXXXXXX&quot;、&quot;XXXXXXX&quot;和&quot;XXXXXXXX)：^(\(\d&#123;3,4&#125;-)|\d&#123;3.4&#125;-)?\d&#123;7,8&#125;$ 6 国内电话号码(0511-4405222、021-87888822)：\d&#123;3&#125;-\d&#123;8&#125;|\d&#123;4&#125;-\d&#123;7&#125; 7 18位身份证号码(数字、字母x结尾)：^((\d&#123;18&#125;)|([0-9x]&#123;18&#125;)|([0-9X]&#123;18&#125;))$ 8 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$ 9 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\w&#123;5,17&#125;$10 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\d)(?=.*[a-z])(?=.*[A-Z]).&#123;8,10&#125;$ 11 日期格式：^\d&#123;4&#125;-\d&#123;1,2&#125;-\d&#123;1,2&#125;12 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$13 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 14 钱的输入格式：15 1.有四种钱的表示形式我们可以接受:&quot;10000.00&quot; 和 &quot;10,000.00&quot;, 和没有 &quot;分&quot; 的 &quot;10000&quot; 和 &quot;10,000&quot;：^[1-9][0-9]*$ 16 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符&quot;0&quot;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 17 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 18 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 19 5.必须说明的是,小数点后面至少应该有1位数,所以&quot;10.&quot;是不通过的,但是 &quot;10&quot; 和 &quot;10.2&quot; 是通过的：^[0-9]+(.[0-9]&#123;2&#125;)?$ 20 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]&#123;1,2&#125;)?$ 21 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*(.[0-9]&#123;1,2&#125;)?$ 22 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*)(.[0-9]&#123;1,2&#125;)?$ 23 备注：这就是最终结果了,别忘了&quot;+&quot;可以用&quot;*&quot;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里24 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$25 中文字符的正则表达式：[\u4e00-\u9fa5]26 双字节字符：[^\x00-\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))27 空白行的正则表达式：\n\s*\r (可以用来删除空白行)28 HTML标记的正则表达式：&lt;(\S*?)[^&gt;]*&gt;.*?&lt;/\1&gt;|&lt;.*? /&gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)29 首尾空白字符的正则表达式：^\s*|\s*$或(^\s*)|(\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)30 腾讯QQ号：[1-9][0-9]&#123;4,&#125; (腾讯QQ号从10000开始)31 中国邮政编码：[1-9]\d&#123;5&#125;(?!\d) (中国邮政编码为6位数字)32 IP地址：\d+\.\d+\.\d+\.\d+ (提取IP地址时有用)33 IP地址：((?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)\\.)&#123;3&#125;(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)) 在线工具http://tool.php.cn/regexhttps://c.runoob.com/front-end/854]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[COOKIE、SESSION、TOKEN各自的优缺点都有哪些？]]></title>
    <url>%2F2019%2F03%2F12%2Fdocs%2F09-pc-base%2Fsession-cookie-token%2F</url>
    <content type="text"><![CDATA[前言HTTP是一个无状态协议。什么是无状态呢？就是说这一次请求和上一次请求是没有关系的，互不认识的，没有关联的。这种无状态的好处是快速。坏处是假如我们想把对次请求关联起来，必须使用某些手段和工具。 COOKIECOOKIE 是什么 COOKIE 本身是由服务器产生的，生成之后发送给浏览器，并保存在浏览器 COOKIE 就是浏览器存储在本地目录的一小段文本 COOKIE 是以 key-value 形式存储的 COOKIE 有大小限制，为了保证COOKIE不占用太多的磁盘空间，每个COOKIE大小一般不超过4KB COOKIE 默认在会话结束后直接销毁，此种COOKIE称之为会话COOKIE COOKIE 可以设置过期时间，此种COOKIE 称之为持久COOKIE COOKIE 的生命周期 COOKIE 的不足 每个 COOKIE 的容量有限 因为cookie由浏览器存储在本地目录，所以不方便记录敏感信息，如密码等 cookie不支持跨域访问 cookie不支持手机端方案 SESSION什么是 SESSION SESSION 是由服务器产生的，存储在服务端 SESSION 的存储形式多种多样，可以是文件、数据库、缓存等，这需要靠程序如何设计 SESSION 也是以 key-value 形式存储的 SESSION 是没有大小限制的，这比cookie灵活很多，不过将过多的东西放在其中也并不是明智的做法 SESSION 也有过期时间的概念，默认为30分钟，可以通过tomcat、web.xml等方式进行配置 SESSION 可以主动通过invalidate()方法进行销毁 SESSION 通过session_id识别，如果请求持有正确的session_id，则服务器认为此请求处于session_id代表的会话中 SESSION 的生命周期 SESSION 的不足 SESSION 大小不限制，存储在服务端，本身是对资源的一种负担 如何保证session的高可用、准确性，优势对整体架构的一种负担 频繁的创建、查询、验证session，会对服务器造成很大的压力 SESSION 是有状态的 TOKEN什么是TOKEN TOKEN 是一种轻量级的用户验证方式 TOKEN 是无状态的 TOKEN 允许跨域访问 TOKEN 是服务端生成的一个字符串，保存在客户端（可以放在cookie中），作为请求服务的验证令牌 TOKEN 无需存放在服务端，这样服务端无需存放用户信息 TOKEN 对服务端压力极小`，因为服务端只需存储秘钥，并支持生成token的算法，无需存储token TOKEN 最简单的构造：用户唯一的身份标识(辨识用户) + 时间戳(用于过期校验) + 签名(防止第三方恶意冒充) TOKEN 无法主动过期，只能等待它达到过期时间后才会失效 TOKEN 的产生：首次请求时，服务器对请求参数（如账号、密码）验证通过，则根据用户标识，加上服务的密钥，通过生成算法，生成token TOKEN 的验证：再次请求时，携带此token，则服务端再次根据用户标识，生成token，根据两个token是否一致且未过期来判定用户是否已授权 TOKEN 的生命周期 TOKEN 的不足 TOKEN 无法主动过期，只能等待它达到过期时间后才会失效 TOKEN 本身比session_id要大，会消耗更多的流量与带宽]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>会话机制</tag>
        <tag>cookie</tag>
        <tag>session</tag>
        <tag>token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Supervisord 管理服务进程]]></title>
    <url>%2F2018%2F07%2F31%2Fdocs%2F06-Linux%2Flinux-supervisord%2F</url>
    <content type="text"><![CDATA[简介在开发中我们通过端口号启动多个网站服务和接口服务，网关服务，如果不使用工具管理这些服务进程，每次开机时都重新启动一次，将浪费我们大量时间。 安装1$ sudo apt install supervisor 配置默认supervisor配置目录为/etc/supervisor/conf.d。为方便操作，这里我们使用自己的配置目录。 1$ mkdir -p supervisor/&#123;conf,logs,run&#125; 添加配置文件supervisor.conf: 12345678910111213141516171819202122[unix_http_server]file=/path/to/your/supervisor/run/supervisor.sock[supervisord]logfile=/path/to/your/supervisor/logs/supervisor.loglogfile_maxbytes=50MBlogfile_backups=10loglevel=infopidfile=/path/to/your/supervisor/run/supervisor.pidnodaemon=falseminfds=1024minprocs=200childlogdir=/path/to/your/supervisor/logs[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///path/to/your/supervisor/run/supervisor.sock[include]files = conf/*.conf 修改配置文件中 /path/to/your/supervisor 为当前目录绝对路径。 启动 supervisor 服务： 1$ supervisord -n -c supervisor.conf 配置与管理进程再启动一个终端，运行命令： 1$ supervisorctl -c supervisor.conf 输入 help 命令查看所有命令： 1234567supervisor&gt; helpdefault commands (type help &lt;topic&gt;):=====================================add exit open reload restart start tail avail fg pid remove shutdown status update clear maintail quit reread signal stop version 运行 status 查看所有管理进程，目前没有配置，所以没有输出。 添加配置 conf/web-test.conf : 123[program:web-test]directory=/path/to/your/web-test/publiccommand=php -S 0:8099 index.php 修改 /path/to/your/web-test 为实际项目地址。 执行 update 命令可以看到配置已经加载： 1234supervisor&gt; updatepet-clinic-web: added process groupsupervisor&gt; statuspet-clinic-web RUNNING pid 5958, uptime 0:00:01 打开网站看看服务是否正确。 开机启动在 /etc/systemd/system 目录中添加我们自己的 supervisor 开机启动配置 my-supervisord.service : 12345678910[Unit]Description=My Supervisord Daemon[Service]ExecStart=/usr/bin/supervisord -n -c /path/to/your/supervisor.confUser=your-usernameGroup=your-username[Install]WantedBy=multi-user.target 替换上面配置文件中路径和用户名。启用开机启动： 123systemctl daemon-reloadsystemctl start my-supervisordsystemctl enable my-supervisord 别名supervisorctl 管理命令需要指定文件名启动，可以通过在 ~/.bashrc 中配置别名： 123function sv &#123; supervisorctl -c /path/to/your/supervisor.conf $@&#125; 现在在终端使用 sv 命令就可以进入管理命令行。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Supervisord</tag>
        <tag>服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TODO AWK 简明教程]]></title>
    <url>%2F2018%2F07%2F23%2Fdocs%2F06-Linux%2Flinux-awk%2F</url>
    <content type="text"><![CDATA[简介awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。 awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 使用方法1234$ awk '&#123;pattern + action&#125;' &#123;filenames&#125;# 示例$ awk '&#123;print $0&#125;' demo.txt 尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 内键变量 变量 描述 $n 当前记录的第n个字段，字段间由FS分隔 $0 完整的输入记录 ARGC 命令行参数的数目 ARGIND 命令行中当前文件的位置(从0开始算) ARGV 包含命令行参数的数组 CONVFMT 数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组 ERRNO 最后一个系统错误的描述 FIELDWIDTHS 字段宽度列表(用空格键分隔) FILENAME 当前文件名 FNR 各文件分别计数的行号 FS 字段分隔符(默认是任何空格) IGNORECASE 如果为真，则进行忽略大小写的匹配 NF 一条记录的字段的数目 NR 已经读出的记录数，就是行号，从1开始 OFMT 数字的输出格式(默认值是%.6g) OFS 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 ORS 输出记录分隔符(默认值是一个换行符) RLENGTH 由match函数所匹配的字符串的长度 RS 记录分隔符(默认是一个换行符) RSTART 由match函数所匹配的字符串的第一个位置 SUBSEP 数组下标分隔符(默认值是/034) 运算符 运算符 描述 = += -= = /= %= ^= *= 赋值 ?: C条件表达式 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / % 乘，除与求余 + - ! 一元加，减和逻辑非 ^ *** 求幂 ++ – 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员 调用awk入门实例]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TODO Nginx+php-fpm 运行原理]]></title>
    <url>%2F2018%2F07%2F20%2Fdocs%2F06-Linux%2Fphp-nginx-run-way%2F</url>
    <content type="text"><![CDATA[前言随着互联网的发展，用户对此接受面广，数据流的增大使得Web端的运行承载压力日益增大,野蛮生长在大数据时代里的WEB语言PHP也找到了比老搭档更优越的活力搭档Nginx. Nginx 是什么Nginx (“engine x”) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。 php-fpm 是什么 php-fpm即php-Fastcgi Process Manager. php-fpm是 FastCGI 的实现，并提供了进程管理的功能 进程包含 master 进程和 worker 进程两种进程。master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个(具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方。 要明白nginx 与 php-fpm是如何协同工作的,那么首先要明白CGI (Common Gateway Interface) 和 FastCGI 这两个协议 CGI与fastcgiCGI 是 Web Server 与后台语言交互的协议，有了这个协议，开发者可以使用任何语言处理 Web Server 发来的请求，动态的生成内容。但 CGI 有一个致命的缺点，那就是每处理一个请求都需要 fork 一个全新的进程，随着 Web 的兴起，高并发越来越成为常态，这样低效的方式明显不能满足需求。就这样，FastCGI 诞生了，CGI 很快就退出了历史的舞台。 FastCGI，顾名思义为更快的CGI, 它允许在一个进程内处理多个请求，而不是一个请求处理完毕就直接结束进程，性能上有了很大的提高。 FastCGI是一个可伸缩地、高速地在HTTP server和动态脚本语言间通信的接口。多数流行的HTTP server都支持FastCGI，包括Apache、Nginx和lighttpd等。同时，FastCGI也被许多脚本语言支持，其中就有PHP FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器[如nginx]专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 至于 FPM (FastCGI Process Manager)，它是 FastCGI 的实现，任何实现了 FastCGI 协议的 Web Server 都能够与之通信。FPM 之于标准的 FastCGI，也提供了一些增强功能. FPM 是一个 PHP 进程管理器，包含 master 进程和 worker 进程两种进程：master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个 (具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>nginx</tag>
        <tag>PHP-FPM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PsySh PHP交互控制台]]></title>
    <url>%2F2018%2F07%2F17%2Fdocs%2F02-tools%2Fpsysh%2F</url>
    <content type="text"><![CDATA[简介psysh是一个PHP的运行时开发平台，交互式调试器和Read-Eval-Print Loop (REPL)。说的简单点,就跟你用Chrome的时候firebug的console调试你的JavaScript代码一样。 官网 GitHub Packagist 安装直接下载123$ wget https://git.io/psysh$ chmod +x psysh$ ./psysh 使用Composer安装12$ composer g require psy/psysh:@stable$ psysh 以下教程以OS X和Windows为例，在这之前您已经将安装了php和composer，并且把加入了环境变量 OS x1. 下载12$ composer global require psy/psysh` 2. 安装完毕后，PsySH已经安装到/Users/{用户名}/.composer/vendor/psy/psysh目录下,这个时候你可以这样来直接运行1$ /Users/&#123;用户名&#125;/.composer/vendor/psy/psysh/bin/psysh 3. 为了使用方便，建议将它加入到环境变量：12$ echo &apos;export PATH=&quot;/Users/&#123;用户名&#125;/.composer/vendor/psy/psysh/bin:$PATH&quot;&apos; &gt;&gt; ~/.bashrc$ source ~/.bashrc Windows1. 我们还是用的composer来安装，win+r召唤控制台，然后1composer global require psy/psysh 2. 安装完成后，PsySH被安装到C:Users{用户名}AppDataRoamingComposervendorpsypsysh因为bin/psysh文件并不是windows的可执行文件，所以需要使用以下命令运行PsySH 1php C:\Users\&#123;用户名&#125;\AppData\Roaming\Composer\vendor\psy\psysh\bin\psysh 3. 为了使用方便，在C:Users{用户名}AppDataRoamingComposervendorpsypsyshbin目录下新建一个名为psysh.bat的文件，其内容如下12@ECHO OFFphp &quot;%~dp0psysh&quot; %* 4. 此时，把C:Users{用户名}A ppDataRoamingComposervendorpsypsyshbin 加入到系统的环境变量PATH，以后可以直接在cmd下运行psysh了123C:\Users\Vergil&gt;psyshPsy Shell v0.6.1 (PHP 5.6.8 — cli) by Justin Hileman&gt;&gt;&gt; 神器特性psysh是一个交互式的PHP运行控制台，在这里，你可以写php代码运行，并且可以清楚看到每次的返回值： 能够很智能的知道你的代码是否已经结束 自动完成，psysh可以像控制台那样，按下两次[tab]键自动补全，帮你自动完成变量名，函数，类，方法，属性，甚至是文件 文档在运行时忘记参数怎么办？psysh的文档功能可以上你及时查看文档。 PsySH的文档存放在~/.local/share/psysh/。（windows系统存放在C:\Users\{用户名}\AppData\Roaming\PsySH\） 下载中文文档： 1234$ cd ~/.local/share $ mkdir psysh$ cd psydh$ wget http://psysh.org/manual/zh/php_manual.sqlite OK，完成后重新打开PsySH 查看源代码轻松展现任何用户级的对象，类，接口，特质，常数，方法或属性的源代码： 反射列表list命令知道所有关于你的代码 - 和其他人的。轻松地列出并搜索所有的变量，常量，类，接口，特点，功能，方法和属性。 获取最后的异常信息如果忘记catch异常，可以使用wtf命令（wtf是what the fuck的意思么？）查看异常的信息： 历史记录可以像类Unix系统的history命令一样，在PsySH可以查看你运行过的PHP代码或命令。详情运行help history命令查看。 退出使用exit命令退出你的PsySH]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>psysh</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 关于 self 和 static]]></title>
    <url>%2F2018%2F06%2F22%2Fdocs%2F03-php%2Fphp-late-static-bindings%2F</url>
    <content type="text"><![CDATA[实例self:: 的限制使用 self:: 或者 __CLASS__ 对当前类的静态引用，取决于定义当前方法所在的类： self:: 用法 123456789101112131415161718192021&lt;?phpclass A &#123; public static function who() &#123; echo __CLASS__; &#125; public static function test() &#123; self::who(); &#125;&#125;class B extends A &#123; public static function who() &#123; echo __CLASS__; &#125;&#125;B::test();// 以上例程会输出：A 后期静态绑定的用法后期静态绑定本想通过引入一个新的关键字表示运行时最初调用的类来绕过限制。简单地说，这个关键字能够让你在上述例子中调用 test() 时引用的类是 B 而不是 A。最终决定不引入新的关键字，而是使用已经预留的 static 关键字。 static:: 简单用法 123456789101112131415161718192021&lt;?phpclass A &#123; public static function who() &#123; echo __CLASS__; &#125; public static function test() &#123; static::who(); // 后期静态绑定从这里开始 &#125;&#125;class B extends A &#123; public static function who() &#123; echo __CLASS__; &#125;&#125;B::test();// 以上例程会输出：B 在非静态环境下，所调用的类即为该对象实例所属的类。由于 $this-&gt; 会在同一作用范围内尝试调用私有方法，而 static:: 则可能给出不同结果。另一个区别是 static:: 只能用于静态属性。 非静态环境下使用 static:: 12345678910111213141516171819202122232425262728293031323334&lt;?phpclass A &#123; private function foo() &#123; echo "success!\n"; &#125; public function test() &#123; $this-&gt;foo(); static::foo(); &#125;&#125;class B extends A &#123; /* foo() will be copied to B, hence its scope will still be A and * the call be successful */&#125;class C extends A &#123; private function foo() &#123; /* original method is replaced; the scope of the new one is C */ &#125;&#125;$b = new B();$b-&gt;test();$c = new C();$c-&gt;test(); //fails// 以上例程会输出：success!success!success!Fatal error: Call to private method C::foo() from context 'A' in /tmp/test.php on line 9 后期静态绑定的解析会一直到取得一个完全解析了的静态调用为止。另一方面，如果静态调用使用 parent:: 或者 self:: 将转发调用信息。 转发和非转发调用 12345678910111213141516171819202122232425262728293031323334&lt;?phpclass A &#123; public static function foo() &#123; static::who(); &#125; public static function who() &#123; echo __CLASS__."\n"; &#125;&#125;class B extends A &#123; public static function test() &#123; A::foo(); parent::foo(); self::foo(); &#125; public static function who() &#123; echo __CLASS__."\n"; &#125;&#125;class C extends B &#123; public static function who() &#123; echo __CLASS__."\n"; &#125;&#125;C::test();// 以上例程会输出：ACC 总结 self 和 __CLASS__，都是对当前类的静态引用，取决于定义当前方法所在的类。也就是说，self 写在哪个类里面， 它引用的就是谁。 $this 指向的是实际调用时的对象，也就是说，实际运行过程中，谁调用了类的属性或方法，$this 指向的就是哪个对象。但 $this 不能访问类的静态属性和常量，且 $this 不能存在于静态方法中。 static 关键字除了可以声明类的静态成员（属性和方法）外，还有一个非常重要的作用就是后期静态绑定。 self 可以用于访问类的静态属性、静态方法和常量，但 self 指向的是当前定义所在的类，这是 self 的限制。 $this 指向的对象所属的类和 static 指向的类相同。 static 可以用于静态或非静态方法中，也可以访问类的静态属性、静态方法、常量和非静态方法，但不能访问非静态属性。 静态调用时，static 指向的是实际调用时的类；非静态调用时，static 指向的是实际调用时的对象所属的类 相关文章 https://www.php.net/manual/zh/language.oop5.late-static-bindings.phphttps://blog.csdn.net/lamp_yang_3533/article/details/79912453]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>self</tag>
        <tag>static</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转）HTTP和HTTPS的区别与联系]]></title>
    <url>%2F2018%2F05%2F13%2Fdocs%2F09-pc-base%2Fnetwork-http-https%2F</url>
    <content type="text"><![CDATA[超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。 为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 HTTP和HTTPS的基本概念HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。 HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 HTTP与HTTPS有什么区别HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。 简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。 HTTPS和HTTP的区别主要如下： https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 HTTPS的工作原理客户端发起HTTPS请求这个没什么好说的，就是用户在浏览器里输入一个https网址，然后连接到server的443端口。 服务端的配置采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。 这套证书其实就是一对公钥和私钥，如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 传送证书这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 客户端解析证书这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。 如果证书没有问题，那么就生成一个随机值，然后用证书对该随机值进行加密，就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 传送加密信息这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 服务段解密信息服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密，所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 传输加密后的信息这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。 客户端解密信息客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容，整个过程第三方即使监听到了数据，也束手无策。 HTTPS的优点正是由于HTTPS非常的安全，攻击者无法从中找到下手的地方，从站长的角度来说，HTTPS的优点有以下2点： SEO方面谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。 安全性尽管HTTPS并非绝对安全，掌握根证书的机构、掌握加密算法的组织同样可以进行中间人形式的攻击，但HTTPS仍是现行架构下最安全的解决方案，主要有以下几个好处： 使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器； HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。 HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。 HTTPS的缺点虽然说HTTPS有很大的优势，但其相对来说，还是有些不足之处的，具体来说，有以下2点： SEO方面据ACM CoNEXT数据显示，使用HTTPS协议会使页面的加载时间延长近50%，增加10%到20%的耗电，此外，HTTPS协议还会影响缓存，增加数据开销和功耗，甚至已有安全措施也会受到影响也会因此而受到影响。 而且HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。 最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。 经济方面 SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。 SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗（SSL有扩展可以部分解决这个问题，但是比较麻烦，而且要求浏览器、操作系统支持，Windows XP就不支持这个扩展，考虑到XP的装机量，这个特性几乎没用）。 HTTPS连接缓存不如HTTP高效，大流量网站如非必要也不会采用，流量成本太高。 HTTPS连接服务器端资源占用高很多，支持访客稍多的网站需要投入更大的成本，如果全部采用HTTPS，基于大部分计算资源闲置的假设的VPS的平均成本会上去。 HTTPS协议握手阶段比较费时，对网站的相应速度有负面影响，如非必要，没有理由牺牲用户体验。 本文转载自 https://blog.csdn.net/xionghuixionghui/article/details/68569282 相关文章 https://www.runoob.com/w3cnote/http-vs-https.htmlhttps://www.jianshu.com/p/37654eb66b58]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TODO 从输入 URL 到页面加载完成的过程中都发生了什么事情？]]></title>
    <url>%2F2018%2F05%2F12%2Fdocs%2F09-pc-base%2Fwhenyouenteraurl%2F</url>
    <content type="text"><![CDATA[背景具体过程DNS 解析DNS（Domain Name System，域名系统）解析DNS解析的过程就是寻找哪台机器上有你需要资源的过程。当你在浏览器中输入一个地址时，例如www.baidu.com，其实不是百度网站真正意义上的地址。互联网上每一台计算机的唯一标识是它的IP地址，但是IP地址并不方便记忆。用户更喜欢用方便记忆的网址去寻找互联网上的其它计算机，也就是上面提到的百度的网址。所以互联网设计者需要在用户的方便性与可用性方面做一个权衡，这个权衡就是一个网址到IP地址的转换，这个过程就是DNS解析。它实际上充当了一个翻译的角色，实现了网址到IP地址的转换。网址到IP地址转换的过程是如何进行的? TCP 连接发送HTTP请求服务器处理请求并返回HTTP报文浏览器解析渲染页面连接结束相关文档 https://dailc.github.io/2018/03/12/whenyouenteraurl.htmlhttp://fex.baidu.com/blog/2014/05/what-happen]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转）CentOS7.4搭建shadowsocks，以及配置BBR加速]]></title>
    <url>%2F2018%2F04%2F13%2Fdocs%2F02-tools%2Fshadowsocks-setting%2F</url>
    <content type="text"><![CDATA[前言作为一个新世纪的码农，我们经常需要使用百度以及Google等搜索引擎搜索资料或搜索一些错误的解决方案，如果English好的还可能需要到stackoverflow里查看或提问一些开发中遇到的问题，再者可能还需要到youtube上查找一下教学、科普视频等等。还好的是stackoverflow部分不牵扯Google的内容在国内还是能够正常访问的，但是Google和youtube嘛大家都懂，所以本文就介绍一下如何在vps上搭建shadowsocks，让我们能够访问这些网站，以便于我门查阅资料，切勿用做其他不法用途。 常见VPS的购买地址活跃于大街小巷的搬瓦工，也是适合新手使用的： https://bwh1.net/ vultr https://www.vultr.com/?ref=7315390 SugarHosts https://www.sugarhosts.com/zh-cn/ Linode https://www.linode.com/ Virmach https://billing.virmach.com/cart.php?gid=1 RAKSmart https://billing.raksmart.com/ Bluehost https://cn.bluehost.com/ DigitalOcean https://www.digitalocean.com 以上这些都是国外的vps，国内的可以购买阿里云或者腾讯云等，国内没有遇到优惠的话就比较贵。 安装 pippip是python的包管理工具。在本文中将使用python版本的shadowsocks，此版本的shadowsocks已发不到pip上，因此我们需要通过pip命令来安装。 在控制台执行以下命令安装 pip： 12$ curl "https://bootstrap.pypa.io/get-pip.py" -o "get-pip.py"$ python get-pip.py 安装配置 shadowsocks在控制台执行以下命令安装shadowsocks: 12$ pip install --upgrade pip$ pip install shadowsocks 安装完成后，需要创建shadowsocks的配置文件/etc/shadowsocks.json，编辑内容如下： 12345678910111213$ vim /etc/shadowsocks.json&#123; "server": "0.0.0.0", "local_address": "127.0.0.1", "local_port": 1080, "port_password": &#123; "8080": "填写密码", "8081": "填写密码" &#125;, "timeout": 600, "method": "aes-256-cfb"&#125; 说明 method为加密方法，可选aes-128-cfb,aes-192-cfb,aes-256-cfb,bf-cfb,cast5-cfb,des-cfb,rc4-md5,chacha20,rc4,table port_password为端口对应的密码，可使用密码生成工具生成一个随机密码 以上两项信息在配置shadowsocks客户端时需要配置一致，具体说明可查看shadowsocks的帮助文档。 如果你不需要配置多个端口的话，仅配置单个端口，则可以使用以下配置： 123456&#123; &quot;server&quot;: &quot;0.0.0.0&quot;, &quot;server_port&quot;: 8080, &quot;password&quot;: &quot;填写密码&quot;, &quot;method&quot;: &quot;aes-256-cfb&quot;&#125; 说明： server_port为服务监听端口 password为密码 同样的以上两项信息在配置 shadowsocks 客户端时需要配置一致。 配置自启动编辑shadowsocks 服务的启动脚本文件，内容如下： 12345678910$ vim /etc/systemd/system/shadowsocks.service[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json[Install]WantedBy=multi-user.target 执行以下命令启动 shadowsocks 服务： 12$ systemctl enable shadowsocks$ systemctl start shadowsocks 检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态： 1$ systemctl status shadowsocks -l 确认服务启动成功后，配置防火墙规则，开放你配置的端口，不然客户端是无法连接的： 123456$ firewall-cmd --zone=public --add-port=8080/tcp --permanentsuccess$ firewall-cmd --zone=public --add-port=8081/tcp --permanentsuccess$ firewall-cmd --reloadsuccess 一键安装脚本代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#!/bin/bash# Install Shadowsocks on CentOS 7echo "Installing Shadowsocks..."random-string()&#123; cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w $&#123;1:-32&#125; | head -n 1&#125;CONFIG_FILE=/etc/shadowsocks.jsonSERVICE_FILE=/etc/systemd/system/shadowsocks.serviceSS_PASSWORD=$(random-string 32)SS_PORT=8388SS_METHOD=aes-256-cfbSS_IP=`ip route get 1 | awk '&#123;print $NF;exit&#125;'`GET_PIP_FILE=/tmp/get-pip.py# install pipcurl "https://bootstrap.pypa.io/get-pip.py" -o "$&#123;GET_PIP_FILE&#125;"python $&#123;GET_PIP_FILE&#125;# install shadowsockspip install --upgrade pippip install shadowsocks# create shadowsocls configcat &lt;&lt;EOF | sudo tee $&#123;CONFIG_FILE&#125;&#123; "server": "0.0.0.0", "server_port": $&#123;SS_PORT&#125;, "password": "$&#123;SS_PASSWORD&#125;", "method": "$&#123;SS_METHOD&#125;"&#125;EOF# create servicecat &lt;&lt;EOF | sudo tee $&#123;SERVICE_FILE&#125;[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c $&#123;CONFIG_FILE&#125;[Install]WantedBy=multi-user.targetEOF# start servicesystemctl enable shadowsockssystemctl start shadowsocks# view service statussleep 5systemctl status shadowsocks -lecho "================================"echo ""echo "Congratulations! Shadowsocks has been installed on your system."echo "You shadowsocks connection info:"echo "--------------------------------"echo "server: $&#123;SS_IP&#125;"echo "server_port: $&#123;SS_PORT&#125;"echo "password: $&#123;SS_PASSWORD&#125;"echo "method: $&#123;SS_METHOD&#125;"echo "--------------------------------" 配置客户端我这里配置的是windows的客户端，挺方便的，点击即用，不需要安装。 Windows客户端下载地址： https://github.com/shadowsocks/shadowsocks-windows/releases Mac客户端下载地址： https://github.com/shadowsocks/ShadowsocksX-NG/releases Android客户端下载地址： https://github.com/shadowsocks/shadowsocks-android/releases 接着测试能否上Google搜索即可，以下的配置BBR加速则是选看，不配置也是可以正常使用shadowsocks的。 配置BBR加速什么是BBR： TCP BBR是谷歌出品的TCP拥塞控制算法。BBR目的是要尽量跑满带宽，并且尽量不要有排队的情况。BBR可以起到单边加速TCP连接的效果。 Google提交到Linux主线并发表在ACM queue期刊上的TCP-BBR拥塞控制算法。继承了Google“先在生产环境上部署，再开源和发论文”的研究传统。TCP-BBR已经再YouTube服务器和Google跨数据中心的内部广域网(B4)上部署。由此可见出该算法的前途。 TCP-BBR的目标就是最大化利用网络上瓶颈链路的带宽。一条网络链路就像一条水管，要想最大化利用这条水管，最好的办法就是给这跟水管灌满水。 BBR解决了两个问题： 在有一定丢包率的网络链路上充分利用带宽。非常适合高延迟，高带宽的网络链路。 降低网络链路上的buffer占用率，从而降低延迟。非常适合慢速接入网络的用户。Google 在 2016年9月份开源了他们的优化网络拥堵算法BBR，最新版本的 Linux内核(4.9-rc8)中已经集成了该算法。 对于TCP单边加速，并非所有人都很熟悉，不过有另外一个大名鼎鼎的商业软件“锐速”，相信很多人都清楚。特别是对于使用国外服务器或者VPS的人来说，效果更佳。 BBR项目地址： https://github.com/google/bbr 升级内核，第一步首先是升级内核到支持BBR的版本：1.yum更新系统版本： 1$ yum update 2.查看系统版本： 12$ cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) 3.安装elrepo并升级内核： 123$ rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org$ rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm$ yum --enablerepo=elrepo-kernel install kernel-ml -y 4.更新grub文件并重启系统： 12345678$ egrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \'CentOS Linux 7 Rescue 8619ff5e1306499eac41c02d3b23868e (4.14.14-1.el7.elrepo.x86_64)CentOS Linux (4.14.14-1.el7.elrepo.x86_64) 7 (Core)CentOS Linux (3.10.0-693.11.6.el7.x86_64) 7 (Core)CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)CentOS Linux (0-rescue-c73a5ccf3b8145c3a675b64c4c3ab1d4) 7 (Core)$ grub2-set-default 0$ reboot 5.重启完成后查看内核是否已更换为4.14版本： 12$ uname -r4.14.14-1.el7.elrepo.x86_64 6.开启bbr： 123$ vim /etc/sysctl.conf # 在文件末尾添加如下内容net.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbr 7.加载系统参数： 12345$ sysctl -pnet.ipv6.conf.all.accept_ra = 2net.ipv6.conf.eth0.accept_ra = 2net.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbr 如上，输出了我们添加的那两行配置代表正常。 8.确定bbr已经成功开启： 1234$ sysctl net.ipv4.tcp_available_congestion_controlnet.ipv4.tcp_available_congestion_control = bbr cubic reno$ lsmod | grep bbrtcp_bbr 20480 2 输出内容如上，则表示bbr已经成功开启。 相关文章 http://blog.51cto.com/zero01/2064660 https://github.com/shadowsocks/shadowsocks-libev https://www.jianshu.com/p/4984f324010f 原文链接（如需转载，请注明出处）http://blog.51cto.com/zero01/2064660]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>shadowsocks</tag>
        <tag>翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 客户端多账号管理]]></title>
    <url>%2F2018%2F02%2F25%2Fdocs%2F02-tools%2Fgit-multiple-accounts%2F</url>
    <content type="text"><![CDATA[前言在开发的过程中，经常会遇到这样的状况：需要在一台电脑上同时使用两个甚至多个 git 账号，负责不同的用途，比如：一个用来写个人项目，一个用来写公司的项目。为此我们需要为不同的账号生成不同的密钥，那对这些不同的账号和不同的密钥，我们该怎么处理呢？ SSH配置取消全局设置的用户名和邮箱12$ git config --global --unset user.name$ git config --global --unset user.email 生成私钥和公钥123456789101112131415$ cd ~/.ssh &amp;&amp; mkdir -pv &#123;github,company&#125;$ ssh-keygen -t rsa -C "youremail@example.com"Generating public/private rsa key pair.Enter file in which to save the key (/Users/Administrator/.ssh/id_rsa):/Users/Administrator/.ssh/github/id_rsa_github # 在回车提示中输入完整路径，如：/Users/Administrator/.ssh/github/id_rsa_github #文件命名后，按2次回车，密码为空 Enter passphrase (empty for no passphrase):Enter same passphrase again:$ ssh-keygen -t rsa -C "youremail@example.com"Generating public/private rsa key pair.Enter file in which to save the key (/Users/Administrator/.ssh/id_rsa):/Users/Administrator/.ssh/company/id_rsa_companyEnter passphrase (empty for no passphrase):Enter same passphrase again: 如果用户家目录中没有 .ssh 目录请自行创建在这里我创建了两个目录 github 和 company ，分别用来存储不同项目的密钥，进行分类管理 New SSH key 把 ~/.ssh/github/id_rsa_github.pub 的内容添加到Github的SSH keys中 把 ~/.ssh/company/id_rsa_company.pub 的内容添加到公司Gitlab的SSH keys中 新密钥添加到SSH agent中添加新密钥到SSH agent，因为默认只读取id_rsa，为了让SSH识别新的私钥，需将其添加到SSH agent中： 12$ ssh-add -K ~/.ssh/github/id_rsa_github$ ssh-add -K ~/.ssh/company/id_rsa_company 如果出现Could not open a connection to your authentication agent的错误，就试着用以下命令： 12$ ssh-agent bash$ ssh-add -K ~/.ssh/github/id_rsa_github 使用 ssh-add -l 查看 ssh key 的设置 修改 config 文件1234567891011121314151617181920$ vim ~/.ssh/configHost * KexAlgorithms +diffie-hellman-group1-sha1# default: myfirstHost github.com HostName github.com User myfirst PreferredAuthentications publickey IdentityFile ~/.ssh/github/id_rsa_github1# mysecondHost mysecond.github.com HostName github.com User mysecond PreferredAuthentications publickey IdentityFile ~/.ssh/github/id_rsa_github2Host company.com HostName company.com User company PreferredAuthentications publickey IdentityFile ~/.ssh/company/id_rsa_company 其规则就是：从上至下读取config的内容，在每个Host下寻找对应的私钥。这里将GitHub SSH仓库地址中的git@github.com替换成新建的Host别名如：mysecond.github.com，那么原地址是：git@github.com:test/Mywork.git，替换后应该是：mysecond.github.com:test/Mywork.git. 测试连通性123$ ssh -T git@github.comHi youremail! You've successfully authenticated, but GitHub does not provide shell access. 项目测试初始化项目a1234567891011121314$ cd ~/a$ git init$ echo "myfirst" &gt; README.md$ git add README.md$ git config user.name "myfirst"$ git config user.email "myfirst@gmail.com"$ git remote add github git@github.com:myfirst/test.git$ git push -u github masterCounting objects: 3, done.Writing objects: 100% (3/3), 213 bytes | 213.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:myfirst/test.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from github. 初始化项目b1234567891011121314$ cd ~/b$ git init$ echo "mysecond" &gt; README.md$ git add README.md$ git config user.name "mysecond"$ git config user.email "mysecond@gmail.com"$ git remote add github git@mysecond.github.com:mysecond/test.git$ git push -u github masterCounting objects: 3, done.Writing objects: 100% (3/3), 218 bytes | 218.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To mysecond.github.com:mysecond/test.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from github.]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Git</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homestead 下安装Swoole扩展]]></title>
    <url>%2F2018%2F02%2F21%2Fdocs%2F06-Linux%2Fphp-extension-swoole-install%2F</url>
    <content type="text"><![CDATA[前言尽管PHP软件源提供了不少PHP扩展，但并不是提供所有的扩展，那么如果我们需要安装一个软件源没有提供的扩展怎么办呢？利用 php-dev 就可以很方便的进行自行编译 PHP 扩展了，但是由于Homestaed内置了多个PHP版本，安装方式略有不同，不能简单粗暴的使用 pecl 安装了，因为安装好了不知道是给谁用的。下面分别介绍单一PHP和多版本PHP如何安装PHP扩展 注意：命令权限不够时请自动在命令前加上sudo前缀提权； 单一版本PHP安装 php-dev ，如果不是 7.2 需要自己修改一下版本号1$ apt install php7.2-dev 安装Swoole扩展1$ pecl install swoole 添加配置文件123$ cd /etc/php/7.2/fpm/conf.d$ touch swoole.ini$ echo "extension=swoole.so" | tee -a swoole.ini 重启php-fpm生效1$ systemctl restart php7.2-fpm 多PHP版本安装php-dev1$ apt install php5.6-dev php7.2-dev 下载swoole源码1234$ cd /usr/src$ wget http://pecl.php.net/get/swoole-1.9.15.tgz$ tar xzf swoole-1.9.15.tgz$ cd swoole-1.9.15 为PHP5.6进行编译1234$ cd /usr/src/swoole-1.9.15$ /usr/bin/phpize5.6$ ./configure --with-php-config=/usr/bin/php-config5.6$ make &amp;&amp; make install 为PHP7.2进行编译1234$ cd /usr/src/swoole-1.9.15$ /usr/bin/phpize7.2$ ./configure --with-php-config=/usr/bin/php-config7.2$ make &amp;&amp; make install 编译完成后扩展在module目录中，它的文件名是swoole.so 查看php的extension_dir1234$ php -i|grep extension_dirextension_dir =&gt; /usr/lib/php/20180731 =&gt; /usr/lib/php/20180731sqlite3.extension_dir =&gt; no value =&gt; no value 这里可以将php替换成指定版本，就可以查看指定版本的extension_dir 添加php配置文件12$ cd /etc/php/7.2/mods-available/$ sudo touch swoole.ini 添加以下内容 123; configuration for php swoole module; priorit=20extension=swoole.so 建立链接文件 123$ sudo ln -s /etc/php/7.0/mods-available/swoole.ini /etc/php/7.2/cli/conf.d/20-swoole.ini $ sudo ln -s /etc/php/7.0/mods-available/swoole.ini /etc/php/7.2/fpm/conf.d/20-swoole.ini 重启php-fpm1$ sudo service php7.2-fpm restart 将7.2替换成5.6为php56添加swoole扩展 同理，什么mongodb、redis的扩展等等，也都能够通过类似的方法完成安装 扩展：Homestead下修改cli模式下默认php版本我们通过命令 ll /usr/bin/php 可以看到，php是/etc/alternatives/php 建立的链接文件 1lrwxrwxrwx 1 root root 21 Feb 3 19:53 /usr/bin/php -&gt; /etc/alternatives/php 然后通过命令 ll /etc/alternatives/php 可以看到是通过 usr/bin/php7.0 建立的链接文件 1lrwxrwxrwx 1 root root 15 Feb 19 05:15 /etc/alternatives/php -&gt; /usr/bin/php7.2* 所以我们只要修改 /etc/alternatives/php 的源文件即可修改cli模式下php的默认版本，命令如下： 12$ sudo mv /etc/alternatives/php$ sudo ln -s /usr/bin/php7.0 /etc/alternatives/php]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>Linux</tag>
        <tag>Swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 RESTful API 设计的总结]]></title>
    <url>%2F2017%2F12%2F17%2Fdocs%2F09-pc-base%2Frestful-architecture%2F</url>
    <content type="text"><![CDATA[RESTful 是目前最流行的 API 设计规范，用于 Web 数据接口的设计。 为什么要用RESTfulRESTful 是一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。 RESTful 架构什么是RESTREST全称是Representational State Transfer，中文意思是表表现（编者注：通常译为表征）层状态转化。 它首次出现在2000年Roy Fielding的博士论文中，Roy Fielding是HTTP规范的主要编写者之一。 他在论文中提到：”我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。REST指的是一组架构约束条件和原则。” 如果一个架构符合REST的约束条件和原则，我们就称它为RESTful架构。 REST本身并没有创造新的技术、组件或服务，而隐藏在RESTful背后的理念就是使用Web的现有特征和能力， 更好地使用现有Web标准中的一些准则和约束。虽然REST本身受Web技术的影响很深， 但是理论上REST架构风格并不是绑定在HTTP上，只不过目前HTTP是唯一与REST相关的实例。 所以我们这里描述的REST也是通过HTTP实现的REST。 理解RESTful要理解 RESTful 架构，最好的方法就是去理解 Representational State Transfer 这个词组到底是什么意思，它的每一个词代表了什么涵义。如果把这个名称搞懂了，也就不难体会 REST 是一种什么样的设计。 资源 （Resources）REST 的名称 “表现层状态转化” 中，省略了主语。”表现层” 其实指的是 “资源”（Resources）的 “表现层”。 所谓 “资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个 URI（统一资源定位符）指向它，每种资源对应一个特定的 URI 。要获取这个资源，访问它的 URI 就可以，因此 URI 就成了每一个资源的地址或独一无二的识别符。所谓 “上网”，就是与互联网上一系列的 “资源” 互动，调用它的 URI 表现层（Representation）“资源” 是一种信息实体，它可以有多种外在表现形式。我们把 “资源” 具体呈现出来的形式，叫做它的 “表现层”（Representation）。比如，文本可以用 txt 格式表现，也可以用 HTML 格式、 XML 格式、JSON 格式表现，甚至可以采用二进制格式；图片可以用 JPG 格式表现，也可以用 PNG 格式表现。URI 只代表资源的实体，不代表它的形式。严格地说，有些网址最后的 “.html” 后缀名是不必要的，因为这个后缀名表示格式，属于 “表现层” 范畴，而 URI 应该只代表 “资源” 的位置。它的具体表现形式，应该在 HTTP 请求的头信息中用 Accept 和 Content-Type 字段指定，这两个字段才是对 “表现层” 的描述。 状态转化（State Transfer）访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。互联网通信协议 HTTP 协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生 “状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是 “表现层状态转化”。客户端用到的手段，只能是 HTTP 协议。具体来说，就是 HTTP 协议里面，四个表示操作方式的动词：GET 、 POST 、 PUT 、 DELETE 。 它们分别对应四种基本操作： GET 用来获取资源， POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。 综述 每一个 URI 代表一种资源 客户端和服务器之间，传递这种资源的某种表现层 客户端通过四个 HTTP 动词，对服务器端资源进行操作，实现 “表现层状态转化” RESTful API 的设计协议如果能全站 HTTPS 当然是最好的，不能的话也请尽量将登录、注册等涉及密码的接口使用 HTTPS。 域名应该尽量将 API 部署在专用域名之下。如： 1https://api.example.com 如果确定 API 很简单，不会有进一步扩展，可以考虑放在主域名下。 1https://example.org/api/ 版本号API 的版本号和客户端 APP 的版本号是毫无关系的，不要让 APP 将它们用于提交应用市场的版本号传递到服务器，而是提供类似于 v1、v2 之类的 API 版本号。 版本号拼接在 URL 中。如 1api.example.com/v1/users 或是放在 Header 中: 123api.example.com/usersversion=v1 请求一般来说 API 的外在形式无非就是增删改查（当然具体的业务逻辑肯定要复杂得多），而查询又分为详情和列表两种，在 RESTful 中这就相当于通用的模板。例如针对文章（Article）设计 API，那么最基础的 URL 就是这几种： GET /articles： 文章列表 GET /articles/id：文章详情 POST /articles/： 创建文章 PUT /articles/id：修改文章 DELETE /articles/id：删除文章 Token 和 SignAPI 需要设计成无状态，所以客户端在每次请求时都需要提供有效的 Token 和 Sign，在我看来它们的用途分别是： Token 用于证明请求所属的用户，一般都是服务端在登录后随机生成一段字符串（UUID）和登录用户进行绑定，再将其返回给客户端。Token 的状态保持一般有两种方式实现：一种是在用户每次操作都会延长或重置 TOKEN 的生存时间（类似于缓存的机制），另一种是 Token 的生存时间固定不变，但是同时返回一个刷新用的 Token，当 Token 过期时可以将其刷新而不是重新登录 Sign 用于证明该次请求合理，所以一般客户端会把请求参数拼接后并加密作为 Sign 传给服务端，这样即使被抓包了，对方只修改参数而无法生成对应的 Sign 也会被服务端识破。当然也可以将时间戳、请求地址和 Token 也混入 Sign，这样 Sign 也拥有了所属人、时效性和目的地 业务参数在 RESTful 的标准中，PUT 和 PATCH 都可以用于修改操作，它们的区别是 PUT 需要提交整个对象，而 PATCH 只需要提交修改的信息。但是在我看来实际应用中不需要这么麻烦，所以我一律使用 PUT，并且只提交修改的信息。 另一个问题是在 POST 创建对象时，究竟该用表单提交更好些还是用 JSON 提交更好些。其实两者都可以，在我看来它们唯一的区别是 JSON 可以比较方便的表示更为复杂的结构（有嵌套对象）。另外无论使用哪种，请保持统一，不要两者混用。 还有一个建议是最好将过滤、分页和排序的相关信息全权交给客户端，包括过滤条件、页数或是游标、每页的数量、排序方式、升降序等，这样可以使 API 更加灵活。但是对于过滤条件、排序方式等，不需要支持所有方式，只需要支持目前用得上的和以后可能会用上的方式即可，并通过字符串枚举解析，这样可见性要更好些。例如： 搜索，客户端只提供关键词，具体搜索的字段，和搜索方式（前缀、全文、精确）由服务端决定 1/users/?query=ScienJus 过滤，只需要对已有的情况进行支持： 1/users/?gender=1 分页： 1/users/?page=2&amp;per_page=20 响应尽量使用 HTTP 状态码，常用的有： 200：请求成功 201：创建、修改成功 204：删除成功 400：参数错误 401：未登录 403：禁止访问 404：未找到 500：系统错误 但是有些时候仅仅使用 HTTP 状态码没有办法明确的表达错误信息，所以也可以在里面再包一层自定义的返回码，例如： 12345678910&#123; &quot;code&quot;: 100, &quot;msg&quot;: &quot;成功&quot;, &quot;data&quot;: &#123;&#125;&#125;&#123; &quot;code&quot;: -1000, &quot;msg&quot;: &quot;用户名或密码错误&quot;&#125; data 是真正需要返回的数据，并且只会在请求成功时才存在，msg 只用在开发环境，并且只为了开发人员识别。客户端逻辑只允许识别 code，并且不允许直接将 msg 的内容展示给用户。如果这个错误很复杂，无法使用一段话描述清楚，也可以在添加一个 doc 字段，包含指向该错误的文档的链接。 返回数据JSON 比 XML 可视化更好，也更加节约流量，所以尽量不要使用 XML。 创建和修改操作成功后，需要返回该资源的全部信息。 返回数据不要和客户端界面强耦合，不要在设计 API 时就考虑少查询一张关联表或是少查询 / 返回几个字段能带来多大的性能提升。并且一定要以资源为单位，即使客户端一个页面需要展示多个资源，也不要在一个接口中全部返回，而是让客户端分别请求多个接口。 最好将返回数据进行加密和压缩，尤其是压缩在移动应用中还是比较重要的。 参考文章 http://www.ruanyifeng.com/blog/2011/09/restful.htmlhttps://www.runoob.com/w3cnote/restful-architecture.htmlhttp://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>RESTful</tag>
        <tag>REST</tag>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 自动加载原理解析]]></title>
    <url>%2F2017%2F10%2F21%2Fdocs%2F03-php%2Fphp-autoload%2F</url>
    <content type="text"><![CDATA[前言PHP 自5.3的版本之后，已经重焕新生，命名空间、性状（trait）、闭包、接口、PSR 规范、以及 composer 的出现已经让 PHP 变成了一门现代化的脚本语言。PHP 的生态系统也一直在演进，而 composer 的出现更是彻底的改变了以往构建 PHP 应用的方式，我们可以根据 PHP 的应用需求混合搭配最合适的 PHP 组件。当然这也得益于 PSR 规范的提出 PHP 自动加载功能PHP 自动加载功能的由来在 PHP 开发过程中，如果希望从外部引入一个 Class ，通常会使用 include 和 require 方法，去把定义这个 Class 的文件包含进来。这个在小规模开发的时候，没什么大问题。但在大型的开发项目中，使用这种方式会带来一些隐含的问题：如果一个 PHP 文件需要使用很多其它类，那么就需要很多的 require/include 语句，这样有可能会 造成遗漏 或者 包含进不必要的类文件。如果大量的文件都需要使用其它的类，那么要保证每个文件都包含正确的类文件肯定是一个噩梦， 况且 require或 incloud 的性能代价很大。 PHP5 为这个问题提供了一个解决方案，这就是 类的自动加载(autoload)机制。autoload机制 可以使得 PHP 程序有可能在使用类时才自动包含类文件，而不是一开始就将所有的类文件include进来，这种机制也称为 Lazy loading (惰性加载)。 自动加载功能的优点 使用类之前无需 include / require 使用类的时候才会 include / require 文件，实现了 lazy loading ，避免了 include / require 多余文件 无需考虑引入类的实际磁盘地址 ，实现了逻辑和实体文件的分离 PHP 自动加载函数 __autoload()从 PHP5 开始，当我们在使用一个类时，如果发现这个类没有加载，就会自动运行 __autoload() 函数，这个函数是我们在程序中自定义的，在这个函数中我们可以加载需要使用的类。下面是个简单的示例 12345&lt;?phpfunction __autoload($classname) &#123; require_once ($classname . ".class.php");&#125; 在我们这个简单的例子中，我们直接将类名加上扩展名 .class.php 构成了类文件名，然后使用 require_once 将其加载 从这个例子中，我们可以看出 __autoload 至少要做三件事情： 根据类名确定类文件名 确定类文件所在的磁盘路径 将类从磁盘文件中加载到系统中 第三步最简单，只需要使用 include / require 即可。要实现第一步，第二步的功能，必须在开发时约定类名与磁盘文件的映射方法，只有这样我们才能根据类名找到它对应的磁盘文件 当有大量的类文件要包含的时候，我们只要确定相应的规则，然后在 __autoload() 函数中，将类名与实际的磁盘文件对应起来，就可以实现 lazy loading 的效果 PHP autoload函数说明 __autoload() 函数存在的问题如果在一个系统的实现中，如果需要使用很多其它的类库，这些类库可能是由不同的开发人员编写的， 其类名与实际的磁盘文件的映射规则不尽相同。这时如果要实现类库文件的自动加载，就必须 在 __autoload() 函数中将所有的映射规则全部实现，这样的话 __autoload() 函数有可能会非常复杂，甚至无法实现。最后可能会导致 __autoload() 函数十分臃肿，这时即便能够实现，也会给将来的维护和系统效率带来很大的负面影响 那么问题出现在哪里呢？问题出现在 __autoload() 是全局函数只能定义一次 ，不够灵活，所以所有的类名与文件名对应的逻辑规则都要在一个函数里面实现，造成这个函数的臃肿。那么如何来解决这个问题呢？答案就是使用一个 __autoload调用堆栈 ，不同的映射关系写到不同的 __autoload函数 中去，然后统一注册统一管理，这个就是 PHP5 引入的 SPL Autoload 。 SPL AutoloadSPL是 Standard PHP Library(标准PHP库)的缩写。它是 PHP5 引入的一个扩展标准库，包括 spl autoload 相关的函数以及各种数据结构和迭代器的接口或类。spl autoload 相关的函数具体可见 php中spl_autoload 123456789101112131415161718192021222324252627282930313233343536&lt;?php// __autoload 函数//// function __autoload($class) &#123;// include 'classes/' . $class . '.class.php';// &#125;function my_autoloader($class) &#123; include 'classes/' . $class . '.class.php';&#125;spl_autoload_register('my_autoloader');// 定义的 autoload 函数在 class 里// 静态方法class MyClass &#123; public static function autoload($className) &#123; // ... &#125;&#125;spl_autoload_register(array('MyClass', 'autoload'));// 非静态方法class MyClass &#123; public function autoload($className) &#123; // ... &#125;&#125;$instance = new MyClass();spl_autoload_register(array($instance, 'autoload')); spl_autoload_register() 就是我们上面所说的__autoload调用堆栈，我们可以向这个函数注册多个我们自己的 autoload() 函数，当 PHP 找不到类名时，PHP就会调用这个堆栈，然后去调用自定义的 autoload() 函数，实现自动加载功能。如果我们不向这个函数输入任何参数，那么就会默认注册 spl_autoload() 函数。 PSR4 标准PSR-4 规范了如何指定文件路径从而自动加载类定义，同时规范了自动加载文件的位置。 一个完整的类名需具有以下结构 完整的类名必须要有一个顶级命名空间，被称为 “vendor namespace” 完整的类名可以有一个或多个子命名空间 完整的类名必须有一个最终的类名 完整的类名中任意一部分中的下滑线都是没有特殊含义的 完整的类名可以由任意大小写字母组成 所有类名都必须是大小写敏感的 根据完整的类名载入相应的文件 完整的类名中，去掉最前面的命名空间分隔符，前面连续的一个或多个命名空间和子命名空间，作为「命名空间前缀」，其必须与至少一个「文件基目录」相对应 紧接命名空间前缀后的子命名空间 必须 与相应的「文件基目录」相匹配，其中的命名空间分隔符将作为目录分隔符。 末尾的类名必须与对应的以 .php 为后缀的文件同名 自动加载器（autoloader）的实现一定不可抛出异常、一定不可触发任一级别的错误信息以及不应该有返回值 例子PSR-4风格 1234类名：ZendAbc 命名空间前缀：Zend 文件基目录：/usr/includes/Zend/ 文件路径：/usr/includes/Zend/Abc.php 1234类名：SymfonyCoreRequest 命名空间前缀：SymfonyCore 文件基目录：./vendor/Symfony/Core/ 文件路径：./vendor/Symfony/Core/Request.php 目录结构 1234567-vendor/| -vendor_name/| | -package_name/| | | -src/| | | | -ClassName.php # Vendor_Name\Package_Name\ClassName| | | -tests/| | | | -ClassNameTest.php # Vendor_Name\Package_Name\ClassNameTest Composer 自动加载过程Composer 做了哪些事情 你有一个项目依赖于若干个库。 其中一些库依赖于其他库。 你声明你所依赖的东西。 Composer 会找出哪个版本的包需要安装，并安装它们（将它们下载到你的项目中）。 例如，你正在创建一个项目，需要做一些单元测试。你决定使用 phpunit 。为了将它添加到你的项目中，你所需要做的就是在 composer.json 文件里描述项目的依赖关系。 12345&#123; "require": &#123; "phpunit/phpunit":"~6.0", &#125; &#125; 然后在 composer require 之后我们只要在项目里面直接 use phpunit 的类即可使用。 执行 composer require 时发生了什么 composer 会找到符合 PR4 规范的第三方库的源 将其加载到 vendor 目录下 初始化顶级域名的映射并写入到指定的文件里 如：&#39;PHPUnit\\Framework\\Assert&#39; =&gt; __DIR__ . &#39;/..&#39; . &#39;/phpunit/phpunit/src/Framework/Assert.php&#39; 写好一个 autoload 函数，并且注册到 spl_autoload_register()里 题外话：现在很多框架都已经帮我们写好了顶级域名映射了，我们只需要在框架里面新建文件，在新建的文件中写好命名空间，就可以在任何地方 use 我们的命名空间了 Composer 源码分析下面我们通过对源码的分析来看看 composer 是如何实现 PSR4标准 的自动加载功能。 很多框架在初始化的时候都会引入 composer 来协助自动加载的，以 Laravel 为例，它入口文件 index.php 第一句就是利用 composer 来实现自动加载功能 启动1234&lt;?php define('LARAVEL_START', microtime(true)); require __DIR__ . '/../vendor/autoload.php'; 去 vendor 目录下的 autoload.php ： 1234567&lt;?php// autoload.php @generated by Composerrequire_once __DIR__ . '/composer/autoload_real.php';return ComposerAutoloaderInit6ed409f9f3791196a1d5a1f407fb5184::getLoader(); 这里就是 Composer 真正开始的地方了 Composer自动加载文件Composer自动加载所用到的源文件。 autoload_real.php: 自动加载功能的引导类 composer 加载类的初始化(顶级命名空间与文件路径映射初始化)和注册(spl_autoload_register()) ClassLoader.php : composer 加载类 composer 自动加载功能的核心类 autoload_static.php : 顶级命名空间初始化类 用于给核心类初始化顶级命名空间 autoload_classmap.php : 自动加载的最简单形式 有完整的命名空间和文件目录的映射 autoload_files.php : 用于加载全局函数的文件 存放各个全局函数所在的文件路径名 autoload_namespaces.php : 符合 PSR0 标准的自动加载文件 存放着顶级命名空间与文件的映射 autoload_psr4.php : 符合 PSR4 标准的自动加载文件 存放着顶级命名空间与文件的映射 autoload_real 引导类在 vendor 目录下的 autoload.php 文件中我们可以看出，程序主要调用了引导类的静态方法 getLoader() ，我们接着看看这个函数 自动加载引导类分为 5 个部分。 第一部分——单例第一部分很简单，就是个最经典的单例模式，自动加载类只能有一个。 1234&lt;?php if (null !== self::$loader) &#123; return self::$loader; &#125; 第二部分——构造ClassLoader核心类第二部分 new 一个自动加载的核心类对象。 1234567891011&lt;?php /***********************获得自动加载核心类对象********************/ spl_autoload_register( array('ComposerAutoloaderInit7b790917ce8899df9af8ed53631a1c29', 'loadClassLoader'), true, true ); self::$loader = $loader = new \Composer\Autoload\ClassLoader(); spl_autoload_unregister( array('ComposerAutoloaderInit7b790917ce8899df9af8ed53631a1c29', 'loadClassLoader') ); 1234567&lt;?phppublic static function loadClassLoader($class)&#123; if ('Composer\Autoload\ClassLoader' === $class) &#123; require __DIR__ . '/ClassLoader.php'; &#125;&#125; 从程序里面我们可以看出，composer 先向 PHP 自动加载机制注册了一个函数，这个函数 require 了 ClassLoader 文件。成功 new 出该文件中核心类 ClassLoader() 后，又销毁了该函数 第三部分 —— 初始化核心类对象12345678910111213141516171819202122232425&lt;?php /***********************初始化自动加载核心类对象********************/ $useStaticLoader = PHP_VERSION_ID &gt;= 50600 &amp;&amp; !defined('HHVM_VERSION'); if ($useStaticLoader) &#123; require_once __DIR__ . '/autoload_static.php'; call_user_func( \Composer\Autoload\ComposerStaticInit7b790917ce8899df9af8ed53631a1c29::getInitializer($loader) ); &#125; else &#123; $map = require __DIR__ . '/autoload_namespaces.php'; foreach ($map as $namespace =&gt; $path) &#123; $loader-&gt;set($namespace, $path); &#125; $map = require __DIR__ . '/autoload_psr4.php'; foreach ($map as $namespace =&gt; $path) &#123; $loader-&gt;setPsr4($namespace, $path); &#125; $classMap = require __DIR__ . '/autoload_classmap.php'; if ($classMap) &#123; $loader-&gt;addClassMap($classMap); &#125; &#125; 这一部分就是对自动加载类的初始化，主要是给自动加载核心类初始化顶级命名空间映射。 初始化的方法有两种： 使用 autoload_static 进行静态初始化 调用核心类接口初始化 autoload_static 静态初始化 ( PHP &gt;= 5.6 )静态初始化只支持 PHP5.6 以上版本并且不支持 HHVM 虚拟机。我们深入 autoload_static.php 这个文件发现这个文件定义了一个用于静态初始化的类，名字叫 ComposerStaticInit7b790917ce8899df9af8ed53631a1c29，仍然为了避免冲突而加了 hash 值。这个类很简单 12345678910111213141516171819&lt;?php class ComposerStaticInit7b790917ce8899df9af8ed53631a1c29&#123; public static $files = array(...); public static $prefixLengthsPsr4 = array(...); public static $prefixDirsPsr4 = array(...); public static $prefixesPsr0 = array(...); public static $classMap = array (...); public static function getInitializer(ClassLoader $loader) &#123; return \Closure::bind(function () use ($loader) &#123; $loader-&gt;prefixLengthsPsr4 = ComposerStaticInit6ed409f9f3791196a1d5a1f407fb5184::$prefixLengthsPsr4; $loader-&gt;prefixDirsPsr4 = ComposerStaticInit6ed409f9f3791196a1d5a1f407fb5184::$prefixDirsPsr4; $loader-&gt;prefixesPsr0 = ComposerStaticInit6ed409f9f3791196a1d5a1f407fb5184::$prefixesPsr0; $loader-&gt;classMap = ComposerStaticInit6ed409f9f3791196a1d5a1f407fb5184::$classMap; &#125;, null, ClassLoader::class); &#125; &#125; 这个静态初始化类的核心就是 getInitializer() 函数，它将自己类中的顶级命名空间映射给了 ClassLoader 类。值得注意的是这个函数返回的是一个匿名函数，为什么呢？原因就是 ClassLoader类 中的 prefixLengthsPsr4 、prefixDirsPsr4等等变量都是 private的。利用匿名函数的绑定功能就可以将这些 private 变量赋给 ClassLoader 类 里的成员变量。 classMap（命名空间映射）1234567891011121314151617&lt;?php public static $classMap = array ( 'App\\Console\\Kernel' =&gt; __DIR__ . '/../..' . '/app/Console/Kernel.php', 'App\\Exceptions\\Handler' =&gt; __DIR__ . '/../..' . '/app/Exceptions/Handler.php', 'App\\Http\\Controllers\\Auth\\ForgotPasswordController' =&gt; __DIR__ . '/../..' . '/app/Http/Controllers/Auth/ForgotPasswordController.php', 'App\\Http\\Controllers\\Auth\\LoginController' =&gt; __DIR__ . '/../..' . '/app/Http/Controllers/Auth/LoginController.php', 'App\\Http\\Controllers\\Auth\\RegisterController' =&gt; __DIR__ . '/../..' . '/app/Http/Controllers/Auth/RegisterController.php', ...) 直接命名空间全名与目录的映射，简单粗暴，也导致这个数组相当的大 PSR4 标准顶级命名空间映射数组1234567891011121314151617181920212223242526&lt;?php public static $prefixLengthsPsr4 = array( 'p' =&gt; array ( 'phpDocumentor\\Reflection\\' =&gt; 25, ), 'S' =&gt; array ( 'Symfony\\Polyfill\\Mbstring\\' =&gt; 26, 'Symfony\\Component\\Yaml\\' =&gt; 23, 'Symfony\\Component\\VarDumper\\' =&gt; 28, ... ), ...); public static $prefixDirsPsr4 = array ( 'phpDocumentor\\Reflection\\' =&gt; array ( 0 =&gt; __DIR__ . '/..' . '/phpdocumentor/reflection-common/src', 1 =&gt; __DIR__ . '/..' . '/phpdocumentor/type-resolver/src', 2 =&gt; __DIR__ . '/..' . '/phpdocumentor/reflection-docblock/src', ), 'Symfony\\Polyfill\\Mbstring\\' =&gt; array ( 0 =&gt; __DIR__ . '/..' . '/symfony/polyfill-mbstring', ), 'Symfony\\Component\\Yaml\\' =&gt; array ( 0 =&gt; __DIR__ . '/..' . '/symfony/yaml', ), ...) PSR4 标准顶级命名空间映射用了两个数组，第一个是用命名空间第一个字母作为前缀索引，然后是 顶级命名空间，但是最终并不是文件路径，而是 顶级命名空间的长度。为什么呢？ 因为 PSR4 标准是用顶级命名空间目录替换顶级命名空间，所以获得顶级命名空间的长度很重要。 具体说明这些数组的作用： 假如我们找 Symfony\Polyfill\Mbstring\example 这个命名空间，通过前缀索引和字符串匹配我们得到了 12&lt;?php 'Symfony\\Polyfill\\Mbstring\\' =&gt; 26, 这条记录，键是顶级命名空间，值是命名空间的长度。拿到顶级命名空间后去 $prefixDirsPsr4数组 获取它的映射目录数组：(注意映射目录可能不止一条) 1234&lt;?php 'Symfony\\Polyfill\\Mbstring\\' =&gt; array ( 0 =&gt; __DIR__ . '/..' . '/symfony/polyfill-mbstring', ) 然后我们就可以将命名空间 Symfony\Polyfill\Mbstring\example 前26个字符替换成目录 DIR . ‘/..’ . ‘/symfony/polyfill-mbstring ，我们就得到了DIR . ‘/..’ . ‘/symfony/polyfill-mbstring/example.php，先验证磁盘上这个文件是否存在，如果不存在接着遍历。如果遍历后没有找到，则加载失败。 ClassLoader 接口初始化（ PHP &lt; 5.6 ）如果PHP版本低于 5.6 或者使用 HHVM 虚拟机环境，那么就要使用核心类的接口进行初始化。 1234567891011121314151617&lt;?php // PSR0 标准 $map = require __DIR__ . '/autoload_namespaces.php'; foreach ($map as $namespace =&gt; $path) &#123; $loader-&gt;set($namespace, $path); &#125; // PSR4 标准 $map = require __DIR__ . '/autoload_psr4.php'; foreach ($map as $namespace =&gt; $path) &#123; $loader-&gt;setPsr4($namespace, $path); &#125; $classMap = require __DIR__ . '/autoload_classmap.php'; if ($classMap) &#123; $loader-&gt;addClassMap($classMap); &#125; PSR4 标准的映射autoload_psr4.php 的顶级命名空间映射 123456789101112131415161718&lt;?php return array( 'XdgBaseDir\\' =&gt; array($vendorDir . '/dnoegel/php-xdg-base-dir/src'), 'Webmozart\\Assert\\' =&gt; array($vendorDir . '/webmozart/assert/src'), 'TijsVerkoyen\\CssToInlineStyles\\' =&gt; array($vendorDir . '/tijsverkoyen/css-to-inline-styles/src'), 'Tests\\' =&gt; array($baseDir . '/tests'), 'Symfony\\Polyfill\\Mbstring\\' =&gt; array($vendorDir . '/symfony/polyfill-mbstring'), ... ) PSR4 标准的初始化接口: 12345678910111213141516&lt;?php public function setPsr4($prefix, $paths) &#123; if (!$prefix) &#123; $this-&gt;fallbackDirsPsr4 = (array) $paths; &#125; else &#123; $length = strlen($prefix); if ('\\' !== $prefix[$length - 1]) &#123; throw new \InvalidArgumentException( "A non-empty PSR-4 prefix must end with a namespace separator." ); &#125; $this-&gt;prefixLengthsPsr4[$prefix[0]][$prefix] = $length; $this-&gt;prefixDirsPsr4[$prefix] = (array) $paths; &#125; &#125; 总结下上面的顶级命名空间映射过程： 12( 前缀 -&gt; 顶级命名空间，顶级命名空间 -&gt; 顶级命名空间长度 )( 顶级命名空间 -&gt; 目录 ) 这两个映射数组。具体形式也可以查看下面的 autoload_static 的 $prefixLengthsPsr4 、 $prefixDirsPsr4 。 命名空间映射autoload_classmap 123456789&lt;?phppublic static $classMap = array ( 'App\\Console\\Kernel' =&gt; __DIR__ . '/../..' . '/app/Console/Kernel.php', 'App\\Exceptions\\Handler' =&gt; __DIR__ . '/../..' . '/app/Exceptions/Handler.php', ...) addClassMap 123456789&lt;?php public function addClassMap(array $classMap) &#123; if ($this-&gt;classMap) &#123; $this-&gt;classMap = array_merge($this-&gt;classMap, $classMap); &#125; else &#123; $this-&gt;classMap = $classMap; &#125; &#125; 自动加载核心类 ClassLoader 的静态初始化到这里就完成了！ 其实说是5部分，真正重要的就两部分——初始化与注册。初始化负责顶层命名空间的目录映射，注册负责实现顶层以下的命名空间映射规则 第四部分 —— 注册讲完了 Composer 自动加载功能的启动与初始化，经过启动与初始化，自动加载核心类对象已经获得了顶级命名空间与相应目录的映射，也就是说，如果有命名空间 App\Console\Kernel，我们已经可以找到它对应的类文件所在位置。那么，它是什么时候被触发去找的呢？ 现在我们开始引导类的第四部分：注册自动加载核心类对象。我们来看看核心类的 register() 函数： 1234public function register($prepend = false)&#123; spl_autoload_register(array($this, 'loadClass'), true, $prepend);&#125; 其实奥秘都在自动加载核心类 ClassLoader 的 loadClass() 函数上： 12345678public function loadClass($class) &#123; if ($file = $this-&gt;findFile($class)) &#123; includeFile($file); return true; &#125; &#125; 这个函数负责按照 PSR 标准将顶层命名空间以下的内容转为对应的目录，也就是上面所说的将 ‘App\Console\Kernel 中’ Console\Kernel 这一段转为目录，至于怎么转的在下面 “运行”的部分讲。核心类 ClassLoader 将 loadClass() 函数注册到PHP SPL中的 spl_autoload_register() 里面去。这样，每当PHP遇到一个不认识的命名空间的时候，PHP会自动调用注册到 spl_autoload_register 里面的 loadClass() 函数，然后找到命名空间对应的文件 全局函数的自动加载Composer 不止可以自动加载命名空间，还可以加载全局函数。怎么实现的呢？把全局函数写到特定的文件里面去，在程序运行前挨个 require就行了。这个就是 composer 自动加载的第五步，加载全局函数。 12345678if ($useStaticLoader) &#123; $includeFiles = Composer\Autoload\ComposerStaticInit7b790917ce8899df9af8ed53631a1c29::$files;&#125; else &#123; $includeFiles = require __DIR__ . '/autoload_files.php';&#125;foreach ($includeFiles as $fileIdentifier =&gt; $file) &#123; composerRequire7b790917ce8899df9af8ed53631a1c29($fileIdentifier, $file);&#125; 跟核心类的初始化一样，全局函数自动加载也分为两种：静态初始化和普通初始化，静态加载只支持PHP5.6以上并且不支持HHVM。 静态初始化：ComposerStaticInit7b790917ce8899df9af8ed53631a1c29::$files： 12345public static $files = array ('0e6d7bf4a5811bfa5cf40c5ccd6fae6a' =&gt; __DIR__ . '/..' . '/symfony/polyfill-mbstring/bootstrap.php','667aeda72477189d0494fecd327c3641' =&gt; __DIR__ . '/..' . '/symfony/var-dumper/Resources/functions/dump.php',...); 普通初始化autoload_files: 12345678$vendorDir = dirname(dirname(__FILE__));$baseDir = dirname($vendorDir); return array('0e6d7bf4a5811bfa5cf40c5ccd6fae6a' =&gt; $vendorDir . '/symfony/polyfill-mbstring/bootstrap.php','667aeda72477189d0494fecd327c3641' =&gt; $vendorDir . '/symfony/var-dumper/Resources/functions/dump.php', ....); 其实跟静态初始化区别不大。 加载全局函数123456789101112131415161718class ComposerAutoloaderInit7b790917ce8899df9af8ed53631a1c29&#123; public static function getLoader()&#123; ... foreach ($includeFiles as $fileIdentifier =&gt; $file) &#123; composerRequire7b790917ce8899df9af8ed53631a1c29($fileIdentifier, $file); &#125; ... &#125;&#125;function composerRequire7b790917ce8899df9af8ed53631a1c29($fileIdentifier, $file) &#123; if (empty(\$GLOBALS['__composer_autoload_files'][\$fileIdentifier])) &#123; require $file; $GLOBALS['__composer_autoload_files'][$fileIdentifier] = true; &#125;&#125; 第五部分 —— 运行到这里，终于来到了核心的核心—— composer 自动加载的真相，命名空间如何通过 composer 转为对应目录文件的奥秘就在这一章。前面说过，ClassLoader 的 register() 函数将 loadClass() 函数注册到 PHP 的 SPL 函数堆栈中，每当 PHP 遇到不认识的命名空间时就会调用函数堆栈的每个函数，直到加载命名空间成功。所以 loadClass() 函数就是自动加载的关键了。 看下 loadClass() 函数: 1234567891011121314151617181920212223242526272829303132333435363738public function loadClass($class)&#123; if ($file = $this-&gt;findFile($class)) &#123; includeFile($file); return true; &#125;&#125;public function findFile($class)&#123; // work around for PHP 5.3.0 - 5.3.2 https://bugs.php.net/50731 if ('\\' == $class[0]) &#123; $class = substr($class, 1); &#125; // class map lookup if (isset($this-&gt;classMap[$class])) &#123; return $this-&gt;classMap[$class]; &#125; if ($this-&gt;classMapAuthoritative) &#123; return false; &#125; $file = $this-&gt;findFileWithExtension($class, '.php'); // Search for Hack files if we are running on HHVM if ($file === null &amp;&amp; defined('HHVM_VERSION')) &#123; $file = $this-&gt;findFileWithExtension($class, '.hh'); &#125; if ($file === null) &#123; // Remember that this class does not exist. return $this-&gt;classMap[$class] = false; &#125; return $file;&#125; 我们看到 loadClass() ，主要调用 findFile() 函数。findFile() 在解析命名空间的时候主要分为两部分：classMap 和 findFileWithExtension() 函数。classMap 很简单，直接看命名空间是否在映射数组中即可。麻烦的是 findFileWithExtension() 函数，这个函数包含了 PSR0 和 PSR4 标准的实现。还有个值得我们注意的是查找路径成功后 includeFile() 仍然是外面的函数，并不是 ClassLoader 的成员函数，原理跟上面一样，防止有用户写 $this 或 self。还有就是如果命名空间是以\开头的，要去掉\然后再匹配。 看下 findFileWithExtension 函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private function findFileWithExtension($class, $ext)&#123; // PSR-4 lookup $logicalPathPsr4 = strtr($class, '\\', DIRECTORY_SEPARATOR) . $ext; $first = $class[0]; if (isset($this-&gt;prefixLengthsPsr4[$first])) &#123; foreach ($this-&gt;prefixLengthsPsr4[$first] as $prefix =&gt; $length) &#123; if (0 === strpos($class, $prefix)) &#123; foreach ($this-&gt;prefixDirsPsr4[$prefix] as $dir) &#123; if (file_exists($file = $dir . DIRECTORY_SEPARATOR . substr($logicalPathPsr4, $length))) &#123; return $file; &#125; &#125; &#125; &#125; &#125; // PSR-4 fallback dirs foreach ($this-&gt;fallbackDirsPsr4 as $dir) &#123; if (file_exists($file = $dir . DIRECTORY_SEPARATOR . $logicalPathPsr4)) &#123; return $file; &#125; &#125; // PSR-0 lookup if (false !== $pos = strrpos($class, '\\')) &#123; // namespaced class name $logicalPathPsr0 = substr($logicalPathPsr4, 0, $pos + 1) . strtr(substr($logicalPathPsr4, $pos + 1), '_', DIRECTORY_SEPARATOR); &#125; else &#123; // PEAR-like class name $logicalPathPsr0 = strtr($class, '_', DIRECTORY_SEPARATOR) . $ext; &#125; if (isset($this-&gt;prefixesPsr0[$first])) &#123; foreach ($this-&gt;prefixesPsr0[$first] as $prefix =&gt; $dirs) &#123; if (0 === strpos($class, $prefix)) &#123; foreach ($dirs as $dir) &#123; if (file_exists($file = $dir . DIRECTORY_SEPARATOR . $logicalPathPsr0)) &#123; return $file; &#125; &#125; &#125; &#125; &#125; // PSR-0 fallback dirs foreach ($this-&gt;fallbackDirsPsr0 as $dir) &#123; if (file_exists($file = $dir . DIRECTORY_SEPARATOR . $logicalPathPsr0)) &#123; return $file; &#125; &#125; // PSR-0 include paths. if ($this-&gt;useIncludePath &amp;&amp; $file = stream_resolve_include_path($logicalPathPsr0)) &#123; return $file; &#125;&#125; 最后小结我们通过举例来说下上面代码的流程： 如果我们在代码中写下 new phpDocumentor\Reflection\Element()，PHP 会通过 SPL_autoload_register 调用 loadClass -&gt; findFile -&gt; findFileWithExtension。步骤如下： 将 \ 转为文件分隔符/，加上后缀php，变成 $logicalPathPsr4, 即 phpDocumentor/Reflection//Element.php; 利用命名空间第一个字母p作为前缀索引搜索 prefixLengthsPsr4 数组，查到下面这个数组： 12345p&apos; =&gt; array ( &apos;phpDocumentor\\Reflection\\&apos; =&gt; 25, &apos;phpDocumentor\\Fake\\&apos; =&gt; 19, ) 遍历这个数组，得到两个顶层命名空间 phpDocumentor\Reflection\ 和 phpDocumentor\Fake\ 在这个数组中查找 phpDocumentor\Reflection\Element，找出 phpDocumentor\Reflection\ 这个顶层命名空间并且长度为25。 在prefixDirsPsr4 映射数组中得到phpDocumentor\Reflection\ 的目录映射为： 123456&apos;phpDocumentor\\Reflection\\&apos; =&gt; array ( 0 =&gt; __DIR__ . &apos;/..&apos; . &apos;/phpdocumentor/reflection-common/src&apos;, 1 =&gt; __DIR__ . &apos;/..&apos; . &apos;/phpdocumentor/type-resolver/src&apos;, 2 =&gt; __DIR__ . &apos;/..&apos; . &apos;/phpdocumentor/reflection-docblock/src&apos;, ), 遍历这个映射数组，得到三个目录映射； 查看 “目录+文件分隔符//+substr(&dollar;logicalPathPsr4, &dollar;length)”文件是否存在，存在即返回。这里就是‘DIR/../phpdocumentor/reflection-common/src + substr(phpDocumentor/Reflection/Element.php,25)’ 如果失败，则利用 fallbackDirsPsr4 数组里面的目录继续判断是否存在文件 以上就是 composer 自动加载的原理解析]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>自动加载</tag>
        <tag>PSR4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转）PHP 7 新特性]]></title>
    <url>%2F2017%2F08%2F21%2Fdocs%2F03-php%2Fphp7-new-features%2F</url>
    <content type="text"><![CDATA[标量类型声明PHP 7 中的函数的形参类型声明可以是标量了。在 PHP 5 中只能是类名、接口、array 或者 callable (PHP 5.4，即可以是函数，包括匿名函数)，现在也可以使用 string、int、float和 bool 了。 12345678&lt;?php// 强制模式function sumOfInts(int ...$ints)&#123; return array_sum($ints);&#125;var_dump(sumOfInts(2, '3', 4.1)); 以上实例会输出： 1int(9) 需要注意的是上文提到的严格模式的问题在这里同样适用：强制模式（默认，既强制类型转换）下还是会对不符合预期的参数进行强制类型转换，严格模式下则触发 TypeError 的致命错误。 返回值类型声明PHP 7 增加了对返回类型声明的支持。 类似于参数类型声明，返回类型声明指明了函数返回值的类型。可用的类型与参数声明中可用的类型相同。 12345678910&lt;?phpfunction arraysSum(array ...$arrays): array&#123; return array_map(function(array $array): int &#123; return array_sum($array); &#125;, $arrays);&#125;print_r(arraysSum([1,2,3], [4,5,6], [7,8,9])); 以上实例会输出： 123456Array( [0] =&gt; 6 [1] =&gt; 15 [2] =&gt; 24) NULL 合并运算符由于日常使用中存在大量同时使用三元表达式和 isset()的情况，NULL 合并运算符使得变量存在且值不为NULL， 它就会返回自身的值，否则返回它的第二个操作数。 实例如下 12345&lt;?php// 如果 $_GET['user'] 不存在返回 'nobody'，否则返回 $_GET['user'] 的值$username = $_GET['user'] ?? 'nobody';// 类似的三元运算符$username = isset($_GET['user']) ? $_GET['user'] : 'nobody'; 太空船操作符（组合比较符）太空船操作符用于比较两个表达式。当$a大于、等于或小于$b时它分别返回-1、0或1。 实例如下 123456789101112131415&lt;?php// 整型echo 1 &lt;=&gt; 1; // 0echo 1 &lt;=&gt; 2; // -1echo 2 &lt;=&gt; 1; // 1// 浮点型echo 1.5 &lt;=&gt; 1.5; // 0echo 1.5 &lt;=&gt; 2.5; // -1echo 2.5 &lt;=&gt; 1.5; // 1 // 字符串echo "a" &lt;=&gt; "a"; // 0echo "a" &lt;=&gt; "b"; // -1echo "b" &lt;=&gt; "a"; // 1 通过 define() 定义常量数组实例如下： 12345678&lt;?phpdefine('ANIMALS', [ 'dog', 'cat', 'bird']);echo ANIMALS[1]; // 输出 "cat" 匿名类现在支持通过new class 来实例化一个匿名类，实例如下： 12345678910111213141516171819202122232425&lt;?phpinterface Logger &#123; public function log(string $msg);&#125;class Application &#123; private $logger; public function getLogger(): Logger &#123; return $this-&gt;logger; &#125; public function setLogger(Logger $logger) &#123; $this-&gt;logger = $logger; &#125;&#125;$app = new Application;$app-&gt;setLogger(new class implements Logger &#123; public function log(string $msg) &#123; echo $msg; &#125;&#125;);var_dump($app-&gt;getLogger()); 以上实例会输出： 12object(class@anonymous)#2 (0) &#123;&#125; Unicode codepoint 转译语法这接受一个以16进制形式的 Unicode codepoint，并打印出一个双引号或heredoc包围的 UTF-8 编码格式的字符串。 可以接受任何有效的 codepoint，并且开头的 0 是可以省略的。 123echo "\u&#123;aa&#125;";echo "\u&#123;0000aa&#125;";echo "\u&#123;9999&#125;"; 以上实例会输出： 123ªª (same as before but with optional leading 0's)香 Closure::call()Closure::call() 现在有着更好的性能，简短干练的暂时绑定一个方法到对象上闭包并调用它。 1234567891011&lt;?phpclass A &#123;private $x = 1;&#125;// Pre PHP 7 代码$getXCB = function() &#123;return $this-&gt;x;&#125;;$getX = $getXCB-&gt;bindTo(new A, 'A'); // intermediate closureecho $getX();// PHP 7+ 代码$getX = function() &#123;return $this-&gt;x;&#125;;echo $getX-&gt;call(new A); 以上实例会输出： 1211 为unserialize()提供过滤这个特性旨在提供更安全的方式解包不可靠的数据。它通过白名单的方式来防止潜在的代码注入。 12345678910&lt;?php// 转换对象为 __PHP_Incomplete_Class 对象$data = unserialize($foo, ["allowed_classes" =&gt; false]);// 转换对象为 __PHP_Incomplete_Class 对象，除了 MyClass 和 MyClass2$data = unserialize($foo, ["allowed_classes" =&gt; ["MyClass", "MyClass2"]);// 默认接受所有类$data = unserialize($foo, ["allowed_classes" =&gt; true]); IntlChar新增加的 IntlChar 类旨在暴露出更多的 ICU 功能。这个类自身定义了许多静态方法用于操作多字符集的 unicode 字符。 1234&lt;?phpprintf('%x', IntlChar::CODEPOINT_MAX);echo IntlChar::charName('@');var_dump(IntlChar::ispunct('!')); 以上实例会输出： 12310ffffCOMMERCIAL ATbool(true) 若要使用此类，请先安装Intl扩展 预期预期是向后兼用并增强之前的 assert() 的方法。 它使得在生产环境中启用断言为零成本，并且提供当断言失败时抛出特定异常的能力。 123456&lt;?phpini_set('assert.exception', 1);class CustomError extends AssertionError &#123;&#125;assert(false, new CustomError('Some error message')); 以上实例会输出： 1Fatal error: Uncaught CustomError: Some error message use 加强从同一 namespace 导入的类、函数和常量现在可以通过单个 use 语句 一次性导入了。 12345678910111213141516171819&lt;?php// PHP 7 之前版本用法use some\namespace\ClassA;use some\namespace\ClassB;use some\namespace\ClassC as C;use function some\namespace\fn_a;use function some\namespace\fn_b;use function some\namespace\fn_c;use const some\namespace\ConstA;use const some\namespace\ConstB;use const some\namespace\ConstC;// PHP 7+ 用法use some\namespace\&#123;ClassA, ClassB, ClassC as C&#125;;use function some\namespace\&#123;fn_a, fn_b, fn_c&#125;;use const some\namespace\&#123;ConstA, ConstB, ConstC&#125;; Generator 加强增强了Generator的功能，这个可以实现很多先进的特性 1234567891011121314151617181920212223&lt;?php&lt;?phpfunction gen()&#123; yield 1; yield 2; yield from gen2();&#125;function gen2()&#123; yield 3; yield 4;&#125;foreach (gen() as $val)&#123; echo $val, PHP_EOL;&#125;?&gt; 以上实例会输出： 12341234 整除新增了整除函数 intdiv(),使用实例： 12&lt;?phpvar_dump(intdiv(10, 3)); 以上实例会输出： 1int(3) 更多内容可以参考：http://www.runoob.com/php/php7-new-features.html。原文地址：https://www.runoob.com/w3cnote/php7-new-features.html]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>PHP7</tag>
        <tag>新特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 分片]]></title>
    <url>%2F2017%2F06%2F14%2Fdocs%2F05-nosql%2Fmongodb-sharding%2F</url>
    <content type="text"><![CDATA[简介在Mongodb里面存在另一种集群，就是分片技术,可以满足MongoDB数据量大量增长的需求。当MongoDB存储海量的数据时，一台机器可能不足以存储数据，也可能不足以提供可接受的读写吞吐量。这时，我们就可以通过在多台机器上分割数据，使得数据库系统能存储和处理更多的数据。 为什么使用片 复制所有的写入操作到主节点 延迟的敏感数据会在主节点查询 单个副本集限制在12个节点 当请求量巨大时会出现内存不足。 本地磁盘不足 垂直扩展价格昂贵 MongoDB分片集群组成MongoDB分片群集主要有如下三个主要组件： Shard：分片服务器，用于存储实际的数据块，实际生产环境中一个shard server角色可由几台服务器组成一个Replica Set 承担，防止主机节点故障。 Config Server：配置服务器，存储了整个分片群集的配置信息，其中包括chunk信息。 Routers：前端路由，客户端由此接入，且让整个群集看上去像单一数据库，前端应用可以透明使用。 下图展示了在MongoDB中使用分片集群结构分布： 分片集群的简单配置在这里在一台物理服务器上部署一个简单结构的MongoDB分片集群： 1台路由实例（端口27017）1台配置实例（端口37017）3台Shard实例（端口47017、47018、47019） 安装Mongodb具体安装参考MongoDB 基础教程 123456$ mkdir -p /usr/local/mongodb/data/db&#123;1,2,3,4&#125; # 创建数据存储目录 $ mkdir /usr/local/mongodb/data/logs # 创建日志文件存储目录 $ touch /usr/local/mongodb/data/logs/mongodb&#123;1,2,3,4&#125;.log # 创建日志文件 $ chmod -R 777 /usr/local/mongodb/data/logs/*.log $ ulimit -n 25000 # 最多打开文件个数，重启后失效 $ ulimit -u 25000 # 最多打开进程数，重启后失效 配置服务器123$ cd /usr/local/mongodb/data$ mkdir conf$ vim mongodb1.conf 12345678port=37017 # 端口号 dbpath=/usr/local/mongodb/data/db/db1 # 数据存储目录 logpath=/usr/local/mongodb/data/logs/mongodb1.log # 日志文件存储目录 logappend=truefork=truemaxConns=5000storageEngine=mmapv1configsvr=true 分片服务器三台分片服务器配置相同，只需更改端口号、数据存储目录和日志存储目录即可； 123$ cp -p mongodb1.conf mongodb2.conf$ vim mongodb2.conf 12345678port=47017 # 端口号dbpath=/usr/local/mongodb/data/db/db2 # 数据存储目录logpath=/usr/local/mongodb/data/logs/mongodb2.log # 日志文件存储目录logappend=truefork=truemaxConns=5000storageEngine=mmapv1shardsvr=true 重复以上步骤分别配置其他分片服务器 启动服务器 1234$ mongod -f /usr/local/mongodb/data/conf/mongodb1.conf$ mongod -f /usr/local/mongodb/data/conf/mongodb2.conf$ mongod -f /usr/local/mongodb/data/conf/mongodb3.conf$ mongod -f /usr/local/mongodb/data/conf/mongodb4.conf 启动路由服务器123456$ ./mongos --port 27017 --fork --logpath=/usr/local/mongodb/data/log/route.log --configdb 192.168.33.12:37017 --chunkSize 1#--port指定对方连接入口#--fork后台运行#--logpath指定日志文件存储路径#--configdb指定给谁处理 启用分片服务器12345$ ./bin/mongo&gt; sh.addShard("192.168.27.153:47017")&gt; sh.addShard("192.168.27.153:47018")&gt; sh.status() 启用分片存储功能123456&gt; use kgc&gt; for (var i=1;i&lt;=50000;i++)db.users.insert(&#123;"id":i,"name":"zhangsan"+i&#125;)&gt; db.users.createIndex(&#123;"id":1&#125;) #对users表创建索引&gt; sh.enableSharding("kgc") #启用kgc数据库分片&gt; sh.shardCollection("kgc.users",&#123;"id":1&#125;) #表分片&gt; sh.status() 给分片添加标签123&gt; sh.addShardTag("shard0000","test01")&gt; sh.addShardTag("shard0001","test02")&gt; sh.status() 添加或删除分片服务器1234&gt; sh.addShard("192.168.33.12:47019")&gt; use admin&gt; db.runCommand(&#123;"removeshard":"192.168.27.153:47019"&#125;)&gt; sh.status() 基本操作查看数据分布 12&gt; use kgc&gt; db.users.getShardDistribution() 查看集合是否分片 1&gt; db.collectionName.stats().sharded # 简单的返回true或者false TODO分片策略 参考文档 https://www.runoob.com/mongodb/mongodb-sharding.htmlhttps://blog.51cto.com/13659182/2149307https://www.jianshu.com/p/cb55bb333e2d]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 复制（副本集）]]></title>
    <url>%2F2017%2F06%2F13%2Fdocs%2F05-nosql%2Fmongodb-replication%2F</url>
    <content type="text"><![CDATA[简介MongoDB复制是将数据同步在多个服务器的过程。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。复制还允许您从硬件故障和服务中断中恢复数据。Mongodb复制集由一组Mongod实例（进程）组成，包含一个Primary节点和多个Secondary节点。Mongodb Driver（客户端）的所有数据都写入Primary，Secondary从Primary同步写入的数据，以保持复制集内所有成员存储相同的数据集，实现数据的高可用。 使用场景 数据冗余，用做故障恢复使用，当发生硬件故障或者其它原因造成的宕机时，可以使用副本进行恢复。 读写分离，读的请求分流到副本上，减轻主节点的读压力。 mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。mongodb各个节点常见的搭配方式为：一主一从、一主多从。主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。 一个典型的副本集架构如下图所示： 以上结构图中，客户端从主节点读取数据，在客户端写入数据到主节点时， 主节点与从节点进行数据交互保障数据的一致性。 MongoDB副本集设置通过指定 –replSet 选项来启动mongoDB。–replSet 基本语法格式如下： 1mongod --port &quot;PORT&quot; --dbpath &quot;YOUR_DB_DATA_PATH&quot; --replSet &quot;REPLICA_SET_INSTANCE_NAME&quot; 实例 1./bin/mongod --port=27017 --dbpath=./data/db/ --replSet=rs0 以上实例会启动一个名为rs0的MongoDB实例，其端口号为27017。启动后打开命令提示框并连接上mongoDB服务。在Mongo客户端使用命令rs.initiate()来启动一个新的副本集。我们可以使用rs.conf()来查看副本集的配置。查看副本集状态使用rs.status()命令 。 副本集特征： N 个节点的集群 任何节点可作为主节点 所有写入操作都在主节点上 自动故障转移 自动恢复 副本集添加成员添加副本集的成员，我们需要使用多台服务器来启动mongo服务。进入Mongo客户端，并使用rs.add()方法来添加副本集的成员。 1&gt; rs.add(HOST_NAME:PORT) MongoDB中你只能通过主节点将Mongo服务添加到副本集中， 判断当前运行的Mongo服务是否为主节点可以使用命令db.isMaster() 。MongoDB的副本集与我们常见的主从有所不同，主从在主机宕机后所有服务将停止，而副本集在主机宕机后，副本会接管主节点成为主节点，不会出现宕机的情况。 副本集角色 主节点（Primary） 接收所有的写请求，然后把修改同步到所有Secondary。一个Replica Set只能有一个Primary节点，当Primary挂掉后，其他Secondary或者Arbiter节点会重新选举出来一个主节点。默认读请求也是发到Primary节点处理的，可以通过修改客户端连接配置以支持读取Secondary节点。 副本节点（Secondary） 与主节点保持同样的数据集。当主节点挂掉的时候，参与选主。 仲裁者（Arbiter） 不保有数据，不参与选主，只进行选主投票。使用Arbiter可以减轻数据存储的硬件需求，Arbiter几乎没什么大的硬件资源需求，但重要的一点是，在生产环境下它和其他数据节点不要部署在同一台机器上。 两种架构模式 PSS Primary + Secondary + Secondary模式，通过Primary和Secondary搭建的Replica SetDiagram of a 3 member replica set that consists of a primary and two secondaries. 该模式下 Replica Set节点数必须为奇数，目的是选主投票的时候要出现大多数才能进行选主决策。 PSA Primary + Secondary + Arbiter模式，使用Arbiter搭建Replica Set 偶数个数据节点，加一个Arbiter构成的Replica Set 选举机制复制集通过 replSetInitiate 命令或 rs.initiate() 命令进行初始化。初始化后各个成员间开始发送心跳消息，并发起 Primary 选举操作，获得大多数成员投票支持的节点，会成为 Primary，其余节点成为 Secondary。 123456789config = &#123; _id : &quot;my_replica_set&quot;, members : [ &#123;_id : 0, host : &quot;rs1.example.net:27017&quot;&#125;, &#123;_id : 1, host : &quot;rs2.example.net:27017&quot;&#125;, &#123;_id : 2, host : &quot;rs3.example.net:27017&quot;&#125;, ]&#125;rs.initiate(config) 大多数假设复制集内投票成员（后续介绍）数量为 N，则大多数为 N/2 + 1，当复制集内存活成员数量不足大多数时，整个复制集将无法选举出 Primary，复制集将无法提供写服务，处于只读状态 关于大多数的计算如下表所示 投票成员数 大多数 容忍失效数 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 Mongodb副本集的选举基于Bully算法，这是一种协调者竞选算法，详细解析可以参考这里Primary 的选举受节点间心跳、优先级、最新的 oplog 时间等多种因素影响。官方文档对于选举机制的说明选举机制的说明 特殊角色 ArbiterArbiter 节点只参与投票，不能被选为 Primary，并且不从 Primary 同步数据。当节点宕机导致复制集无法选出 Primary时，可以给复制集添加一个 Arbiter 节点，即使有节点宕机，仍能选出 Primary。Arbiter 本身不存储数据，是非常轻量级的服务，当复制集成员为偶数时，最好加入一个 Arbiter 节点，以提升复制集可用性。 Priority0Priority0节点的选举优先级为0，不会被选举为 Primary。比如你跨机房 A、B 部署了一个复制集，并且想指定 Primary 必须在 A 机房，这时可以将 B 机房的复制集成员 Priority 设置为0，这样 Primary 就一定会是 A 机房的成员。（注意：如果这样部署，最好将大多数节点部署在 A 机房，否则网络分区时可能无法选出 Primary。） Vote0Mongodb 3.0里，复制集成员最多50个，参与 Primary 选举投票的成员最多7个，其他成员（Vote0）的 vote 属性必须设置为0，即不参与投票。 HiddenHidden 节点不能被选为主（Priority 为0），并且对 Driver 不可见。因 Hidden 节点不会接受 Driver 的请求，可使用 Hidden 节点做一些数据备份、离线计算的任务，不会影响复制集的服务。 DelayedDelayed 节点必须是 Hidden 节点，并且其数据落后与 Primary 一段时间（可配置，比如1个小时）。因 Delayed 节点的数据比 Primary 落后一段时间，当错误或者无效的数据写入 Primary 时，可通过 Delayed 节点的数据来恢复到之前的时间点。 触发选举条件 初始化一个副本集时。 从库不能连接到主库(默认超过10s，可通过heartbeatTimeoutSecs参数控制)，由从库发起选举 主库放弃primary 角色，比如执行rs.stepdown 命令 Mongodb副本集通过心跳检测实现自动failover机制，进而实现高可用 MongoDB复制流程Primary 与 Secondary 之间通过 oplog 来同步数据，Primary 上的写操作完成后，会向特殊的 local.oplog.rs 特殊集合写入一条 oplog，Secondary 不断的从 Primary 取新的 oplog 并应用。因 oplog 的数据会不断增加，local.oplog.rs 被设置成为一个 capped 集合，当容量达到配置上限时，会将最旧的数据删除掉。另外考虑到 oplog 在 Secondary 上可能重复应用，oplog 必须具有幂等性，即重复应用也会得到相同的结果。如下 oplog 的格式，包含 ts、h、op、ns、o 等字段。 123456789101112&#123; &quot;ts&quot; : Timestamp(1446011584, 2), &quot;h&quot; : NumberLong(&quot;1687359108795812092&quot;), &quot;v&quot; : 2, &quot;op&quot; : &quot;i&quot;, &quot;ns&quot; : &quot;test.nosql&quot;, &quot;o&quot; : &#123; &quot;_id&quot; : ObjectId(&quot;563062c0b085733f34ab4129&quot;), &quot;name&quot; : &quot;mongodb&quot;, &quot;score&quot; : &quot;100&quot; &#125;&#125; 属性 说明 ts 操作时间，当前 timestamp + 计数器，计数器每秒都被重置 h 操作的全局唯一标识 v oplog 版本信息 op 操作类型 op.i 插入操作 op.u 更新操作 op.d 删除操作 op.c 执行命令（如 createDatabase，dropDatabase） op.n 空操作，特殊用途 ns 操作针对的集合 o 操作内容 o2 操作查询条件，仅 update 操作包含该字段。 Secondary 初次同步数据时，会先执行 init sync，从 Primary（或其他数据更新的 Secondary）同步全量数据，然后不断通过执行tailable cursor从 Primary 的 local.oplog.rs 集合里查询最新的 oplog 并应用到自身。 异常回滚 当 Primary 宕机时，如果有数据未同步到 Secondary，当 Primary 重新加入时，如果新的 Primary 上已经发生了写操作，则旧 Primary 需要回滚部分操作，以保证数据集与新的 Primary 一致。旧 Primary 将回滚的数据写到单独的 rollback 目录下，数据库管理员可根据需要使用 mongorestore 进行恢复 读写配置默认情况下，复制集的所有读请求都发到 Primary，Driver 可通过设置 Read Preference 来将读请求路由到其他的节点。 primary：默认规则，所有读请求发到 Primary； primaryPreferred：Primary 优先，如果 Primary 不可达，请求 Secondary； secondary：所有的读请求都发到 secondary； secondaryPreferred：Secondary 优先，当所有 Secondary 不可达时，请求 Primary； nearest：读请求发送到最近的可达节点上（通过 ping 探测得出最近的节点）。 关于read-preference Write Concern默认情况下，Primary 完成写操作即返回，Driver 可通过设置 Write Concern 来设置写成功的规则。如下的 write concern 规则设置写必须在大多数节点上成功，超时时间为5s。 1234db.products.insert( &#123; item: &quot;envelopes&quot;, qty : 100, type: &quot;Clasp&quot; &#125;, &#123; writeConcern: &#123; w: majority, wtimeout: 5000 &#125; &#125;) 关于write-concern 参考文档 https://www.runoob.com/mongodb/mongodb-replication.htmlhttps://www.cnblogs.com/littleatp/p/8562842.htmlhttp://www.mongoing.com/archives/5200]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 基础教程]]></title>
    <url>%2F2017%2F06%2F11%2Fdocs%2F05-nosql%2Fmongodb-tutorial-base%2F</url>
    <content type="text"><![CDATA[MongoDB 简介什么是MongoDBMongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多地节点，可以保证服务器的性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值（key=&gt;value）对组成。MongoDB 文档类似于JSON对象。字段值可以包含其他文档，数组以及文档数据。 主要特点 MongoDB 是一个面向文档存储的数据库，操作起来比较简单和容易。 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=”Sameer”,Address=”8 Gandhi Road”)来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。 MongoDB安装简单。 安装Linux平台安装MongoDBMongoDB 提供了linux各发行版本64位的安装包，你可以在官网下载安装包。下载地址：https://www.mongodb.com/download-center/community 下载完安装包，并解压 tgz（以下演示的是 64 位 Linux上的安装） 。 123$ wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.6.tgz$ tar -zxvf mongodb-linux-x86_64-3.0.6.tgz$ mv mongodb-linux-x86_64-3.0.6/ mongodb MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中： 1$ export PATH=mongodb-install-directory/bin:$PATH mongodb-install-directory 为你 MongoDB 的安装路径。如本文的 /usr/local/mongodb 。 创建数据目录MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。 以下实例中我们将data目录创建于/usr/local/mongodb/目录下。 1$ mkdir -p /usr/local/mongodb/data/db 启动MongoDB服务你可以再命令行中执行mongodb安装目录中的bin目录执行mongod命令来启动mongdb服务。 注意：如果你的数据库目录不是/data/db（MongoDB 默认的启动的数据库路径），可以通过 –dbpath 来指定。 1$ mongod --dbpath=/usr/local/mongodb/data/db MongoDB后台管理Shell如果你需要进入MongoDB后台管理，你需要先打开mongodb装目录的下的bin目录，然后执行mongo命令文件。MongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。当你进入mongoDB后台后，它默认会链接到 test 文档（数据库）： 1234567891011$ mongoMongoDB shell version: 3.0.6connecting to: testWelcome to the MongoDB shell.For interactive help, type "help".For more comprehensive documentation, see http://docs.mongodb.org/Questions? Try the support group http://groups.google.com/group/mongodb-user&gt; 现在让我们插入一些简单的数据，并对插入的数据进行检索： 12345&gt; db.runoob.insert(&#123;test:1&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.runoob.find()&#123; &quot;_id&quot; : ObjectId(&quot;5d26b208168b6593d96e6387&quot;), &quot;test&quot; : 1 &#125;&gt; OK，至此我们的MongoDB已经安装完成。 概念解析不管我们学习什么数据库都应该学习其中的基础概念，在mongodb中基本的概念是文档、集合、数据库，下面我们挨个介绍。下表将帮助您更容易理解Mongo中的一些概念： SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table join 表连接，MongoDB不支持 primary key primary key 主键，MongoDB自动将_id字段设置为主键 数据库一个mongodb中可以建立多个数据库。MongoDB的默认数据库为”db”，该数据库存储在data目录中。MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 文档(Document)文档是一组键值(key-value)对(即 BSON)。MongoDB 的文档不需要设置相同的字段，并且相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。 一个简单的文档例子如下： 1&#123;"site":"www.axkeson.com", "name":"Axkeson"&#125; 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 集合集合就是 MongoDB 文档组，类似于 RDBMS （关系数据库管理系统：Relational Database Management System)中的表格。 集合存在于数据库中，集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。 比如，我们可以将以下不同数据结构的文档插入到集合中： 123&#123;&quot;site&quot;:&quot;www.baidu.com&quot;&#125;&#123;&quot;site&quot;:&quot;www.google.com&quot;,&quot;name&quot;:&quot;Google&quot;&#125;&#123;&quot;site&quot;:&quot;www.axkeson.com&quot;, &quot;name&quot;:&quot;Axkeson&quot;&#125; 当第一个文档插入时，集合就会被创建。 capped collections Capped collections 就是固定大小的collection。它有很高的性能以及队列过期的特性(过期按照插入的顺序). 有点和 “RRD” 概念类似。Capped collections 是高性能自动的维护对象的插入顺序。它非常适合类似记录日志的功能和标准的 collection 不同，你必须要显式的创建一个capped collection，指定一个 collection 的大小，单位是字节。collection 的数据存储空间值提前分配的。Capped collections 可以按照文档的插入顺序保存到集合中，而且这些文档在磁盘上存放位置也是按照插入顺序来保存的，所以当我们更新Capped collections 中文档的时候，更新后的文档不可以超过之前文档的大小，这样话就可以确保所有文档在磁盘上的位置一直保持不变。由于 Capped collection 是按照文档的插入顺序而不是使用索引确定插入位置，这样的话可以提高增添数据的效率。MongoDB 的操作日志文件 oplog.rs 就是利用 Capped Collection 来实现的。要注意的是指定的存储大小包含了数据库的头信息。 1&gt; db.createCollection(&quot;mycoll&quot;, &#123;capped:true, size:100000&#125;) 在 capped collection 中，你能添加新的对象。 能进行更新，然而，对象不会增加存储空间。如果增加，更新就会失败 。 使用 Capped Collection 不能删除一个文档，可以使用 drop() 方法删除 collection 所有的行。 删除之后，你必须显式的重新创建这个 collection。 常用操作数据库创建数据库 1use &lt;DATABASE_NAME&gt; 查看所有数据库 1show dbs 查看当数据库 1db 删除数据库 1db.dropDatabase() 注意: 在 MongoDB 中，集合只有在内容插入后才会创建! 就是说，创建集合(数据表)后要再插入一个文档(记录)，集合才会真正创建。 集合创建集合 1db.createCollection(COLLECTION_NAME, options) 查看已有集合 1show collections 或 show tables 删除集合 1db.COLLECTION_NAME.drop() 实例 1234&gt; db.createCollection(&quot;mycol&quot;, &#123; capped : true, autoIndexId : true, size : 6142800, max : 10000 &#125; )&#123; &quot;ok&quot; : 1 &#125;&gt; 在 MongoDB 中，你不需要创建集合。当你插入一些文档时，MongoDB 会自动创建集合。 文档插入文档 1db.COLLECTION_NAME.insert(document) 更新文档 123456789db.COLLECTION_NAME.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 参数说明： query : update的查询条件，类似sql update查询内where后面的。 update : update的对象和一些更新的操作符（如$,$inc…）等，也可以理解为sql update查询内set后面的 upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入 multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。 writeConcern :可选，抛出异常的级别。 实例 1234567891011121314151617181920212223242526&gt;db.col.insert(&#123; title: &apos;MongoDB 教程&apos;, description: &apos;MongoDB 是一个 Nosql 数据库&apos;, by: &apos;Axkeson教程&apos;, url: &apos;http://www.axkeson.com&apos;, tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;], likes: 100&#125;)&gt;db.col.update(&#123;&apos;title&apos;:&apos;MongoDB 教程&apos;&#125;,&#123;$set:&#123;&apos;title&apos;:&apos;MongoDB&apos;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.col.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;56064f89ade2f21f36b03136&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;Axkeson教程&quot;, &quot;url&quot; : &quot;http://www.axkeson.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100&#125;&gt; save() 方法 通过传入的文档来替换已有文档。语法格式如下：参数说明： document : 文档数据。 writeConcern :可选，抛出异常的级别。 123456db.COLLECTION_NAME.save( &lt;document&gt;, &#123; writeConcern: &lt;document&gt; &#125;) 更多实例 12345db.col.update( &#123; &quot;count&quot; : &#123; $gt : 1 &#125; &#125; , &#123; $set : &#123; &quot;test2&quot; : &quot;OK&quot;&#125; &#125; ); // 只更新第一条记录：db.col.update( &#123; &quot;count&quot; : &#123; $gt : 3 &#125; &#125; , &#123; $set : &#123; &quot;test2&quot; : &quot;OK&quot;&#125; &#125;,false,true ); // 全部更新：db.col.update( &#123; &quot;count&quot; : &#123; $gt : 5 &#125; &#125; , &#123; $set : &#123; &quot;test5&quot; : &quot;OK&quot;&#125; &#125;,true,true ); // 全部添加进去:db.col.update( &#123; &quot;count&quot; : &#123; $gt : 15 &#125; &#125; , &#123; $inc : &#123; &quot;count&quot; : 1&#125; &#125;,false,true ); // 全部更新：db.col.update( &#123; &quot;count&quot; : &#123; $gt : 10 &#125; &#125; , &#123; $inc : &#123; &quot;count&quot; : 1&#125; &#125;,false,false ); // 只更新第一条记录 删除文档 1234db.COLLECTION_NAME.remove( &lt;query&gt;, &lt;justOne&gt;) 查询文档 123db.COLLECTION_NAME.findOne(query, projection)db.COLLECTION_NAME.find(query, projection)db.COLLECTION_NAME.find(query, projection).pretty() 索引创建索引 1db.COLLECTION_NAME.createIndex(keys, options) 参考文档 https://docs.mongodb.com/manual/https://www.runoob.com/mongodb/mongodb-replication.html]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[限制IP某个时间段内访问的次数]]></title>
    <url>%2F2017%2F05%2F21%2Fdocs%2F03-php%2Fphp-restricted-access%2F</url>
    <content type="text"><![CDATA[PHP 结合Redis限制IP某个时间段内访问的次数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?php/** * PHP 结合Redis限制IP某个时间段内访问的次数 */$redis = new Redis();$redis-&gt;connect('127.0.0.1');$key = getRealIp();//限制次数为10次。$limit = 10;if ($redis-&gt;exists($key)) &#123; $redis-&gt;incr($key); $count = $redis-&gt;get($key); // 超出请求次数限制 冻结该IP访问2分钟 if ($count == $limit) &#123; $redis-&gt;expire($key, 120); &#125; if ($count &gt; $limit) &#123; exit('超出访问限制次数'); &#125;&#125; else &#123; $redis-&gt;incr($key); // 限制时间为60秒 $redis-&gt;expire($key, 60);&#125;$count = $redis-&gt;get($key);exit(sprintf('Hello World！ %s request', $count));function getRealIp()&#123; if (isset($_SERVER)) &#123; if (isset($_SERVER['HTTP_X_FORWARDED_FOR'])) &#123; $realip = $_SERVER['HTTP_X_FORWARDED_FOR']; &#125; else &#123; if (isset($_SERVER['HTTP_CLIENT_IP'])) &#123; $realip = $_SERVER['HTTP_CLIENT_IP']; &#125; else &#123; $realip = $_SERVER['REMOTE_ADDR']; &#125; &#125; &#125; else &#123; if (getenv('HTTP_X_FORWARDED_FOR')) &#123; $realip = getenv('HTTP_X_FORWARDED_FOR'); &#125; else &#123; if (getenv('HTTP_CLIENT_IP')) &#123; $realip = getenv('HTTP_CLIENT_IP'); &#125; else &#123; $realip = getenv('REMOTE_ADDR'); &#125; &#125; &#125; return $realip;&#125; NGINXnginx可以通过ngx_http_limit_conn_module和ngx_http_limit_req_module配置来限制ip在同一时间段的访问次数 ngx_http_limit_conn_module：该模块用于限制每个定义的密钥的连接数，特别是单个IP​​地址的连接数．使用limit_conn_zone和limit_conn指令． ngx_http_limit_req_module：用于限制每一个定义的密钥的请求的处理速率，特别是从一个单一的IP地址的请求的处理速率。使用“泄漏桶”方法进行限制．指令：limit_req_zone和limit_req． ngx_http_limit_conn_module：限制单个IP的连接数示例 12345678910111213141516http &#123; limit_conn_zone $binary_remote_addr zone=addr：10m; #定义一个名为addr的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key, #nginx 1.18以后用limit_conn_zone替换了limit_conn, #且只能放在http&#123;&#125;代码段． ... server &#123; ... location /download/ &#123; limit_conn addr 1; #连接数限制 #设置给定键值的共享内存区域和允许的最大连接数。超出此限制时，服务器将返回503（服务临时不可用）错误. ＃如果区域存储空间不足，服务器将返回503（服务临时不可用）错误 &#125; &#125;&#125; 可能有几个limit_conn指令,以下配置将限制每个客户端IP与服务器的连接数，同时限制与虚拟服务器的总连接数： 12345678910http &#123; limit_conn_zone $binary_remote_addr zone=perip：10m; limit_conn_zone $server_name zone=perserver：10m ... server &#123; ... limit_conn perip 10; #单个客户端ip与服务器的连接数． limit_conn perserver 100; ＃限制与服务器的总连接数 &#125;&#125; 参考文档：http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html ngx_http_limit_req_module：限制某一时间内，单一IP的请求数 123456789101112131415161718192021222324http &#123; limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; ... #定义一个名为one的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key,限制平均每秒的请求为1个， #1M能存储16000个状态，rete的值必须为整数， server &#123; ... location /search/ &#123; limit_req zone=one burst=5; #限制每ip每秒不超过1个请求，漏桶数burst为5,也就是队列． #nodelay，如果不设置该选项，严格使用平均速率限制请求数，超过的请求被延时处理． #举个栗子： ＃设置rate=20r/s每秒请求数为２０个，漏桶数burst为5个， #brust的意思就是，如果第1秒、2,3,4秒请求为19个，第5秒的请求为25个是被允许的，可以理解为20+5 #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误． ＃如果区域存储空间不足，服务器将返回503（服务临时不可用）错误 ＃速率在每秒请求中指定（r/s）。如果需要每秒少于一个请求的速率，则以每分钟的请求（r/m）指定。 &#125; &#125;&#125; 还可以限制来自单个IP地址的请求的处理速率，同时限制虚拟服务器的请求处理速率： 12345678910http &#123; limit_req_zone $binary_remote_addr zone=perip:10m rate=1r/s; limit_req_zone $server_name zone=perserver:10m rate=10r/s; ... server &#123; ... limit_req zone=perip burst=5 nodelay; #漏桶数为５个．也就是队列数．nodelay:不启用延迟． limit_req zone=perserver burst=10; #限制nginx的处理速率为每秒10个 &#125;&#125;]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>访问限制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 垃圾回收机制]]></title>
    <url>%2F2017%2F01%2F19%2Fdocs%2F03-php%2Fphp-gc%2F</url>
    <content type="text"><![CDATA[简介在PHP中，没有任何变量指向这个对象时，这个对象就成为垃圾；PHP会将其在内存中销毁。这是PHP的 GC 垃圾回收机制，目的是防止内存溢出； PHP进行内存管理的核心算法一共两项：一是引用计数，二是写时拷贝。当你声明一个PHP变量的时候，C语言就在底层给你搞了一个叫做zval的struct（结构体）；如果你还给这个变量赋值了，比如“hello world”，那么C语言就在底层再给你搞一个叫做zend_value的union（联合体） PHP垃圾回收机制是 php5 之后才有的这个东西，php5.3 之前使用的垃圾回收机制是单纯的“引用计数”，就是每个内存对象都分配一个计数器，当内存对象被变量引用时，计数器+ 1;当变量引用撇掉后，计数器 -1 ；当计数器 =0 时，表名内存中对象没有被使用，该内存对象进行销毁，垃圾回收完成； php5.3开始，使用了新的垃圾回收机制，在引用计数基础上，实现了一种复杂的算法，来检测内存对象中 引用环 的存在，以避免内存泄露； 引用计数基本知识每个php变量存在一个叫”zval”的变量容器中。一个zval变量容器，除了包含变量的类型和值，还包括两个字节的额外信息。第一个是”is_ref”，是个bool值，用来标识这个变量是否是属于引用集合(reference set)。通过这个字节，php引擎才能把普通变量和引用变量区分开来，由于php允许用户通过使用&amp;来使用自定义引用，zval变量容器中还有一个内部引用计数机制，来优化内存使用。第二个额外字节是”refcount”，用以表示指向这个zval变量容器的变量(也称符号即symbol)个数。所有的符号存在一个符号表中，其中每个符号都有作用域(scope)，那些主脚本(比如：通过浏览器请求的的脚本)和每个函数或者方法也都有作用域。 12345678910zval &#123; string &quot;a&quot; //变量的名字是a value zend_value //变量的值 type string //变量是字符串类型&#125;zend_value &#123; string &quot;hello916&quot; //值的内容 refcount 1 //引用计数&#125; 12345678910111213141516171819&lt;?php $a = 'hello'. mt_rand( 1, 1000 );xdebug_debug_zval( 'a');$b = $a;xdebug_debug_zval('a');$c = $a;xdebug_debug_zval('a');unset( $c );xdebug_debug_zval( 'a');// 输出结果a: (refcount=1, is_ref=0)='hello517'a: (refcount=2, is_ref=0)='hello517'a: (refcount=3, is_ref=0)='hello517'a: (refcount=2, is_ref=0)='hello517' 其中，zval struct结构体用于保存$a，zend_value union联合体用于保存数据内容也就是’hello517’。由于后面又声明了b和c，所以C不得不又在底层给你搞出两个zval struct结构体来。 那么写时拷贝是什么意思呢？看下面代码： 123456789101112&lt;?php $a = 'hello'. mt_rand( 1, 1000 );$b = $a;xdebug_debug_zval( 'a');$a = 'world'. mt_rand( 2, 2000 );xdebug_debug_zval( 'a');// 输出结果a: (refcount=2, is_ref=0)='hello834'a: (refcount=1, is_ref=0)='world1198' 引用计数和写时拷贝，那么垃圾回收也该来了。当一个zval在被unset的时候、或者从一个函数中运行完毕出来（就是局部变量）的时候等等很多地方，都会产生zval与zend_value发生断开的行为，这个时候zend引擎需要检测的就是zend_value的refcount是否为0，如果为0，则直接KO free空出内容来。如果zend_value的recount不为0（废话一定是大于0），这个value不能被释放，但是也不代表这个zend_value是清白的，因为此zend_value依然可能是个垃圾。 什么样的情况会导致zend_value的refcount不为0，但是这个zend_value却是个垃圾呢？PHP7种两种情况： 数组：a数组的某个成员使用&amp;引用a自己对象：对象的某个成员引用对象自己 12345&lt;?php$arr = [ 1 ];$arr[] = &amp;$arr;unset( $arr ); 这种情况下，zend_value不会能释放，但也不能放过它，不然一定会产生内存泄漏，所以这会儿zend_value会被扔到一个叫做垃圾回收堆中，然后zend引擎会依次对垃圾回收堆中的这些zend_value进行二次检测，检测是不是由于上述两种情况造成的refcount为1但是自身却确实没有人再用了，如果一旦确定是上述两种情况造成的，那么就会将zend_value彻底抹掉释放内存。 那么垃圾回收发生在什么时候？有些同学可能有疑问，就是php不是运行一次就销毁了吗，我要着gc有何用？并不是啦，首先当一次fpm运行完毕后，最后一定还有gc的，这个销毁就是gc；其次是，内存都是即用即释放的，而不是攒着非得到最后，你想想一个典型的场景，你的控制器里的某个方法里用了一个函数，函数需要一个巨大的数组参数，然后函数还需要修改这个巨大的数组参数，你们应该是函数的运行范围里面修改这个数组，所以此时会发生写时拷贝了，当函数运行完毕后，就得赶紧释放掉这块儿内存以供给其他进程使用，而不是非得等到本地fpm request彻底完成后才销毁。 PHP5 和 PHP7的来及回收机制有什么不同PHP5 和 PHP7 的垃圾回收机制都属于引用计数，但是复杂数据类型的算法处理上：在PHP7中zval有了新的实现方式。 最基础的变化是*zval需要的内存不再是单独从堆上分配，不再自己存储引用计数复杂数据类型（比如字符串、数组和对象）的引用计数由其自身来存储 这种实现方式有以下好处： 简单数据类型不需要单独分配内存，也不需要计数； 不会再有两次计数的情况。在对象中，只有对象自身存储的计数是有效的； 由于现在计数由数值自身存储，所以也就可以和非 zval 结构的数据共享，比如 zval 和 hashtable key 之间； 相关文档 https://www.php.net/manual/zh/features.gc.phphttps://www.sohu.com/a/252341086_470018]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>垃圾回收</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 事务详解]]></title>
    <url>%2F2016%2F10%2F06%2Fdocs%2F04-mysql%2Fmysql-transaction%2F</url>
    <content type="text"><![CDATA[简介MySQL事务主要用于处理操作量大，复杂度高的数据。由一步或几步数据库操作序列组成逻辑执行单元，这系列操作要么全部执行，要么全部放弃执行。在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。事务用来管理 insert,update,delete 语句。 事务的基本特征（ACID）一般来说，事务是必须满足4个条件的（ACID） 原子性： Atomicity，或称不可分割性。一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务的执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性： Consistency，在事务开始之前和事务结束以后，数据库的完整性没有破坏。这表示写入的资料必须完全符合所有的预设规则，这包括资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性： Isolation，又称独立性。数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同的级别，包扩未提交（Read uncommitted）、读提交（Read committed）、可重复读（Repeatable read）和串行化（Serializable）。 持久性： Durability，事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 事务的隔离级别为什么需要隔离性如果事务之间不是互相隔离的，可能将会出现以下问题。 脏读 脏读（dirty read），简单来说，就是一个事务在处理过程中读取了另外一个事务未提交的数据。这种未提交的数据我们称之为脏数据。依据脏数据所做的操作肯定是不正确的。 不可重复读 不可重复读（non-repeatable read），是指一个事务范围内，多次查询某个数据，却得到不同的结果。在第一个事务中的两次读取数据之间，由于第二个事务的修改，第一个事务两次读到的数据可能就是不一样的。 幻读 幻读（plantom read），是事务非独立执行时发生的一种现象。例如事务 T1 对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务 T2 又对这个表中插入了一行数据项为“1”的数据，并且提交给数据库，而操作事务 T1 的用户如果再查看刚刚修改的数据，会发现数据怎么还是 1？其实这行是从事务 T2 中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 四种隔离级别为了解决上面可能出现的问题，我们就需要设置隔离级别，也就是事务之间按照什么规则进行隔离，将事务隔离到什么程度。 首先，需要明白一点，隔离程度越强，越能保证数据的完整性和一致性，但是付出的代价却是并发执行效率的低下。 ANSI/ISO SQL 定义了 4 种标准隔离级别： Serializable（串行化） 我的事务尚未提交，别人就别想改数据。 花费最高代价但最可靠的事务隔离级别。“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。事务 100% 隔离，可避免脏读、不可重复读、幻读的发生。 Repeatable read（可重复读，默认级别） 别人改数据的事务已经提交，我在我的事务中也不去读。 多次读取同一范围的数据会返回第一次查询的快照，即使其他事务对该数据做了更新修改。事务在执行期间看到的数据前后必须是一致的。但如果这个事务在读取某个范围内的记录时，其他事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行，这就是幻读。 Read committed (读已提交) 别人改数据的事务已经提交，我在我的事务中才能读到。 保证一个事务提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。可避免脏读的发生，但是可能会造成不可重复读。大多数数据库的默认级别就是 Read committed，比如 Sql Server , Oracle。 Read uncommitted (读未提交) 别人改数据的事务尚未提交，我在我的事务中也能读到。 最低的事务隔离级别，一个事务还没提交时，它做的变更就能被别的事务看到。任何情况都无法保证。 隔离级别与一致性关系 隔离级别 脏读 不可重复读 幻读 Read uncommitted 可能 可能 可能 Read committed 不可能 可能 可能 Repeatable Read 不可能 不可能 可能 Serializable 不可能 不可能 不可能 隔离级别的一些基本操作设置事务隔离级别 可以在my.ini文件中使用transaction-isolation选项来设置服务器的缺省事务隔离级别 该选项值可以是 12345678– READ-UNCOMMITTED– READ-COMMITTED– REPEATABLE-READ– SERIALIZABLE# 例如：[mysqld]transaction-isolation = READ-COMMITTED 通过命令动态设置隔离级别 隔离级别也可以在运行的服务器中动态设置，应使用SET TRANSACTION ISOLATION LEVEL语句 123456789101112131415SET [GLOBAL | SESSION] TRANSACTION ISOLATION LEVEL &lt;isolation-level&gt; 其中的&lt;isolation-level&gt;可以是： – READ UNCOMMITTED – READ COMMITTED – REPEATABLE READ – SERIALIZABLE# 例如： • 事务隔离级别的作用范围分为两种： – 全局级：对所有的会话有效 – 会话级：只对当前的会话有效 SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED； # 会话级SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED； # 全局级 查看隔离级别1mysql&gt; select @@tx_isolation; 隔离级别的实现事务的机制是通过视图（read-view）来实现的并发版本控制（MVCC），不同的事务隔离级别创建读视图的时间点不同。 可重复读是每个事务重建读视图，整个事务存在期间都用这个视图。 读已提交是每条 SQL 创建读视图，在每个 SQL 语句开始执行的时候创建的。隔离作用域仅限该条 SQL 语句。 读未提交是不创建，直接返回记录上的最新值 串行化隔离级别下直接用加锁的方式来避免并行访问。 这里的视图可以理解为数据副本，每次创建视图时，将当前已持久化的数据创建副本，后续直接从副本读取，从而达到数据隔离效果。 事务控制语句 BEGIN 或 START TRANSACTION 显式地开启一个事务； COMMIT 也可以使用 COMMIT WORK，不过二者是等价的。COMMIT 会提交事务，并使已对数据库进行的所有修改成为永久性的； ROLLBACK 也可以使用 ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier，SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT； RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier 把事务回滚到标记点； SET TRANSACTION 用来设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748mysql&gt; use RUNOOB;Database changedmysql&gt; CREATE TABLE runoob_transaction_test( id int(5)) engine=innodb; # 创建数据表Query OK, 0 rows affected (0.04 sec) mysql&gt; select * from runoob_transaction_test;Empty set (0.01 sec) mysql&gt; begin; # 开始事务Query OK, 0 rows affected (0.00 sec) mysql&gt; insert into runoob_transaction_test value(5);Query OK, 1 rows affected (0.01 sec) mysql&gt; insert into runoob_transaction_test value(6);Query OK, 1 rows affected (0.00 sec) mysql&gt; commit; # 提交事务Query OK, 0 rows affected (0.01 sec) mysql&gt; select * from runoob_transaction_test;+------+| id |+------+| 5 || 6 |+------+2 rows in set (0.01 sec) mysql&gt; begin; # 开始事务Query OK, 0 rows affected (0.00 sec) mysql&gt; insert into runoob_transaction_test values(7);Query OK, 1 rows affected (0.00 sec) mysql&gt; rollback; # 回滚Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from runoob_transaction_test; # 因为回滚所以数据没有插入+------+| id |+------+| 5 || 6 |+------+2 rows in set (0.01 sec) mysql&gt; PHP中使用事务实例 1234567891011121314151617181920212223242526&lt;?php$dbhost = 'localhost:3306'; // mysql服务器主机地址$dbuser = 'root'; // mysql用户名$dbpass = '123456'; // mysql用户名密码$conn = mysqli_connect($dbhost, $dbuser, $dbpass);if(! $conn )&#123; die('连接失败: ' . mysqli_error($conn));&#125;// 设置编码，防止中文乱码mysqli_query($conn, "set names utf8");mysqli_select_db( $conn, 'RUNOOB' );mysqli_query($conn, "SET AUTOCOMMIT=0"); // 设置为不自动提交，因为MYSQL默认立即执行mysqli_begin_transaction($conn); // 开始事务定义 if(!mysqli_query($conn, "insert into runoob_transaction_test (id) values(8)"))&#123; mysqli_query($conn, "ROLLBACK"); // 判断当执行失败时回滚&#125; if(!mysqli_query($conn, "insert into runoob_transaction_test (id) values(9)"))&#123; mysqli_query($conn, "ROLLBACK"); // 判断执行失败时回滚&#125;mysqli_commit($conn); //执行事务mysqli_close($conn); 什么是大事务 定义 运行时间比较长，操作的数据比较多的事务。 大事务风险 锁定太多的数据，造成大量的阻塞和锁超时，回滚所需要的时间比较长。执行时间长，容易造成主从延迟 如何处理大事务 避免一次处理太多大数据。移出不必要在事务中的select操作。 相关文章 http://blog.itpub.net/31559358/viewspace-2221931https://www.runoob.com/mysql/mysql-transaction.htmlhttps://blog.csdn.net/w_linux/article/details/79666086https://blog.csdn.net/changudeng1992/article/details/81988927]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 截取文件后缀的几种方法]]></title>
    <url>%2F2016%2F05%2F12%2Fdocs%2F03-php%2Fphp-get-file-ext%2F</url>
    <content type="text"><![CDATA[expload 函数1234567&lt;?phpfunction getExt($path)&#123; $ext = explode('.', $path); return end($ext);&#125; strrpos 函数12345&lt;?phpfunction getExt($path)&#123; return substr($path, strrpos($path, '.')+1);&#125; strrchr 函数12345&lt;?phpfunction getExt($path)&#123; return substr(strrchr($path, '.'), 1);&#125; pathinfo 函数12345&lt;?phpfunction getExt($path)&#123; return pathinfo($path, PATHINFO_EXTENSION);&#125;]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>ext</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Explain详解]]></title>
    <url>%2F2016%2F03%2F29%2Fdocs%2F04-mysql%2Fmysql-explain%2F</url>
    <content type="text"><![CDATA[简介使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈。 通过EXPLAIN，我们可以分析出以下结果 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 使用方式如下EXPLAIN +SQL语句 123456789mysql&gt; explain select * from test where name = 10000;+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+| 1 | SIMPLE | test | NULL | ALL | NULL | NULL | NULL | NULL | 378000 | 10.00 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+1 row in set, 1 warning (0.00 sec)mysql&gt; 执行计划各字段含义概要描述 字段 描述 id 选择标识符 select_type 表示查询的类型 table 输出结果集的表 partitions 匹配的分区 type 表示表的连接类型 possible_keys 表示查询时，可能使用的索引 key 表示实际使用的索引 key_len 索引字段的长度 ref 列与索引的比较 rows 扫描出的行数(估算的行数) filtered 按表条件过滤的行百分比 Extra 执行情况的描述和说明 idselect查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序 id相同时，执行顺序由上至下 如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行 select_type表示查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询 select_type 描述 SIMPLE 简单SELECT，不使用UNION或子查询等 PRIMARY 子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY UNION UNION中的第二个或后面的SELECT语句 DEPENDENT UNION UNION中的第二个或后面的SELECT语句，取决于外面的查询 UNION RESULT UNION的结果，union语句中第二个select开始后面所有select SUBQUERY 子查询中的第一个SELECT，结果不依赖于外部查询 DEPENDENT SUBQUERY 子查询中的第一个SELECT，依赖于外部查询 DERIVED 派生表的SELECT, FROM子句的子查询 UNCACHEABLE SUBQUERY 一个子查询的结果不能被缓存，必须重新评估外链接的第一行 table指的就是当前执行的表 type对表访问方式，表示MySQL在表中找到所需行的方式，又称”访问类型”。常用的类型有： ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好） type 描述 ALL Full Table Scan， MySQL将遍历全表以找到匹配的行 index Full Index Scan，index与ALL区别为index类型只遍历索引树 range 只检索给定范围的行，使用一个索引来选择行 ref 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 eq_ref 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件 const 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system system 表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计 NULL MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 possible_keys指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用（该查询可以利用的索引，如果没有任何索引显示 null） 该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询 Keykey列显示MySQL实际决定使用的键（索引），必然包含在possible_keys中 如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。 key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的） 不损失精确性的情况下，长度越短越好 ref列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 Extra该列包含MySQL解决查询的详细信息,有以下几种情况： Using where:不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by Using filesort：当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序” Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行 No tables used：Query语句中使用from dual 或不含任何from子句 总结 EXPLAIN不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况 EXPLAIN不考虑各种Cache EXPLAIN不能显示MySQL在执行查询时所作的优化工作 部分统计信息是估算的，并非精确值 EXPALIN只能解释SELECT操作，其他操作要重写为SELECT后查看执行计划。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Explain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 索引详解]]></title>
    <url>%2F2016%2F03%2F28%2Fdocs%2F04-mysql%2Fmysql-index%2F</url>
    <content type="text"><![CDATA[介绍什么是索引？一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，在生产环境中，我们遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，因此对查询语句的优化显然是重中之重。说起加速查询，就不得不提到索引了。 为什么要有索引呢？索引在MySQL中也叫做“键”，是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。索引优化应该是对查询性能优化最有效的手段了。索引能够轻易将查询性能提高好几个数量级。索引相当于字典的音序表，如果要查某个字，如果不使用音序表，则需要从几百页中逐页去查。 索引的分类 普通索引 唯一索引 联合索引 全文索引 空间索引 索引的优缺点 优势： 可以快速检索，减少I/O次数，加快检索速度；根据索引分组和排序，可以加快分组和排序 劣势： 索引本身也是表，因此会占用存储空间，一般来说，索引表占用的空间的数据表的1.5倍；索引表的维护和创建需要时间成本，这个成本随着数据量增大而增大；构建索引会降低数据表的修改操作（删除，添加，修改）的效率，因为在修改数据表的同时还需要修改索引表 索引的实现原理哈希索引只有memory（内存）存储引擎支持哈希索引，哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能。 全文索引FULLTEXT（全文）索引，仅可用于MyISAM和InnoDB，针对较大的数据，生成全文索引非常的消耗时间和空间。对于文本的大对象，或者较大的CHAR类型的数据，如果使用普通索引，那么匹配文本前几个字符还是可行的，但是想要匹配文本中间的几个单词，那么就要使用LIKE %word%来匹配，这样需要很长的时间来处理，响应时间会大大增加，这种情况，就可使用时FULLTEXT索引了，在生成FULLTEXT索引时，会为文本生成一份单词的清单，在索引时及根据这个单词的清单来索引。FULLTEXT可以在创建表的时候创建，也可以在需要的时候用ALTER或者CREATE INDEX来添加。 BTree索引和B+Tree索引BTree索引BTree是平衡搜索多叉树，设树的度为2d（d&gt;1），高度为h，那么BTree要满足以一下条件： 每个叶子结点的高度一样，等于h； 每个非叶子结点由n-1个key和n个指针point组成，其中d&lt;=n&lt;=2d,key和point相互间隔，结点两端一定是key； 叶子结点指针都为null； 非叶子结点的key都是[key,data]二元组，其中key表示作为索引的键，data为键值所在行的数据； B+Tree索引B+Tree是BTree的一个变种，设d为树的度数，h为树的高度，B+Tree和BTree的不同主要在于： B+Tree中的非叶子结点不存储数据，只存储键值； B+Tree的叶子结点没有指针，所有键值都会出现在叶子结点上，且key存储的键值对应data数据的物理地址； B+Tree的每个非叶子节点由n个键值key和n个指针point组成； 聚簇索引和非聚簇索引分析了MySQL的索引结构的实现原理，然后我们来看看具体的存储引擎怎么实现索引结构的，MySQL中最常见的两种存储引擎分别是MyISAM和InnoDB，分别实现了非聚簇索引和聚簇索引。 聚簇索引的解释是:聚簇索引的顺序就是数据的物理存储顺序 非聚簇索引的解释是:索引顺序与数据物理排列顺序无关 索引的使用策略什么时候要使用索引 主键自动建立唯一索引； 经常作为查询条件在WHERE或者ORDER BY 语句中出现的列要建立索引； 作为排序的列要建立索引； 查询中与其他表关联的字段，外键关系建立索引 高并发条件下倾向组合索引； 用于聚合函数的列可以建立索引，例如使用了max(column_1)或者count(column_1)时的column_1就需要建立索引 什么时候不要使用索引 经常增删改的列不要建立索引； 有大量重复的列不建立索引； 表记录太少不要建立索引。只有当数据库里已经有了足够多的测试数据时，它的性能测试结果才有实际参考价值。如果在测试数据库里只有几百条数据记录，它们往往在执行完第一条查询命令之后就被全部加载到内存里，这将使后续的查询命令都执行得非常快–不管有没有使用索引。只有当数据库里的记录超过了1000条、数据总量也超过了MySQL服务器上的内存总量时，数据库的性能测试结果才有意义。 索引失效的情况 在组合索引中不能有列的值为NULL，如果有，那么这一列对组合索引就是无效的。 在一个SELECT语句中，索引只能使用一次，如果在WHERE中使用了，那么在ORDER BY中就不要用了。 LIKE操作中，’%aaa%’不会使用索引，也就是索引会失效，但是‘aaa%’可以使用索引。 在索引的列上使用表达式或者函数会使索引失效，例如：select * from users where YEAR(adddate)&lt;2007，将在每个行上进行运算，这将导致索引失效而进行全表扫描，因此我们可以改成：select * from users where adddate&lt;’2007-01-01′。其它通配符同样，也就是说，在查询条件中使用正则表达式时，只有在搜索模板的第一个字符不是通配符的情况下才能使用索引。 在查询条件中使用不等于，包括&lt;符号、&gt;符号和！=会导致索引失效。特别的是如果对主键索引使用！=则不会使索引失效，如果对主键索引或者整数类型的索引使用&lt;符号或者&gt;符号不会使索引失效。（经erwkjrfhjwkdb同学提醒，不等于，包括&lt;符号、&gt;符号和！，如果占总记录的比例很小的话，也不会失效） 在查询条件中使用IS NULL或者IS NOT NULL会导致索引失效。 字符串不加单引号会导致索引失效。更准确的说是类型不一致会导致失效，比如字段email是字符串类型的，使用WHERE email=99999 则会导致失败，应该改为WHERE email=’99999’。 在查询条件中使用OR连接多个条件会导致索引失效，除非OR链接的每个条件都加上索引，这时应该改为两次查询，然后用UNION ALL连接起来。 如果排序的字段使用了索引，那么select的字段也要是索引字段，否则索引失效。特别的是如果排序的是主键索引则select * 也不会导致索引失效。尽量不要包括多列排序，如果一定要，最好为这队列构建组合索引； 索引的语法查看一张表的索引123用法：show index from TABLE_NAME;mysql&gt; show index from users; 建立索引1234567891011121314151617181920用法# 普通索引 create index INDEX_NAME on TABLE_NAME(字段名);# 唯一索引 create unique INDEX_NAME on TABLE_NAME(字段名);# 全文索引 create fulltext INDEX_NAME on TABLE_NAME(字段名);# 多列索引 create index INDEX_NAME on TABLE_NAME(字段名,字段名);mysql&gt; create index index_name on user(name, age);创建表时直接创建索引CREATE TABLE school( NAME VARCHAR(8) NOT NULL , sid INT PRIMARY KEY auto_increment NOT NULL , age INT NOT NULL , sex ENUM(&apos;F&apos; , &apos;M&apos;) , INDEX(sid , NAME));在已存在的表上添加索引mysql&gt; alter table school add index index_name(name); 删除索引1mysql&gt; drop index INDEX_NAME on TABLE_NAME; 查看查询语句使用索引的情况1mysql&gt; explain SELECT * FROM TABLE_NAME WHERE COLUMN_NAME = &apos;123&apos;; 索引测试准备 创建表 123456CREATE TABLE test( id INT , name VARCHAR(20) , gender CHAR(6) , email VARCHAR(50)); 创建存储过程，实现批量插入记录 123456789101112131415161718delimiter $$ #声明存储过程的结束符号为$$CREATE PROCEDURE auto_insert()BEGINDECLARE i INT DEFAULT 1 ;WHILE(i &lt; 1000000) DO INSERT INTO s1VALUES ( i , concat(&apos;egon&apos; , i) , &apos;male&apos; , concat(&apos;egon&apos; , i , &apos;@oldboy&apos;) ) ;SET i = i + 1 ;ENDWHILE ; END$$ #$$结束delimiter ; #重新声明分号为结束符号 调用存储过程 1call auto_insert(); 在没有索引的前提下测试查询速度123456789mysql&gt; select * from test where id = 10000;+-------+-----------+--------+------------------+| id | name | gender | email |+-------+-----------+--------+------------------+| 10000 | egon10000 | male | egon10000@oldboy |+-------+-----------+--------+------------------+1 row in set (0.03 sec)mysql&gt; 加上索引12345678910111213mysql&gt; create index idx on test(id);Query OK, 0 rows affected (0.60 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; select * from test where id = 10000;+-------+-----------+--------+------------------+| id | name | gender | email |+-------+-----------+--------+------------------+| 10000 | egon10000 | male | egon10000@oldboy |+-------+-----------+--------+------------------+1 row in set (0.00 sec)mysql&gt; 相关文章 https://www.runoob.com/mysql/mysql-index.htmlhttps://www.cnblogs.com/bypp/p/7755307.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP状态码]]></title>
    <url>%2F2016%2F03%2F01%2Fdocs%2F09-pc-base%2Fhttp-status-codes%2F</url>
    <content type="text"><![CDATA[简介当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含HTTP状态码的信息头（server header）用以响应浏览器的请求。 HTTP状态码的英文为HTTP Status Code。 分类HTTP状态码（HTTP Status Code）是用以表示网页服务器HTTP响应状态的3位数字代码。它由 RFC 2616 规范定义的，并得到RFC 2518、RFC 2817、RFC 2295、RFC 2774、RFC 4918等规范扩展。 所有状态码的第一个数字代表了响应的五种状态之一。 分类 分类描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 HTTP状态码列表 状态码 含义 100 客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。 101 服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。 只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。 102 由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。 200 请求已成功，请求所希望的响应头或数据体将随此响应返回。 201 请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 ‘202 Accepted’。 202 服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。 返回202状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。 203 服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。 204 服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。 如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。 205 服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。 与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。 206 服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。 响应必须包含如下的头部域： Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。 Date ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。 Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。 假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。 任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。 207 由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 300 被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。 如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。 301 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。 新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个301响应的话，接下来的重定向请求将会变成 GET 方式。 302 请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 注意：虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将302响应视作为303响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码303和307被添加了进来，用以明确服务器期待客户端进行何种反应。 303 对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动，302状态码应该可以胜任，因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的。 304 如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 该响应必须包含以下的头信息： Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068中规定的一样），缓存机制将会正常工作。 ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。 假如某个304响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。 假如接收到一个要求更新某个缓存条目的304响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。 305 被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。 注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。 306 在最新版的规范中，306状态码已经不再被使用。 307 请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 新的临时性的URI 应当在响应的 Location 域中返回。除非这是一个HEAD 请求，否则响应的实体中应当包含指向新的URI 的超链接及简短说明。因为部分浏览器不能识别307响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 400 1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。 2、请求参数有误。 401 当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617。 402 该状态码是为了将来可能的需求而预留的。 403 服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。 404 请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。 405 请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。 406 请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。 除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。 407 与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见RFC 2617。 408 请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。 409 由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。 冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个409错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。 410 被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用404状态码。除非额外说明，否则这个响应是可缓存的。 410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为’410 Gone’，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。 411 服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。 412 服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。 413 服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。 414 请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括： 本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。 重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。 客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行[1]。没有此类漏洞的服务器，应当返回414状态码。 415 对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。 416 如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。 假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。 417 在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。 421 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 当前资源被锁定。（RFC 4918 WebDAV） 424 由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） 425 在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。 426 客户端应当切换到TLS/1.0。（RFC 2817） 449 由微软扩展，代表请求应当在执行完适当的操作后进行重试。 499 An Nginx HTTP server extension. This code is introduced to log the case when the connection is closed by client while HTTP server is processing its request, making server unable to send the HTTP header back.。 500 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。 501 服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 502 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。 注意：503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。 504 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 注意：某些代理服务器在DNS查询超时时会返回400或者500错误 505 服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。 506 由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 507 服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918) 509 服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。 510 获取资源所需要的策略并没有没满足。（RFC 2774） 相关文章 http://tool.oschina.net/commons?type=5http://www.httpstatus.cnhttps://www.runoob.com/http/http-status-codes.html]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 修改root密码的几种方法]]></title>
    <url>%2F2016%2F01%2F25%2Fdocs%2F04-mysql%2Fmysql-root-password-update%2F</url>
    <content type="text"><![CDATA[SET PASSWORD 命令123格式:mysql&gt; SET PASSWORD FOR 用户名@localhost = PASSWORD(&apos;新密码&apos;) mysql&gt; SET PASSWORD FOR root@localhost = PASSWORD(&apos;123456&apos;); 使用 mysqladmin 命令123格式:mysqladmin -u用户名 -p旧密码 password 新密码; $ mysqladmin -uroot -p123456 password 12345678; 使用 update 直接编辑 user 表123mysql&gt; USE mysql; mysql&gt; UPDATE user SET password = password(&apos;123456&apos;) WHERE user = &apos;root&apos; AND host = &apos;loclhoast&apos;; mysql&gt; flush privileges; 在忘记root密码的时候,可以这样Linux12345678910111213# Stop MySQLsudo service mysql stop# Make MySQL service directory.sudo mkdir /var/run/mysqld# Give MySQL user permission to write to the service directory.sudo chown mysql: /var/run/mysqld# Start MySQL manually, without permission checks or networking.sudo mysqld_safe --skip-grant-tables --skip-networking &amp;# Log in without a password.mysql -uroot mysqlUPDATE mysql.user SET authentication_string=PASSWORD('YOURNEWPASSWORD'), plugin='mysql_native_password' WHERE User='root' AND Host='%';EXIT; windows 关闭正在运行的MySQL服务 打开DOS窗口,转到mysql/bin目录 输入mysqld --skip-grant-tables回车。--skip-grant-tables的意思是启动MySQL服务的时候跳过权限表认证 再打开一个DOS窗口(因为刚才那个DOS窗口已经不能动啦),转到mysql/bin目录 输入mysql回车,如果成功,将出现MySQL提示符 &gt; 修改密码:UPDATE user SET password = password(&#39;123456&#39;) WHERE user = &#39;root&#39; 刷新权限(必须):flush priviliges; 退出:quit 注销系统,再进入使用户名root和刚才设置的新密码123456登录 相关文章 https://coderwall.com/p/j9btlg/reset-the-mysql-5-7-root-password-in-ubuntu-16-04-lts]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库安装]]></title>
    <url>%2F2016%2F01%2F18%2Fdocs%2F04-mysql%2Fmysql-install%2F</url>
    <content type="text"><![CDATA[安装Oracle官方的yum源12$ wget http://dev.mysql.com/get/mysql-community-release-el6-5.noarch.rpm$ rpm -ivh mysql-community-release-el6-5.noarch.rpm 安装MySQL服务器端和客户端1$ yum -y install mysql-server mysql 配置服务启动1$ chkconfig mysqld on 初始化安装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768$ service mysqld start第一次启动时会自动创建初始化数据库，启动后执行 /usr/bin/mysql_secure_installation回车后显示如下信息： NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MySQL SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MySQL to secure it, we'll need the current password for the root user. If you've just installed MySQL, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none):（直接回车）执行后会提示输入当前密码，当前密码为空，直接回车 Set root password? [Y/n] （输入Y）回车后会提示是否设置root密码，输入“Y”回车，然后输入root的密码 New password: Re-enter new password:输入两次密码，回车后显示如下信息： By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n]（输入Y）输入Y移除匿名用户 Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n]（输入n）输入n，不禁止root远程登录 By default, MySQL comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n]（输入Y）输入Y移除测试数据库，可能有错误信息，可以忽略 Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n]（输入Y）输入Y重载数据库权限 All done! If you've completed all of the above steps, your MySQL installation should now be secure. Thanks for using MySQL! Cleaning up...安装成功 配置文件1$ find / -name my.cnf 查找my.cnf的位置，确保只有/etc/my.cnf一个文件，如果在其他目录下还有该文件，将其他目录下的文件删除，只保留/etc/my.cnf 修改配置文件中主要是innodb_buffer_pool_size项的配置，如果该服务器为数据库专用服务器，则将该项配置为服务器内存的70%左右，例如服务器内存为16G的，可以将此项配置为12G，然后服务器内存为32G的，可以将此项配置为24G、26G或28G 删除/var/lib/mysql/下的ib_logfile0、ib_logfile1文件 123456$ service mysqld restart#进入mysql命令行$ mysql -uroot -p#查看InnoDB引擎是否启用mysql&gt; show engines; Engine Support MRG_MYISAM YES CSV YES MyISAM DEFAULT InnoDB YES MEMORY YES 如果看到InnoDB为yes即正常启用了，如果不为yes，则说明未启用，说明安装有问题。 完成安装 配置远程登录1234567$ service mysqld startmysql -uroot -p（不允许直接在-p后面直接带上密码，这样容易导致密码泄露，因为可以通过history看历史命令获取该密码）输入密码use mysql//将Host为localhost的记录改为允许任意主机访问%update user set Host='%' where Host='localhost';flush privileges; 注意：远程访问必须确认主机的防火墙中已开启3306端口的访问，否则将无法远程访问数据库]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在IDE上安装代码规范检查工具]]></title>
    <url>%2F2016%2F01%2F01%2Fdocs%2F02-tools%2Fphpcs-ide-setting%2F</url>
    <content type="text"><![CDATA[我相信每个公司都有一套完备的代码规范标准，但标准是标准，如何能有效的让所有人遵守，那就要工具的辅助和实时提醒了。 安装phpcs使用composer全局安装phpcs1$ composer global require "squizlabs/php_codesniffer=*" 具体可参考：https://github.com/squizlabs/PHP_CodeSniffer IDE集成PHPStorm 设置 (适用mac) 打开PHPStorm点击 PhpStorm -&gt; Preference; 点击 Languages &amp; Frameworks -&gt; PHP -&gt; Code Sniffer; 点击 Configuration 右侧的按钮; 选择 PHP Code Sniffer（phpcs）path：的路径，就是刚才composer之后生成的那个phpcs(/vendor/squizlabs/php_codesniffer/bin/phpcs)的路径; 选择之后点击 Validate 验证成功; 继续点击 Editor -&gt; Inspections 展开点击右侧的PHP; 勾选 PHP Code Sniffer Validation 选择右侧的PSR2; 勾选 PHP Mess Detector Validation 右侧 Options 全部勾选; 点击Code Style -&gt; PHP -&gt; Set from... -&gt; Predefiend Style 选择 PSR1/PSR2 现在笔者使用phpstorm的格式化，将会自动格式化成psr-2的风格。 Sublime Text (适用mac) 安装Package Control command + shift + p 调出 安装界面 install package Preferences-&gt;Package Settings-&gt;PHP Code Sniffer-&gt;Settings - User(Default) 配置phpcs 路径 “phpcs_executable_path”: “/usr/local/bin/phpcs” 配置phpcbf 路径 “phpcbf_executable_path”: “/usr/local/bin/phpcbf” VSCode TODO 如果写的代码不符合PSR-2编码风格规范的时候，该行代码会有波浪线，点击波浪线可以查看提示信息，根据信息我们修改就可以写出优雅的代码了。 参考文章：https://segmentfault.com/a/1190000015971297]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>phpcs</tag>
        <tag>代码检查</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转）开发效率低？造成代码难以维护的35个恶习]]></title>
    <url>%2F2016%2F01%2F01%2Fdocs%2F01-program-life%2F01001%2F</url>
    <content type="text"><![CDATA[代码组织 总是说”一会弄好”，但从来不兑现。(缺乏任务管理和时间管理能力) 坚持所谓的高效、优雅的”一行代码流”，事实上，可读性才是最重的，聪明是第二位的。 无意义的优化。(类似网页大小之类的优化最后在做) 不注重代码样式和风格的严谨。 使用无意义的命名。 忽略经过验证的最佳实践。(例如代码审核、TDD、QA、自动化部署等，推荐阅读软件开发必读经典著作：Making Software：What Really Works，and Why We Believe It) 给自己埋雷。(例如使用不会报错的类库或者忽略例外) 团队工作 过早放弃计划。 坚持一个无效的计划。 总是单打独斗。(必须强迫自己于团队分享进度和想法，避免错觉，提高效率) 拒绝写糟糕的代码。(日程紧迫的时候可以写一些”糟糕”的代码，这是程序员的能力而不是bug，当然，有时间的时候一定要回头偿还”技术债”) 抱怨他人。 不与团队分享所学。 向主管/客户反馈的速度过慢。 不会充分利用Google。 看重个人编码风格。 带着个人情绪看待他人对自己代码的评论和注释。 写代码 不懂优化策略。 使用错误的工具。 不追求对开发工具和IDE的精熟。 忽略报错信息 迷恋趁手的开发工具。(不同类型的开发任务需要匹配对应的最佳开发工具，例如Sublime适合动态语言，而Eclipse适合Java，如果你喜欢vim或emacs，并不意味着能用这些工具干所有事) 不注重代码中赋值的可配置型。(不养成把代码中的活动部件分离出来的习惯，会导致技术债暴增) 喜欢重新发明车轮。 盲目的剪切/粘贴代码。 应付差事，不求甚解，不花时间搞清楚项目运作的机理。 对自己写的代码过度的自信。 不去考虑每一个设计、方案或者代码库的”副作用”。(一个成功的用例并不意味着”万灵药”) 在一个地方卡住了但坚持不呼救。 测试与维护 只去写能通过的测试。 重要项目中忽略性能测试。 不去核实代码是否真的可用，没有养成开发中及时快速测试的习惯。 重大改进延迟推送。 抛弃和逃避自己的代码。 忽略其他非功能性需求。(例如安全和性能，准备一份这方面的清单，忽略这些会毁掉你的所有成果) 点击查看原文]]></content>
      <categories>
        <category>程序人生</category>
      </categories>
      <tags>
        <tag>程序人生</tag>
        <tag>开发效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文章列表]]></title>
    <url>%2F2016%2F01%2F01%2Fdocs%2FREADME%2F</url>
    <content type="text"><![CDATA[目录 程序人生 开发效率低？造成代码难以维护的35个恶习 工具 在IDE上安装代码规范检查工具 PsySh PHP交互控制台 Git 客户端多账号管理 CentOS7.4搭建shadowsocks，以及配置BBR加速 PHP PHP 垃圾回收机制 PHP 截取文件后缀的几种方法 PHP 关于 self 和 static PHP 自动加载原理解析 PHP 7 新特性 限制IP某个时间段内访问的次数 MySQL MySQL 数据库安装 MySQL 修改root密码的几种方法 MySQL 事务详解 MySQL 索引详解 MySQL Explain详解 Linux Homestead 下安装Swoole扩展 TODO Nginx+php-fpm 运行原理 TODP AWK 简明教程 NoSQL MongoDB 基础教程 MongoDB 复制（副本集） MongoDB 分片 数据存储 计算机基础 HTTP状态码 HTTP和HTTPS的区别与联系 TODO 从输入 URL 到页面加载完成的过程中都发生了什么事情？ 正则表达式速查表 COOKIE、SESSION、TOKEN各自的优缺点都有哪些？ 关于 RESTful API 设计的总结 数据结构与算法]]></content>
  </entry>
</search>
