<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PsySh PHP交互控制台]]></title>
    <url>%2F2018%2F07%2F17%2Fdocs%2F02-tools%2Fpsysh%2F</url>
    <content type="text"><![CDATA[简介psysh是一个PHP的运行时开发平台，交互式调试器和Read-Eval-Print Loop (REPL)。说的简单点,就跟你用Chrome的时候firebug的console调试你的JavaScript代码一样。 官网 GitHub Packagist 安装直接下载123$ wget https://git.io/psysh$ chmod +x psysh$ ./psysh 使用Composer安装12$ composer g require psy/psysh:@stable$ psysh 以下教程以OS X和Windows为例，在这之前您已经将安装了php和composer，并且把加入了环境变量 OS x1. 下载12$ composer global require psy/psysh` 2. 安装完毕后，PsySH已经安装到/Users/{用户名}/.composer/vendor/psy/psysh目录下,这个时候你可以这样来直接运行1$ /Users/&#123;用户名&#125;/.composer/vendor/psy/psysh/bin/psysh 3. 为了使用方便，建议将它加入到环境变量：12$ echo &apos;export PATH=&quot;/Users/&#123;用户名&#125;/.composer/vendor/psy/psysh/bin:$PATH&quot;&apos; &gt;&gt; ~/.bashrc$ source ~/.bashrc Windows1. 我们还是用的composer来安装，win+r召唤控制台，然后1composer global require psy/psysh 2. 安装完成后，PsySH被安装到C:Users{用户名}AppDataRoamingComposervendorpsypsysh因为bin/psysh文件并不是windows的可执行文件，所以需要使用以下命令运行PsySH 1php C:\Users\&#123;用户名&#125;\AppData\Roaming\Composer\vendor\psy\psysh\bin\psysh 3. 为了使用方便，在C:Users{用户名}AppDataRoamingComposervendorpsypsyshbin目录下新建一个名为psysh.bat的文件，其内容如下12@ECHO OFFphp &quot;%~dp0psysh&quot; %* 4. 此时，把C:Users{用户名}A ppDataRoamingComposervendorpsypsyshbin 加入到系统的环境变量PATH，以后可以直接在cmd下运行psysh了123C:\Users\Vergil&gt;psyshPsy Shell v0.6.1 (PHP 5.6.8 — cli) by Justin Hileman&gt;&gt;&gt; 神器特性psysh是一个交互式的PHP运行控制台，在这里，你可以写php代码运行，并且可以清楚看到每次的返回值： 能够很智能的知道你的代码是否已经结束 自动完成，psysh可以像控制台那样，按下两次[tab]键自动补全，帮你自动完成变量名，函数，类，方法，属性，甚至是文件 文档在运行时忘记参数怎么办？psysh的文档功能可以上你及时查看文档。 PsySH的文档存放在~/.local/share/psysh/。（windows系统存放在C:\Users\{用户名}\AppData\Roaming\PsySH\） 下载中文文档： 1234$ cd ~/.local/share $ mkdir psysh$ cd psydh$ wget http://psysh.org/manual/zh/php_manual.sqlite OK，完成后重新打开PsySH 查看源代码轻松展现任何用户级的对象，类，接口，特质，常数，方法或属性的源代码： 反射列表list命令知道所有关于你的代码 - 和其他人的。轻松地列出并搜索所有的变量，常量，类，接口，特点，功能，方法和属性。 获取最后的异常信息如果忘记catch异常，可以使用wtf命令（wtf是what the fuck的意思么？）查看异常的信息： 历史记录可以像类Unix系统的history命令一样，在PsySH可以查看你运行过的PHP代码或命令。详情运行help history命令查看。 退出使用exit命令退出你的PsySH]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>psysh</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转）CentOS7.4搭建shadowsocks，以及配置BBR加速]]></title>
    <url>%2F2018%2F04%2F13%2Fdocs%2F02-tools%2Fshadowsocks-setting%2F</url>
    <content type="text"><![CDATA[前言作为一个新世纪的码农，我们经常需要使用百度以及Google等搜索引擎搜索资料或搜索一些错误的解决方案，如果English好的还可能需要到stackoverflow里查看或提问一些开发中遇到的问题，再者可能还需要到youtube上查找一下教学、科普视频等等。还好的是stackoverflow部分不牵扯Google的内容在国内还是能够正常访问的，但是Google和youtube嘛大家都懂，所以本文就介绍一下如何在vps上搭建shadowsocks，让我们能够访问这些网站，以便于我门查阅资料，切勿用做其他不法用途。 常见VPS的购买地址活跃于大街小巷的搬瓦工，也是适合新手使用的： https://bwh1.net/ vultr https://www.vultr.com/?ref=7315390 SugarHosts https://www.sugarhosts.com/zh-cn/ Linode https://www.linode.com/ Virmach https://billing.virmach.com/cart.php?gid=1 RAKSmart https://billing.raksmart.com/ Bluehost https://cn.bluehost.com/ DigitalOcean https://www.digitalocean.com 以上这些都是国外的vps，国内的可以购买阿里云或者腾讯云等，国内没有遇到优惠的话就比较贵。 安装 pippip是python的包管理工具。在本文中将使用python版本的shadowsocks，此版本的shadowsocks已发不到pip上，因此我们需要通过pip命令来安装。 在控制台执行以下命令安装 pip： 12$ curl "https://bootstrap.pypa.io/get-pip.py" -o "get-pip.py"$ python get-pip.py 安装配置 shadowsocks在控制台执行以下命令安装shadowsocks: 12$ pip install --upgrade pip$ pip install shadowsocks 安装完成后，需要创建shadowsocks的配置文件/etc/shadowsocks.json，编辑内容如下： 12345678910111213$ vim /etc/shadowsocks.json&#123; "server": "0.0.0.0", "local_address": "127.0.0.1", "local_port": 1080, "port_password": &#123; "8080": "填写密码", "8081": "填写密码" &#125;, "timeout": 600, "method": "aes-256-cfb"&#125; 说明 method为加密方法，可选aes-128-cfb,aes-192-cfb,aes-256-cfb,bf-cfb,cast5-cfb,des-cfb,rc4-md5,chacha20,rc4,table port_password为端口对应的密码，可使用密码生成工具生成一个随机密码 以上两项信息在配置shadowsocks客户端时需要配置一致，具体说明可查看shadowsocks的帮助文档。 如果你不需要配置多个端口的话，仅配置单个端口，则可以使用以下配置： 123456&#123; &quot;server&quot;: &quot;0.0.0.0&quot;, &quot;server_port&quot;: 8080, &quot;password&quot;: &quot;填写密码&quot;, &quot;method&quot;: &quot;aes-256-cfb&quot;&#125; 说明： server_port为服务监听端口 password为密码 同样的以上两项信息在配置 shadowsocks 客户端时需要配置一致。 配置自启动编辑shadowsocks 服务的启动脚本文件，内容如下： 12345678910$ vim /etc/systemd/system/shadowsocks.service[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json[Install]WantedBy=multi-user.target 执行以下命令启动 shadowsocks 服务： 12$ systemctl enable shadowsocks$ systemctl start shadowsocks 检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态： 1$ systemctl status shadowsocks -l 确认服务启动成功后，配置防火墙规则，开放你配置的端口，不然客户端是无法连接的： 123456$ firewall-cmd --zone=public --add-port=8080/tcp --permanentsuccess$ firewall-cmd --zone=public --add-port=8081/tcp --permanentsuccess$ firewall-cmd --reloadsuccess 一键安装脚本代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#!/bin/bash# Install Shadowsocks on CentOS 7echo "Installing Shadowsocks..."random-string()&#123; cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w $&#123;1:-32&#125; | head -n 1&#125;CONFIG_FILE=/etc/shadowsocks.jsonSERVICE_FILE=/etc/systemd/system/shadowsocks.serviceSS_PASSWORD=$(random-string 32)SS_PORT=8388SS_METHOD=aes-256-cfbSS_IP=`ip route get 1 | awk '&#123;print $NF;exit&#125;'`GET_PIP_FILE=/tmp/get-pip.py# install pipcurl "https://bootstrap.pypa.io/get-pip.py" -o "$&#123;GET_PIP_FILE&#125;"python $&#123;GET_PIP_FILE&#125;# install shadowsockspip install --upgrade pippip install shadowsocks# create shadowsocls configcat &lt;&lt;EOF | sudo tee $&#123;CONFIG_FILE&#125;&#123; "server": "0.0.0.0", "server_port": $&#123;SS_PORT&#125;, "password": "$&#123;SS_PASSWORD&#125;", "method": "$&#123;SS_METHOD&#125;"&#125;EOF# create servicecat &lt;&lt;EOF | sudo tee $&#123;SERVICE_FILE&#125;[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c $&#123;CONFIG_FILE&#125;[Install]WantedBy=multi-user.targetEOF# start servicesystemctl enable shadowsockssystemctl start shadowsocks# view service statussleep 5systemctl status shadowsocks -lecho "================================"echo ""echo "Congratulations! Shadowsocks has been installed on your system."echo "You shadowsocks connection info:"echo "--------------------------------"echo "server: $&#123;SS_IP&#125;"echo "server_port: $&#123;SS_PORT&#125;"echo "password: $&#123;SS_PASSWORD&#125;"echo "method: $&#123;SS_METHOD&#125;"echo "--------------------------------" 配置客户端我这里配置的是windows的客户端，挺方便的，点击即用，不需要安装。 Windows客户端下载地址： https://github.com/shadowsocks/shadowsocks-windows/releases Mac客户端下载地址： https://github.com/shadowsocks/ShadowsocksX-NG/releases Android客户端下载地址： https://github.com/shadowsocks/shadowsocks-android/releases 接着测试能否上Google搜索即可，以下的配置BBR加速则是选看，不配置也是可以正常使用shadowsocks的。 配置BBR加速什么是BBR： TCP BBR是谷歌出品的TCP拥塞控制算法。BBR目的是要尽量跑满带宽，并且尽量不要有排队的情况。BBR可以起到单边加速TCP连接的效果。 Google提交到Linux主线并发表在ACM queue期刊上的TCP-BBR拥塞控制算法。继承了Google“先在生产环境上部署，再开源和发论文”的研究传统。TCP-BBR已经再YouTube服务器和Google跨数据中心的内部广域网(B4)上部署。由此可见出该算法的前途。 TCP-BBR的目标就是最大化利用网络上瓶颈链路的带宽。一条网络链路就像一条水管，要想最大化利用这条水管，最好的办法就是给这跟水管灌满水。 BBR解决了两个问题： 在有一定丢包率的网络链路上充分利用带宽。非常适合高延迟，高带宽的网络链路。 降低网络链路上的buffer占用率，从而降低延迟。非常适合慢速接入网络的用户。Google 在 2016年9月份开源了他们的优化网络拥堵算法BBR，最新版本的 Linux内核(4.9-rc8)中已经集成了该算法。 对于TCP单边加速，并非所有人都很熟悉，不过有另外一个大名鼎鼎的商业软件“锐速”，相信很多人都清楚。特别是对于使用国外服务器或者VPS的人来说，效果更佳。 BBR项目地址： https://github.com/google/bbr 升级内核，第一步首先是升级内核到支持BBR的版本：1.yum更新系统版本： 1$ yum update 2.查看系统版本： 12$ cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) 3.安装elrepo并升级内核： 123$ rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org$ rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm$ yum --enablerepo=elrepo-kernel install kernel-ml -y 4.更新grub文件并重启系统： 12345678$ egrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \'CentOS Linux 7 Rescue 8619ff5e1306499eac41c02d3b23868e (4.14.14-1.el7.elrepo.x86_64)CentOS Linux (4.14.14-1.el7.elrepo.x86_64) 7 (Core)CentOS Linux (3.10.0-693.11.6.el7.x86_64) 7 (Core)CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)CentOS Linux (0-rescue-c73a5ccf3b8145c3a675b64c4c3ab1d4) 7 (Core)$ grub2-set-default 0$ reboot 5.重启完成后查看内核是否已更换为4.14版本： 12$ uname -r4.14.14-1.el7.elrepo.x86_64 6.开启bbr： 123$ vim /etc/sysctl.conf # 在文件末尾添加如下内容net.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbr 7.加载系统参数： 12345$ sysctl -pnet.ipv6.conf.all.accept_ra = 2net.ipv6.conf.eth0.accept_ra = 2net.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbr 如上，输出了我们添加的那两行配置代表正常。 8.确定bbr已经成功开启： 1234$ sysctl net.ipv4.tcp_available_congestion_controlnet.ipv4.tcp_available_congestion_control = bbr cubic reno$ lsmod | grep bbrtcp_bbr 20480 2 输出内容如上，则表示bbr已经成功开启。 相关文章 http://blog.51cto.com/zero01/2064660 https://github.com/shadowsocks/shadowsocks-libev https://www.jianshu.com/p/4984f324010f 原文链接（如需转载，请注明出处）http://blog.51cto.com/zero01/2064660]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>shadowsocks</tag>
        <tag>翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 客户端多账号管理]]></title>
    <url>%2F2018%2F02%2F25%2Fdocs%2F02-tools%2Fgit-multiple-accounts%2F</url>
    <content type="text"><![CDATA[前言在开发的过程中，经常会遇到这样的状况：需要在一台电脑上同时使用两个甚至多个 git 账号，负责不同的用途，比如：一个用来写个人项目，一个用来写公司的项目。为此我们需要为不同的账号生成不同的密钥，那对这些不同的账号和不同的密钥，我们该怎么处理呢？ SSH配置取消全局设置的用户名和邮箱12$ git config --global --unset user.name$ git config --global --unset user.email 生成私钥和公钥123456789101112131415$ cd ~/.ssh &amp;&amp; mkdir -pv &#123;github,company&#125;$ ssh-keygen -t rsa -C "youremail@example.com"Generating public/private rsa key pair.Enter file in which to save the key (/Users/Administrator/.ssh/id_rsa):/Users/Administrator/.ssh/github/id_rsa_github # 在回车提示中输入完整路径，如：/Users/Administrator/.ssh/github/id_rsa_github #文件命名后，按2次回车，密码为空 Enter passphrase (empty for no passphrase):Enter same passphrase again:$ ssh-keygen -t rsa -C "youremail@example.com"Generating public/private rsa key pair.Enter file in which to save the key (/Users/Administrator/.ssh/id_rsa):/Users/Administrator/.ssh/company/id_rsa_companyEnter passphrase (empty for no passphrase):Enter same passphrase again: 如果用户家目录中没有 .ssh 目录请自行创建在这里我创建了两个目录 github 和 company ，分别用来存储不同项目的密钥，进行分类管理 New SSH key 把 ~/.ssh/github/id_rsa_github.pub 的内容添加到Github的SSH keys中 把 ~/.ssh/company/id_rsa_company.pub 的内容添加到公司Gitlab的SSH keys中 新密钥添加到SSH agent中添加新密钥到SSH agent，因为默认只读取id_rsa，为了让SSH识别新的私钥，需将其添加到SSH agent中： 12$ ssh-add -K ~/.ssh/github/id_rsa_github$ ssh-add -K ~/.ssh/company/id_rsa_company 如果出现Could not open a connection to your authentication agent的错误，就试着用以下命令： 12$ ssh-agent bash$ ssh-add -K ~/.ssh/github/id_rsa_github 使用 ssh-add -l 查看 ssh key 的设置 修改 config 文件1234567891011121314151617181920$ vim ~/.ssh/configHost * KexAlgorithms +diffie-hellman-group1-sha1# default: myfirstHost github.com HostName github.com User myfirst PreferredAuthentications publickey IdentityFile ~/.ssh/github/id_rsa_github1# mysecondHost mysecond.github.com HostName github.com User mysecond PreferredAuthentications publickey IdentityFile ~/.ssh/github/id_rsa_github2Host company.com HostName company.com User company PreferredAuthentications publickey IdentityFile ~/.ssh/company/id_rsa_company 其规则就是：从上至下读取config的内容，在每个Host下寻找对应的私钥。这里将GitHub SSH仓库地址中的git@github.com替换成新建的Host别名如：mysecond.github.com，那么原地址是：git@github.com:test/Mywork.git，替换后应该是：mysecond.github.com:test/Mywork.git. 测试连通性123$ ssh -T git@github.comHi youremail! You've successfully authenticated, but GitHub does not provide shell access. 项目测试初始化项目 a1234567891011121314$ cd ~/a$ git init$ echo "myfirst" &gt; README.md$ git add README.md$ git config user.name "myfirst"$ git config user.email "myfirst@gmail.com"$ git remote add github git@github.com:myfirst/test.git$ git push -u github masterCounting objects: 3, done.Writing objects: 100% (3/3), 213 bytes | 213.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:myfirst/test.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from github. 初始化项目 b1234567891011121314$ cd ~/b$ git init$ echo "mysecond" &gt; README.md$ git add README.md$ git config user.name "mysecond"$ git config user.email "mysecond@gmail.com"$ git remote add github git@mysecond.github.com:mysecond/test.git$ git push -u github masterCounting objects: 3, done.Writing objects: 100% (3/3), 218 bytes | 218.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To mysecond.github.com:mysecond/test.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from github.]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Git</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homestead 下安装Swoole扩展]]></title>
    <url>%2F2018%2F02%2F21%2Fdocs%2F06-Linux%2Fphp-extension-swoole-install%2F</url>
    <content type="text"><![CDATA[前言尽管PHP软件源提供了不少PHP扩展，但并不是提供所有的扩展，那么如果我们需要安装一个软件源没有提供的扩展怎么办呢？利用 php-dev 就可以很方便的进行自行编译 PHP 扩展了，但是由于Homestaed内置了多个PHP版本，安装方式略有不同，不能简单粗暴的使用 pecl 安装了，因为安装好了不知道是给谁用的。下面分别介绍单一PHP和多版本PHP如何安装PHP扩展 注意：命令权限不够时请自动在命令前加上sudo前缀提权； 单一版本PHP安装 php-dev ，如果不是 7.2 需要自己修改一下版本号1$ apt install php7.2-dev 安装Swoole扩展1$ pecl install swoole 添加配置文件123$ cd /etc/php/7.2/fpm/conf.d$ touch swoole.ini$ echo "extension=swoole.so" | tee -a swoole.ini 重启php-fpm生效1$ systemctl restart php7.2-fpm 多PHP版本安装php-dev1$ apt install php5.6-dev php7.2-dev 下载swoole源码1234$ cd /usr/src$ wget http://pecl.php.net/get/swoole-1.9.15.tgz$ tar xzf swoole-1.9.15.tgz$ cd swoole-1.9.15 为PHP5.6进行编译1234$ cd /usr/src/swoole-1.9.15$ /usr/bin/phpize5.6$ ./configure --with-php-config=/usr/bin/php-config5.6$ make &amp;&amp; make install 为PHP7.2进行编译1234$ cd /usr/src/swoole-1.9.15$ /usr/bin/phpize7.2$ ./configure --with-php-config=/usr/bin/php-config7.2$ make &amp;&amp; make install 编译完成后扩展在module目录中，它的文件名是swoole.so 查看php的extension_dir1234$ php -i|grep extension_dirextension_dir =&gt; /usr/lib/php/20180731 =&gt; /usr/lib/php/20180731sqlite3.extension_dir =&gt; no value =&gt; no value 这里可以将php替换成指定版本，就可以查看指定版本的extension_dir 添加php配置文件12$ cd /etc/php/7.2/mods-available/$ sudo touch swoole.ini 添加以下内容 123; configuration for php swoole module; priorit=20extension=swoole.so 建立链接文件 123$ sudo ln -s /etc/php/7.0/mods-available/swoole.ini /etc/php/7.2/cli/conf.d/20-swoole.ini $ sudo ln -s /etc/php/7.0/mods-available/swoole.ini /etc/php/7.2/fpm/conf.d/20-swoole.ini 重启php-fpm1$ sudo service php7.2-fpm restart 将7.2替换成5.6为php56添加swoole扩展 同理，什么mongodb、redis的扩展等等，也都能够通过类似的方法完成安装 扩展：Homestead下修改cli模式下默认php版本我们通过命令 ll /usr/bin/php 可以看到，php是/etc/alternatives/php 建立的链接文件 1lrwxrwxrwx 1 root root 21 Feb 3 19:53 /usr/bin/php -&gt; /etc/alternatives/php 然后通过命令 ll /etc/alternatives/php 可以看到是通过 usr/bin/php7.0 建立的链接文件 1lrwxrwxrwx 1 root root 15 Feb 19 05:15 /etc/alternatives/php -&gt; /usr/bin/php7.2* 所以我们只要修改 /etc/alternatives/php 的源文件即可修改cli模式下php的默认版本，命令如下： 12$ sudo mv /etc/alternatives/php$ sudo ln -s /usr/bin/php7.0 /etc/alternatives/php]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Swoole</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 分片]]></title>
    <url>%2F2017%2F06%2F14%2Fdocs%2F05-nosql%2Fmongodb-sharding%2F</url>
    <content type="text"><![CDATA[简介在Mongodb里面存在另一种集群，就是分片技术,可以满足MongoDB数据量大量增长的需求。当MongoDB存储海量的数据时，一台机器可能不足以存储数据，也可能不足以提供可接受的读写吞吐量。这时，我们就可以通过在多台机器上分割数据，使得数据库系统能存储和处理更多的数据。 为什么使用片 复制所有的写入操作到主节点 延迟的敏感数据会在主节点查询 单个副本集限制在12个节点 当请求量巨大时会出现内存不足。 本地磁盘不足 垂直扩展价格昂贵 MongoDB分片集群组成MongoDB分片群集主要有如下三个主要组件： Shard：分片服务器，用于存储实际的数据块，实际生产环境中一个shard server角色可由几台服务器组成一个Replica Set 承担，防止主机节点故障。 Config Server：配置服务器，存储了整个分片群集的配置信息，其中包括chunk信息。 Routers：前端路由，客户端由此接入，且让整个群集看上去像单一数据库，前端应用可以透明使用。 下图展示了在MongoDB中使用分片集群结构分布： 分片集群的简单配置在这里在一台物理服务器上部署一个简单结构的MongoDB分片集群： 1台路由实例（端口27017）1台配置实例（端口37017）3台Shard实例（端口47017、47018、47019） 安装Mongodb具体安装参考MongoDB 基础教程 123456$ mkdir -p /usr/local/mongodb/data/db&#123;1,2,3,4&#125; # 创建数据存储目录 $ mkdir /usr/local/mongodb/data/logs # 创建日志文件存储目录 $ touch /usr/local/mongodb/data/logs/mongodb&#123;1,2,3,4&#125;.log # 创建日志文件 $ chmod -R 777 /usr/local/mongodb/data/logs/*.log $ ulimit -n 25000 # 最多打开文件个数，重启后失效 $ ulimit -u 25000 # 最多打开进程数，重启后失效 配置服务器123$ cd /usr/local/mongodb/data$ mkdir conf$ vim mongodb1.conf 12345678port=37017 # 端口号 dbpath=/usr/local/mongodb/data/db/db1 # 数据存储目录 logpath=/usr/local/mongodb/data/logs/mongodb1.log # 日志文件存储目录 logappend=truefork=truemaxConns=5000storageEngine=mmapv1configsvr=true 分片服务器三台分片服务器配置相同，只需更改端口号、数据存储目录和日志存储目录即可； 123$ cp -p mongodb1.conf mongodb2.conf$ vim mongodb2.conf 12345678port=47017 # 端口号dbpath=/usr/local/mongodb/data/db/db2 # 数据存储目录logpath=/usr/local/mongodb/data/logs/mongodb2.log # 日志文件存储目录logappend=truefork=truemaxConns=5000storageEngine=mmapv1shardsvr=true 重复以上步骤分别配置其他分片服务器 启动服务器 1234$ mongod -f /usr/local/mongodb/data/conf/mongodb1.conf$ mongod -f /usr/local/mongodb/data/conf/mongodb2.conf$ mongod -f /usr/local/mongodb/data/conf/mongodb3.conf$ mongod -f /usr/local/mongodb/data/conf/mongodb4.conf 启动路由服务器123456$ ./mongos --port 27017 --fork --logpath=/usr/local/mongodb/data/log/route.log --configdb 192.168.33.12:37017 --chunkSize 1#--port指定对方连接入口#--fork后台运行#--logpath指定日志文件存储路径#--configdb指定给谁处理 启用分片服务器12345$ ./bin/mongo&gt; sh.addShard("192.168.27.153:47017")&gt; sh.addShard("192.168.27.153:47018")&gt; sh.status() 启用分片存储功能123456&gt; use kgc&gt; for (var i=1;i&lt;=50000;i++)db.users.insert(&#123;"id":i,"name":"zhangsan"+i&#125;)&gt; db.users.createIndex(&#123;"id":1&#125;) #对users表创建索引&gt; sh.enableSharding("kgc") #启用kgc数据库分片&gt; sh.shardCollection("kgc.users",&#123;"id":1&#125;) #表分片&gt; sh.status() 给分片添加标签123&gt; sh.addShardTag("shard0000","test01")&gt; sh.addShardTag("shard0001","test02")&gt; sh.status() 添加或删除分片服务器1234&gt; sh.addShard("192.168.33.12:47019")&gt; use admin&gt; db.runCommand(&#123;"removeshard":"192.168.27.153:47019"&#125;)&gt; sh.status() 基本操作查看数据分布 12&gt; use kgc&gt; db.users.getShardDistribution() 查看集合是否分片 1&gt; db.collectionName.stats().sharded # 简单的返回true或者false TODO分片策略 参考文档 https://www.runoob.com/mongodb/mongodb-sharding.htmlhttps://blog.51cto.com/13659182/2149307https://www.jianshu.com/p/cb55bb333e2d]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 复制（副本集）]]></title>
    <url>%2F2017%2F06%2F13%2Fdocs%2F05-nosql%2Fmongodb-replication%2F</url>
    <content type="text"><![CDATA[简介MongoDB复制是将数据同步在多个服务器的过程。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。复制还允许您从硬件故障和服务中断中恢复数据。Mongodb复制集由一组Mongod实例（进程）组成，包含一个Primary节点和多个Secondary节点。Mongodb Driver（客户端）的所有数据都写入Primary，Secondary从Primary同步写入的数据，以保持复制集内所有成员存储相同的数据集，实现数据的高可用。 使用场景 数据冗余，用做故障恢复使用，当发生硬件故障或者其它原因造成的宕机时，可以使用副本进行恢复。 读写分离，读的请求分流到副本上，减轻主节点的读压力。 mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。mongodb各个节点常见的搭配方式为：一主一从、一主多从。主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。 一个典型的副本集架构如下图所示： 以上结构图中，客户端从主节点读取数据，在客户端写入数据到主节点时， 主节点与从节点进行数据交互保障数据的一致性。 MongoDB副本集设置通过指定 –replSet 选项来启动mongoDB。–replSet 基本语法格式如下： 1mongod --port &quot;PORT&quot; --dbpath &quot;YOUR_DB_DATA_PATH&quot; --replSet &quot;REPLICA_SET_INSTANCE_NAME&quot; 实例 1./bin/mongod --port=27017 --dbpath=./data/db/ --replSet=rs0 以上实例会启动一个名为rs0的MongoDB实例，其端口号为27017。启动后打开命令提示框并连接上mongoDB服务。在Mongo客户端使用命令rs.initiate()来启动一个新的副本集。我们可以使用rs.conf()来查看副本集的配置。查看副本集状态使用rs.status()命令 。 副本集特征： N 个节点的集群 任何节点可作为主节点 所有写入操作都在主节点上 自动故障转移 自动恢复 副本集添加成员添加副本集的成员，我们需要使用多台服务器来启动mongo服务。进入Mongo客户端，并使用rs.add()方法来添加副本集的成员。 1&gt; rs.add(HOST_NAME:PORT) MongoDB中你只能通过主节点将Mongo服务添加到副本集中， 判断当前运行的Mongo服务是否为主节点可以使用命令db.isMaster() 。MongoDB的副本集与我们常见的主从有所不同，主从在主机宕机后所有服务将停止，而副本集在主机宕机后，副本会接管主节点成为主节点，不会出现宕机的情况。 副本集角色 主节点（Primary） 接收所有的写请求，然后把修改同步到所有Secondary。一个Replica Set只能有一个Primary节点，当Primary挂掉后，其他Secondary或者Arbiter节点会重新选举出来一个主节点。默认读请求也是发到Primary节点处理的，可以通过修改客户端连接配置以支持读取Secondary节点。 副本节点（Secondary） 与主节点保持同样的数据集。当主节点挂掉的时候，参与选主。 仲裁者（Arbiter） 不保有数据，不参与选主，只进行选主投票。使用Arbiter可以减轻数据存储的硬件需求，Arbiter几乎没什么大的硬件资源需求，但重要的一点是，在生产环境下它和其他数据节点不要部署在同一台机器上。 两种架构模式 PSS Primary + Secondary + Secondary模式，通过Primary和Secondary搭建的Replica SetDiagram of a 3 member replica set that consists of a primary and two secondaries. 该模式下 Replica Set节点数必须为奇数，目的是选主投票的时候要出现大多数才能进行选主决策。 PSA Primary + Secondary + Arbiter模式，使用Arbiter搭建Replica Set 偶数个数据节点，加一个Arbiter构成的Replica Set 选举机制复制集通过 replSetInitiate 命令或 rs.initiate() 命令进行初始化。初始化后各个成员间开始发送心跳消息，并发起 Primary 选举操作，获得大多数成员投票支持的节点，会成为 Primary，其余节点成为 Secondary。 123456789config = &#123; _id : &quot;my_replica_set&quot;, members : [ &#123;_id : 0, host : &quot;rs1.example.net:27017&quot;&#125;, &#123;_id : 1, host : &quot;rs2.example.net:27017&quot;&#125;, &#123;_id : 2, host : &quot;rs3.example.net:27017&quot;&#125;, ]&#125;rs.initiate(config) 大多数假设复制集内投票成员（后续介绍）数量为 N，则大多数为 N/2 + 1，当复制集内存活成员数量不足大多数时，整个复制集将无法选举出 Primary，复制集将无法提供写服务，处于只读状态 关于大多数的计算如下表所示 投票成员数 大多数 容忍失效数 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 Mongodb副本集的选举基于Bully算法，这是一种协调者竞选算法，详细解析可以参考这里Primary 的选举受节点间心跳、优先级、最新的 oplog 时间等多种因素影响。官方文档对于选举机制的说明选举机制的说明 特殊角色 ArbiterArbiter 节点只参与投票，不能被选为 Primary，并且不从 Primary 同步数据。当节点宕机导致复制集无法选出 Primary时，可以给复制集添加一个 Arbiter 节点，即使有节点宕机，仍能选出 Primary。Arbiter 本身不存储数据，是非常轻量级的服务，当复制集成员为偶数时，最好加入一个 Arbiter 节点，以提升复制集可用性。 Priority0Priority0节点的选举优先级为0，不会被选举为 Primary。比如你跨机房 A、B 部署了一个复制集，并且想指定 Primary 必须在 A 机房，这时可以将 B 机房的复制集成员 Priority 设置为0，这样 Primary 就一定会是 A 机房的成员。（注意：如果这样部署，最好将大多数节点部署在 A 机房，否则网络分区时可能无法选出 Primary。） Vote0Mongodb 3.0里，复制集成员最多50个，参与 Primary 选举投票的成员最多7个，其他成员（Vote0）的 vote 属性必须设置为0，即不参与投票。 HiddenHidden 节点不能被选为主（Priority 为0），并且对 Driver 不可见。因 Hidden 节点不会接受 Driver 的请求，可使用 Hidden 节点做一些数据备份、离线计算的任务，不会影响复制集的服务。 DelayedDelayed 节点必须是 Hidden 节点，并且其数据落后与 Primary 一段时间（可配置，比如1个小时）。因 Delayed 节点的数据比 Primary 落后一段时间，当错误或者无效的数据写入 Primary 时，可通过 Delayed 节点的数据来恢复到之前的时间点。 触发选举条件 初始化一个副本集时。 从库不能连接到主库(默认超过10s，可通过heartbeatTimeoutSecs参数控制)，由从库发起选举 主库放弃primary 角色，比如执行rs.stepdown 命令 Mongodb副本集通过心跳检测实现自动failover机制，进而实现高可用 MongoDB复制流程Primary 与 Secondary 之间通过 oplog 来同步数据，Primary 上的写操作完成后，会向特殊的 local.oplog.rs 特殊集合写入一条 oplog，Secondary 不断的从 Primary 取新的 oplog 并应用。因 oplog 的数据会不断增加，local.oplog.rs 被设置成为一个 capped 集合，当容量达到配置上限时，会将最旧的数据删除掉。另外考虑到 oplog 在 Secondary 上可能重复应用，oplog 必须具有幂等性，即重复应用也会得到相同的结果。如下 oplog 的格式，包含 ts、h、op、ns、o 等字段。 123456789101112&#123; &quot;ts&quot; : Timestamp(1446011584, 2), &quot;h&quot; : NumberLong(&quot;1687359108795812092&quot;), &quot;v&quot; : 2, &quot;op&quot; : &quot;i&quot;, &quot;ns&quot; : &quot;test.nosql&quot;, &quot;o&quot; : &#123; &quot;_id&quot; : ObjectId(&quot;563062c0b085733f34ab4129&quot;), &quot;name&quot; : &quot;mongodb&quot;, &quot;score&quot; : &quot;100&quot; &#125;&#125; 属性 说明 ts 操作时间，当前 timestamp + 计数器，计数器每秒都被重置 h 操作的全局唯一标识 v oplog 版本信息 op 操作类型 op.i 插入操作 op.u 更新操作 op.d 删除操作 op.c 执行命令（如 createDatabase，dropDatabase） op.n 空操作，特殊用途 ns 操作针对的集合 o 操作内容 o2 操作查询条件，仅 update 操作包含该字段。 Secondary 初次同步数据时，会先执行 init sync，从 Primary（或其他数据更新的 Secondary）同步全量数据，然后不断通过执行tailable cursor从 Primary 的 local.oplog.rs 集合里查询最新的 oplog 并应用到自身。 异常回滚 当 Primary 宕机时，如果有数据未同步到 Secondary，当 Primary 重新加入时，如果新的 Primary 上已经发生了写操作，则旧 Primary 需要回滚部分操作，以保证数据集与新的 Primary 一致。旧 Primary 将回滚的数据写到单独的 rollback 目录下，数据库管理员可根据需要使用 mongorestore 进行恢复 读写配置默认情况下，复制集的所有读请求都发到 Primary，Driver 可通过设置 Read Preference 来将读请求路由到其他的节点。 primary：默认规则，所有读请求发到 Primary； primaryPreferred：Primary 优先，如果 Primary 不可达，请求 Secondary； secondary：所有的读请求都发到 secondary； secondaryPreferred：Secondary 优先，当所有 Secondary 不可达时，请求 Primary； nearest：读请求发送到最近的可达节点上（通过 ping 探测得出最近的节点）。 关于read-preference Write Concern默认情况下，Primary 完成写操作即返回，Driver 可通过设置 Write Concern 来设置写成功的规则。如下的 write concern 规则设置写必须在大多数节点上成功，超时时间为5s。 1234db.products.insert( &#123; item: &quot;envelopes&quot;, qty : 100, type: &quot;Clasp&quot; &#125;, &#123; writeConcern: &#123; w: majority, wtimeout: 5000 &#125; &#125;) 关于write-concern 参考文档 https://www.runoob.com/mongodb/mongodb-replication.htmlhttps://www.cnblogs.com/littleatp/p/8562842.htmlhttp://www.mongoing.com/archives/5200]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 基础教程]]></title>
    <url>%2F2017%2F06%2F11%2Fdocs%2F05-nosql%2Fmongodb-tutorial-base%2F</url>
    <content type="text"><![CDATA[MongoDB 简介什么是MongoDBMongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多地节点，可以保证服务器的性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值（key=&gt;value）对组成。MongoDB 文档类似于JSON对象。字段值可以包含其他文档，数组以及文档数据。 主要特点 MongoDB 是一个面向文档存储的数据库，操作起来比较简单和容易。 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=”Sameer”,Address=”8 Gandhi Road”)来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。 MongoDB安装简单。 安装Linux平台安装MongoDBMongoDB 提供了linux各发行版本64位的安装包，你可以在官网下载安装包。下载地址：https://www.mongodb.com/download-center/community 下载完安装包，并解压 tgz（以下演示的是 64 位 Linux上的安装） 。 123$ wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.6.tgz$ tar -zxvf mongodb-linux-x86_64-3.0.6.tgz$ mv mongodb-linux-x86_64-3.0.6/ mongodb MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中： 1$ export PATH=mongodb-install-directory/bin:$PATH mongodb-install-directory 为你 MongoDB 的安装路径。如本文的 /usr/local/mongodb 。 创建数据目录MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。 以下实例中我们将data目录创建于/usr/local/mongodb/目录下。 1$ mkdir -p /usr/local/mongodb/data/db 启动MongoDB服务你可以再命令行中执行mongodb安装目录中的bin目录执行mongod命令来启动mongdb服务。 注意：如果你的数据库目录不是/data/db（MongoDB 默认的启动的数据库路径），可以通过 –dbpath 来指定。 1$ mongod --dbpath=/usr/local/mongodb/data/db MongoDB后台管理Shell如果你需要进入MongoDB后台管理，你需要先打开mongodb装目录的下的bin目录，然后执行mongo命令文件。MongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。当你进入mongoDB后台后，它默认会链接到 test 文档（数据库）： 1234567891011$ mongoMongoDB shell version: 3.0.6connecting to: testWelcome to the MongoDB shell.For interactive help, type "help".For more comprehensive documentation, see http://docs.mongodb.org/Questions? Try the support group http://groups.google.com/group/mongodb-user&gt; 现在让我们插入一些简单的数据，并对插入的数据进行检索： 12345&gt; db.runoob.insert(&#123;test:1&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.runoob.find()&#123; &quot;_id&quot; : ObjectId(&quot;5d26b208168b6593d96e6387&quot;), &quot;test&quot; : 1 &#125;&gt; OK，至此我们的MongoDB已经安装完成。 概念解析不管我们学习什么数据库都应该学习其中的基础概念，在mongodb中基本的概念是文档、集合、数据库，下面我们挨个介绍。下表将帮助您更容易理解Mongo中的一些概念： SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table join 表连接，MongoDB不支持 primary key primary key 主键，MongoDB自动将_id字段设置为主键 数据库一个mongodb中可以建立多个数据库。MongoDB的默认数据库为”db”，该数据库存储在data目录中。MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 文档(Document)文档是一组键值(key-value)对(即 BSON)。MongoDB 的文档不需要设置相同的字段，并且相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。 一个简单的文档例子如下： 1&#123;"site":"www.axkeson.com", "name":"Axkeson"&#125; 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 集合集合就是 MongoDB 文档组，类似于 RDBMS （关系数据库管理系统：Relational Database Management System)中的表格。 集合存在于数据库中，集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。 比如，我们可以将以下不同数据结构的文档插入到集合中： 123&#123;&quot;site&quot;:&quot;www.baidu.com&quot;&#125;&#123;&quot;site&quot;:&quot;www.google.com&quot;,&quot;name&quot;:&quot;Google&quot;&#125;&#123;&quot;site&quot;:&quot;www.axkeson.com&quot;, &quot;name&quot;:&quot;Axkeson&quot;&#125; 当第一个文档插入时，集合就会被创建。 capped collections Capped collections 就是固定大小的collection。它有很高的性能以及队列过期的特性(过期按照插入的顺序). 有点和 “RRD” 概念类似。Capped collections 是高性能自动的维护对象的插入顺序。它非常适合类似记录日志的功能和标准的 collection 不同，你必须要显式的创建一个capped collection，指定一个 collection 的大小，单位是字节。collection 的数据存储空间值提前分配的。Capped collections 可以按照文档的插入顺序保存到集合中，而且这些文档在磁盘上存放位置也是按照插入顺序来保存的，所以当我们更新Capped collections 中文档的时候，更新后的文档不可以超过之前文档的大小，这样话就可以确保所有文档在磁盘上的位置一直保持不变。由于 Capped collection 是按照文档的插入顺序而不是使用索引确定插入位置，这样的话可以提高增添数据的效率。MongoDB 的操作日志文件 oplog.rs 就是利用 Capped Collection 来实现的。要注意的是指定的存储大小包含了数据库的头信息。 1&gt; db.createCollection(&quot;mycoll&quot;, &#123;capped:true, size:100000&#125;) 在 capped collection 中，你能添加新的对象。 能进行更新，然而，对象不会增加存储空间。如果增加，更新就会失败 。 使用 Capped Collection 不能删除一个文档，可以使用 drop() 方法删除 collection 所有的行。 删除之后，你必须显式的重新创建这个 collection。 常用操作数据库创建数据库 1use &lt;DATABASE_NAME&gt; 查看所有数据库 1show dbs 查看当数据库 1db 删除数据库 1db.dropDatabase() 注意: 在 MongoDB 中，集合只有在内容插入后才会创建! 就是说，创建集合(数据表)后要再插入一个文档(记录)，集合才会真正创建。 集合创建集合 1db.createCollection(COLLECTION_NAME, options) 查看已有集合 1show collections 或 show tables 删除集合 1db.COLLECTION_NAME.drop() 实例 1234&gt; db.createCollection(&quot;mycol&quot;, &#123; capped : true, autoIndexId : true, size : 6142800, max : 10000 &#125; )&#123; &quot;ok&quot; : 1 &#125;&gt; 在 MongoDB 中，你不需要创建集合。当你插入一些文档时，MongoDB 会自动创建集合。 文档插入文档 1db.COLLECTION_NAME.insert(document) 更新文档 123456789db.COLLECTION_NAME.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 参数说明： query : update的查询条件，类似sql update查询内where后面的。 update : update的对象和一些更新的操作符（如$,$inc…）等，也可以理解为sql update查询内set后面的 upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入 multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。 writeConcern :可选，抛出异常的级别。 实例 1234567891011121314151617181920212223242526&gt;db.col.insert(&#123; title: &apos;MongoDB 教程&apos;, description: &apos;MongoDB 是一个 Nosql 数据库&apos;, by: &apos;Axkeson教程&apos;, url: &apos;http://www.axkeson.com&apos;, tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;], likes: 100&#125;)&gt;db.col.update(&#123;&apos;title&apos;:&apos;MongoDB 教程&apos;&#125;,&#123;$set:&#123;&apos;title&apos;:&apos;MongoDB&apos;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.col.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;56064f89ade2f21f36b03136&quot;), &quot;title&quot; : &quot;MongoDB&quot;, &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;, &quot;by&quot; : &quot;Axkeson教程&quot;, &quot;url&quot; : &quot;http://www.axkeson.com&quot;, &quot;tags&quot; : [ &quot;mongodb&quot;, &quot;database&quot;, &quot;NoSQL&quot; ], &quot;likes&quot; : 100&#125;&gt; save() 方法 通过传入的文档来替换已有文档。语法格式如下：参数说明： document : 文档数据。 writeConcern :可选，抛出异常的级别。 123456db.COLLECTION_NAME.save( &lt;document&gt;, &#123; writeConcern: &lt;document&gt; &#125;) 更多实例 12345db.col.update( &#123; &quot;count&quot; : &#123; $gt : 1 &#125; &#125; , &#123; $set : &#123; &quot;test2&quot; : &quot;OK&quot;&#125; &#125; ); // 只更新第一条记录：db.col.update( &#123; &quot;count&quot; : &#123; $gt : 3 &#125; &#125; , &#123; $set : &#123; &quot;test2&quot; : &quot;OK&quot;&#125; &#125;,false,true ); // 全部更新：db.col.update( &#123; &quot;count&quot; : &#123; $gt : 5 &#125; &#125; , &#123; $set : &#123; &quot;test5&quot; : &quot;OK&quot;&#125; &#125;,true,true ); // 全部添加进去:db.col.update( &#123; &quot;count&quot; : &#123; $gt : 15 &#125; &#125; , &#123; $inc : &#123; &quot;count&quot; : 1&#125; &#125;,false,true ); // 全部更新：db.col.update( &#123; &quot;count&quot; : &#123; $gt : 10 &#125; &#125; , &#123; $inc : &#123; &quot;count&quot; : 1&#125; &#125;,false,false ); // 只更新第一条记录 删除文档 1234db.COLLECTION_NAME.remove( &lt;query&gt;, &lt;justOne&gt;) 查询文档 123db.COLLECTION_NAME.findOne(query, projection)db.COLLECTION_NAME.find(query, projection)db.COLLECTION_NAME.find(query, projection).pretty() 索引创建索引 1db.COLLECTION_NAME.createIndex(keys, options) 参考文档 https://docs.mongodb.com/manual/https://www.runoob.com/mongodb/mongodb-replication.html]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在IDE上安装代码规范检查工具]]></title>
    <url>%2F2016%2F01%2F01%2Fdocs%2F02-tools%2Fphpcs-ide-setting%2F</url>
    <content type="text"><![CDATA[我相信每个公司都有一套完备的代码规范标准，但标准是标准，如何能有效的让所有人遵守，那就要工具的辅助和实时提醒了。 安装phpcs使用composer全局安装phpcs1$ composer global require "squizlabs/php_codesniffer=*" 具体可参考：https://github.com/squizlabs/PHP_CodeSniffer IDE集成PHPStorm 设置 (适用mac) 打开PHPStorm点击 PhpStorm -&gt; Preference; 点击 Languages &amp; Frameworks -&gt; PHP -&gt; Code Sniffer; 点击 Configuration 右侧的按钮; 选择 PHP Code Sniffer（phpcs）path：的路径，就是刚才composer之后生成的那个phpcs(/vendor/squizlabs/php_codesniffer/bin/phpcs)的路径; 选择之后点击 Validate 验证成功; 继续点击 Editor -&gt; Inspections 展开点击右侧的PHP; 勾选 PHP Code Sniffer Validation 选择右侧的PSR2; 勾选 PHP Mess Detector Validation 右侧 Options 全部勾选; 点击Code Style -&gt; PHP -&gt; Set from... -&gt; Predefiend Style 选择 PSR1/PSR2 现在笔者使用phpstorm的格式化，将会自动格式化成psr-2的风格。 Sublime Text (适用mac) 安装Package Control command + shift + p 调出 安装界面 install package Preferences-&gt;Package Settings-&gt;PHP Code Sniffer-&gt;Settings - User(Default) 配置phpcs 路径 “phpcs_executable_path”: “/usr/local/bin/phpcs” 配置phpcbf 路径 “phpcbf_executable_path”: “/usr/local/bin/phpcbf” VSCode TODO 如果写的代码不符合PSR-2编码风格规范的时候，该行代码会有波浪线，点击波浪线可以查看提示信息，根据信息我们修改就可以写出优雅的代码了。 参考文章：https://segmentfault.com/a/1190000015971297]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>phpcs</tag>
        <tag>代码检查</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转）开发效率低？造成代码难以维护的35个恶习]]></title>
    <url>%2F2016%2F01%2F01%2Fdocs%2F01-program-life%2F01001%2F</url>
    <content type="text"><![CDATA[代码组织 总是说”一会弄好”，但从来不兑现。(缺乏任务管理和时间管理能力) 坚持所谓的高效、优雅的”一行代码流”，事实上，可读性才是最重的，聪明是第二位的。 无意义的优化。(类似网页大小之类的优化最后在做) 不注重代码样式和风格的严谨。 使用无意义的命名。 忽略经过验证的最佳实践。(例如代码审核、TDD、QA、自动化部署等，推荐阅读软件开发必读经典著作：Making Software：What Really Works，and Why We Believe It) 给自己埋雷。(例如使用不会报错的类库或者忽略例外) 团队工作 过早放弃计划。 坚持一个无效的计划。 总是单打独斗。(必须强迫自己于团队分享进度和想法，避免错觉，提高效率) 拒绝写糟糕的代码。(日程紧迫的时候可以写一些”糟糕”的代码，这是程序员的能力而不是bug，当然，有时间的时候一定要回头偿还”技术债”) 抱怨他人。 不与团队分享所学。 向主管/客户反馈的速度过慢。 不会充分利用Google。 看重个人编码风格。 带着个人情绪看待他人对自己代码的评论和注释。 写代码 不懂优化策略。 使用错误的工具。 不追求对开发工具和IDE的精熟。 忽略报错信息 迷恋趁手的开发工具。(不同类型的开发任务需要匹配对应的最佳开发工具，例如Sublime适合动态语言，而Eclipse适合Java，如果你喜欢vim或emacs，并不意味着能用这些工具干所有事) 不注重代码中赋值的可配置型。(不养成把代码中的活动部件分离出来的习惯，会导致技术债暴增) 喜欢重新发明车轮。 盲目的剪切/粘贴代码。 应付差事，不求甚解，不花时间搞清楚项目运作的机理。 对自己写的代码过度的自信。 不去考虑每一个设计、方案或者代码库的”副作用”。(一个成功的用例并不意味着”万灵药”) 在一个地方卡住了但坚持不呼救。 测试与维护 只去写能通过的测试。 重要项目中忽略性能测试。 不去核实代码是否真的可用，没有养成开发中及时快速测试的习惯。 重大改进延迟推送。 抛弃和逃避自己的代码。 忽略其他非功能性需求。(例如安全和性能，准备一份这方面的清单，忽略这些会毁掉你的所有成果) 点击查看原文]]></content>
      <categories>
        <category>程序人生</category>
      </categories>
      <tags>
        <tag>程序人生</tag>
        <tag>开发效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文章列表]]></title>
    <url>%2F2016%2F01%2F01%2Fdocs%2FREADME%2F</url>
    <content type="text"><![CDATA[目录 程序人生 开发效率低？造成代码难以维护的35个恶习 工具 在IDE上安装代码规范检查工具 PsySh PHP交互控制台 Git 客户端多账号管理 CentOS7.4搭建shadowsocks，以及配置BBR加速 PHP MySQL Linux Homestead 下安装Swoole扩展 NoSQL MongoDB 基础教程 MongoDB 复制（副本集） MongoDB 分片 数据存储 计算机基础 数据结构预算法]]></content>
  </entry>
</search>
